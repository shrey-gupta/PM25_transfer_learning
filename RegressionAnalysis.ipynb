{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories uploaded!!\n"
     ]
    }
   ],
   "source": [
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2 ##STrAdaBoost.R2\n",
    "# from TwoStageTrAdaBoostR2 import TwoStageTrAdaBoostR2 ##two-stage TrAdaBoost.R2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Dropout, Flatten\n",
    "from keras import optimizers, utils, initializers, regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler #Importing the StandardScaler\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "#Geo plotting libraries\n",
    "import geopandas as gdp\n",
    "from matplotlib.colors import ListedColormap\n",
    "# import geoplot as glpt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "######### Instance Transfer repositories ####################\n",
    "from adapt.instance_based import TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Repositories uploaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Upload Completed!!\n"
     ]
    }
   ],
   "source": [
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "print(\"Second Upload Completed!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concrete Data\n",
      "-------------------------------------------\n",
      "(1030, 9)\n",
      "Target Set:  (368, 8)\n",
      "Source Set:  (406, 8)\n",
      "Test Set:  (256, 8)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################################### Concrete ###########################################################################################################\n",
    "ConcreteData_df = pd.read_excel('UCI_regression/Concrete/Concrete_Data.xls') ## 'Cement' found to be correlated at 0.4 :: 100\n",
    "print(\"Concrete Data\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(ConcreteData_df.shape)\n",
    "\n",
    "drop_col_concrete = ['Cement']\n",
    "\n",
    "concrete_tgt_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] <= 225)]\n",
    "concrete_tgt_df = concrete_tgt_df.drop(drop_col_concrete, axis = 1)\n",
    "concrete_tgt_df = concrete_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",concrete_tgt_df.shape)\n",
    "\n",
    "concrete_source_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] > 225) & (ConcreteData_df['Cement'] <= 350)]\n",
    "concrete_source_df = concrete_source_df.drop(drop_col_concrete, axis = 1)\n",
    "concrete_source_df = concrete_source_df.reset_index(drop=True)\n",
    "print(\"Source Set: \",concrete_source_df.shape)\n",
    "\n",
    "concrete_test_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] > 350)]\n",
    "concrete_test_df = concrete_test_df.drop(drop_col_concrete, axis = 1)\n",
    "concrete_test_df = concrete_test_df.reset_index(drop=True)\n",
    "print(\"Test Set: \",concrete_test_df.shape)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_column_concrete = ['ConcreteCompressiveStrength']\n",
    "\n",
    "concrete_tgt_df_y = concrete_tgt_df[target_column_concrete]\n",
    "concrete_tgt_df_X = concrete_tgt_df.drop(target_column_concrete, axis = 1)\n",
    "\n",
    "concrete_source_df_y = concrete_source_df[target_column_concrete]\n",
    "concrete_source_df_X = concrete_source_df.drop(target_column_concrete, axis = 1)\n",
    "\n",
    "concrete_test_df_y = concrete_test_df[target_column_concrete]\n",
    "concrete_test_df_X = concrete_test_df.drop(target_column_concrete, axis = 1)\n",
    "\n",
    "############## Merging the datasets ##########################################\n",
    "concrete_X_df = pd.concat([concrete_tgt_df_X, concrete_source_df_X], ignore_index=True)\n",
    "concrete_y_df = pd.concat([concrete_tgt_df_y, concrete_source_df_y], ignore_index=True)\n",
    "\n",
    "concrete_np_train_X = concrete_X_df.to_numpy()\n",
    "concrete_np_train_y = concrete_y_df.to_numpy()\n",
    "\n",
    "concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "\n",
    "src_size_concrete = len(concrete_source_df_y)\n",
    "tgt_size_concrete = len(concrete_tgt_df_y)\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Transfer Learning specifications #########################\n",
    "src_idx = np.arange(start=0, stop=(src_size_concrete - 1), step=1)\n",
    "tgt_idx = np.arange(start=src_size_concrete, stop=((src_size_concrete + tgt_size_concrete)-1), step=1)\n",
    "\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Two-Stage TrAdaboost.R2: 14.541708818834294\n",
      "R^2 of TrAdaboostR2: 0.6380025091352669\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 #######################################\n",
    "\n",
    "model_TwoTrAda_concrete = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 1000, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_concrete.fit(concrete_np_train_X, concrete_np_train_y_list, src_idx, tgt_idx)\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_concrete = model_TwoTrAda_concrete.predict(concrete_np_test_X)\n",
    "mse_TwoTrAda_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_TwoTrAda_concrete))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_concrete)\n",
    "\n",
    "r2_score_TwoTrAda_concrete = pearsonr(concrete_np_test_y_list, y_pred_TwoTrAda_concrete)\n",
    "r2_score_TwoTrAda_concrete = (r2_score_TwoTrAda_concrete[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_concrete)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 14.14134604172718\n",
      "R^2 of TrAdaboostR2: 0.6617768705437826\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer LearningL #####################################################\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_concrete = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_concrete.fit(concrete_np_train_X, concrete_np_train_y_list)\n",
    "\n",
    "y_pred_ada_concrete = model_Ada_concrete.predict(concrete_np_test_X)\n",
    "mse_Ada_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_ada_concrete))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_concrete)\n",
    "\n",
    "r2_score_Ada_concrete = pearsonr(concrete_np_test_y_list, y_pred_ada_concrete)\n",
    "r2_score_Ada_concrete = (r2_score_Ada_concrete[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_concrete)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Adaboost.R2: 24.871232748488882\n",
      "R^2 of TrAdaboostR2: 0.4313630624407841\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 #####################################################\n",
    "print(\"Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_concrete = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_concrete.fit(concrete_tgt_df_X, concrete_tgt_df_y)\n",
    "\n",
    "y_pred_ada_concrete = model_Ada_concrete.predict(concrete_np_test_X)\n",
    "mse_Ada_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_ada_concrete))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_concrete)\n",
    "\n",
    "r2_score_Ada_concrete = pearsonr(concrete_np_test_y_list, y_pred_ada_concrete)\n",
    "r2_score_Ada_concrete = (r2_score_Ada_concrete[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_concrete)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Mean Matching\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 24.695170122194522\n",
      "R^2 of TrAdaboostR2: 0.2077368001621871\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Kernel Mean Matching #######################################\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_KMM_concrete = KMM(get_estimator = get_estimator)\n",
    "model_KMM_concrete.fit(concrete_np_train_X, concrete_np_train_y_list, src_idx, tgt_idx)\n",
    "\n",
    "y_pred_KMM_concrete = model_KMM_concrete.predict(concrete_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_KMM_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_KMM_concrete))\n",
    "print(\"RMSE of KMM:\", mse_KMM_concrete)\n",
    "\n",
    "r2_score_KMM_concrete = pearsonr(concrete_np_test_y_list, y_pred_KMM_concrete)\n",
    "r2_score_KMM_concrete = (r2_score_KMM_concrete[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_KMM_concrete)\n",
    "\n",
    "#model_KMM_concrete.weights_   #To get the weights of the algorithm\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 11.258851937503154\n",
      "R^2 of TrAdaboostR2: 0.6895184459321161\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_concrete = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_concrete.fit(concrete_np_train_X, concrete_np_train_y_list)\n",
    "\n",
    "y_pred_GBR_concrete = model_GBR_concrete.predict(concrete_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_GBR_concrete))\n",
    "print(\"RMSE of KMM:\", mse_GBR_concrete)\n",
    "\n",
    "r2_score_GBR_concrete = pearsonr(concrete_np_test_y_list, y_pred_GBR_concrete)\n",
    "r2_score_GBR_concrete = (r2_score_GBR_concrete[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_concrete)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of KMM: 23.41655933034992\n",
      "R^2 of TrAdaboostR2: 0.5650871647106431\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_concrete = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_concrete.fit(concrete_tgt_df_X, concrete_tgt_df_y)\n",
    "\n",
    "y_pred_GBR_concrete = model_GBR_concrete.predict(concrete_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_GBR_concrete))\n",
    "print(\"RMSE of KMM:\", mse_GBR_concrete)\n",
    "\n",
    "r2_score_GBR_concrete = pearsonr(concrete_np_test_y_list, y_pred_GBR_concrete)\n",
    "r2_score_GBR_concrete = (r2_score_GBR_concrete[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_concrete)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Two-Stage TrAdaboost.R2: 20.34869140770156\n",
      "R^2 of TrAdaboostR2: 0.3977255550270938\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################ Transformed TrAdaBoost.R2 #############################################\n",
    "\n",
    "weights_KMM = model_KMM_concrete.weights_\n",
    "\n",
    "val_mean = np.mean(weights_KMM)\n",
    "weights_KMM = np.append(weights_KMM, val_mean)\n",
    "\n",
    "concrete_source_df_X_trans = concrete_source_df_X.apply(lambda concrete_source_df_X: concrete_source_df_X * weights_KMM)\n",
    "#concrete_source_df_X.multiply(weights_KMM, axis=0)\n",
    "\n",
    "# concrete_np_train_X_trans = concrete_source_df_X_trans.to_numpy()\n",
    "\n",
    "concrete_X_df = pd.concat([concrete_tgt_df_X, concrete_source_df_X_trans], ignore_index=True)\n",
    "concrete_y_df = pd.concat([concrete_tgt_df_y, concrete_source_df_y], ignore_index=True)\n",
    "\n",
    "concrete_np_train_X = concrete_X_df.to_numpy()\n",
    "concrete_np_train_y = concrete_y_df.to_numpy()\n",
    "\n",
    "concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "\n",
    "\n",
    "# print(concrete_np_train_y_list.shape, concrete_np_train_X_trans.shape)\n",
    "\n",
    "##################################################################\n",
    "model_TwoTrAda_concrete = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_concrete.fit(concrete_np_train_X, concrete_np_train_y_list, src_idx, tgt_idx)\n",
    "\n",
    "print(\"Transformed Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_concrete = model_TwoTrAda_concrete.predict(concrete_np_test_X)\n",
    "\n",
    "mse_TwoTrAda_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_TwoTrAda_concrete))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_concrete)\n",
    "\n",
    "r2_score_TwoTrAda_concrete = pearsonr(concrete_np_test_y_list, y_pred_TwoTrAda_concrete)\n",
    "r2_score_TwoTrAda_concrete = (r2_score_TwoTrAda_concrete[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_concrete)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "RMSE of STrAdaboostR2: 12.86329037846698\n",
      "R^2 of STrAdaboostR2: 0.7153926855970645\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "sample_size = [len(concrete_tgt_df_X), len(concrete_source_df_X)]\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "model_stradaboost_concrete = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                    n_estimators = n_estimators, sample_size = sample_size,\n",
    "                    steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "model_stradaboost_concrete.fit(concrete_np_train_X, concrete_np_train_y_list)\n",
    "y_pred_stradaboost_concrete = model_stradaboost_concrete.predict(concrete_np_test_X)\n",
    "\n",
    "mse_stradaboost_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_stradaboost_concrete))\n",
    "print(\"RMSE of STrAdaboostR2:\", mse_stradaboost_concrete)\n",
    "\n",
    "r2_score_stradaboost_concrete = pearsonr(concrete_np_test_y_list, y_pred_stradaboost_concrete)\n",
    "r2_score_stradaboost_concrete = (r2_score_stradaboost_concrete[0])**2\n",
    "print(\"R^2 of STrAdaboostR2:\", r2_score_stradaboost_concrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "# from newtwoStage_TrAdaBoostR2 import TradaboostRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Dropout, Flatten\n",
    "from keras import optimizers, utils, initializers, regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler #Importing the StandardScaler\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "################# Geo plotting libraries\n",
    "import geopandas as gdp\n",
    "from matplotlib.colors import ListedColormap\n",
    "# import geoplot as glpt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "import statistics\n",
    "\n",
    "from matplotlib.transforms import Affine2D\n",
    "import folium\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "###################################################################################################################################################################\n",
    "STrAdaBoost_RMSE_NOx = [84.49069754636324, 83.19323870128466, 81.27928359120179, 82.18747206693598, 82.60804181502738, 82.65985343387109,\n",
    "81.93233750015905, 83.74998065696522, 82.92239432705983, 84.71932508116717]\n",
    "TrAdaBoost_RMSE_NOx = [76.29870110031176, 90.49733765158976, 88.66740065772586, 76.61069182772832, 89.19167720613721, 76.63572940793705,\n",
    "75.91621027222305, 88.91209884411252, 75.66965212493261,76.56390041476169]\n",
    "AdaBoost_RMSE_NOx = [90.63932170294021, 87.15426790901572, 88.34473432945258, 86.93531815065907, 86.09325821106664, 90.33874900883123,\n",
    "89.75706293974721, 89.18255026677808, 86.79257145189278,88.15379488581348]\n",
    "\n",
    "STrAdaBoost_RMSE_NO2 = [24.283690808360245, 24.127661779305818, 23.795924043958564, 23.86071279600051, 23.842607206027456, 23.678043189310404,\n",
    "24.832202009871946, 24.72540998123888, 23.952057769016328, 24.499915240375014]\n",
    "TrAdaBoost_RMSE_NO2 = [29.967565846373816, 29.918410405444156, 30.07324513362625, 30.057292629368256, 30.15716067372586, 30.099997992631963,\n",
    "30.169099696332275, 30.116280516373376, 29.989850789314207, 30.29776937245375]\n",
    "AdaBoost_RMSE_NO2 = [27.587178104589203, 27.64482357816312, 26.6654992063022, 26.949370826873007, 27.357169025084616, 27.438634766666453,\n",
    "28.137109920599684, 27.36063648100872, 27.929103697001345, 28.52297816586722]\n",
    "\n",
    "STrAdaBoost_RMSE_O3 = [173.64151805705194, 173.6334619111963, 173.65662665726717, 174.1308577850406, 174.0310122302578, 174.07118389774956, 173.3810950553901,\n",
    "173.7619765646141, 173.89517540044486, 173.71213163191527]\n",
    "TrAdaBoost_RMSE_O3 = [171.6515413016132, 170.14551538005634, 170.69377563176536, 170.23152266767838, 172.05586024289434, 169.06705817239322, 173.20665423910825,\n",
    "172.54867998954228, 170.27823788650394, 170.2347615205619]\n",
    "AdaBoost_RMSE_O3 = [180.68119379123922, 177.1889644285649, 178.03999086375444, 177.73683263644602, 178.61357778268032, 178.53935080389707, 180.62098338916542,\n",
    "180.12605079594596, 179.4711714920254, 182.32380075254858]\n",
    "\n",
    "# STrAdaBoost_RMSE_NOx_Norm = [116.56207487781757, 117.12744898440695, 122.21001928176337, 116.02213691302707, 115.01356572936842, 117.82206454755801, 116.33390399761493,\n",
    "# 117.29859060209448, 117.15492417635203, 118.52620461003417]\n",
    "# TrAdaBoost_RMSE_NOx = [135.32110275619965, 134.39566747250927, 134.72552610715496, 133.4738476573543, 136.75743147426928, 136.6462951739915, 134.9491286623907,\n",
    "# 134.6030488331259, 134.27917844884996,135.24583900366477]\n",
    "# AdaBoost_RMSE_NOx = [87.51229327934197, 88.32432900140913, 88.08834819883502, 87.52912955139539, 88.6824868839292, 88.11432378088877, 86.51542456695174,\n",
    "# 88.2780125086002, 88.42890140495514, 85.80770659201272]\n",
    "#\n",
    "# STrAdaBoost_RMSE_NO2_Norm = [45.623681500346684, 45.627289088592484, 45.6410716215836, 45.950142322965014, 45.746781764008034, 45.51898933766781, 46.416842540407266,\n",
    "# 45.61379839353198, 45.46275490362647, 45.48011193000623]\n",
    "# TrAdaBoost_RMSE_NO2 = [44.74193223206197, 44.65640007857625, 44.7477254703826, 44.74501305364314, 44.80431951909328, 44.74216239294229, 44.65573169849547,\n",
    "# 44.81223332738691, 44.59243606389392, 44.66763885614316]\n",
    "# AdaBoost_RMSE_NO2 = [27.386627364748396, 27.91727196005653, 27.064526060877395, 26.934118784173428, 28.273217386873775, 27.57585539705687, 27.490141344356058,\n",
    "# 28.16892932308915, 27.31365610561806, 27.90207530790275]\n",
    "\n",
    "############################################################################################################################################################\n",
    "\n",
    "methods = ['S-TrAdaBoost.R2', 'two-stage TrAdaBoost.R2', 'AdaBoost.R2']\n",
    "\n",
    "# STrAdaBoost_R2_val = (max(STrAdaBoost_R2) - min(STrAdaBoost_R2))/2\n",
    "# AdaBoost_R2_val = (max(AdaBoost_R2) - min(AdaBoost_R2))/2\n",
    "# TrAdaBoost_R2_val = (max(TrAdaBoost_R2) - min(TrAdaBoost_R2))/2\n",
    "\n",
    "STrAdaBoost_std1 = statistics.pstdev(STrAdaBoost_RMSE_NOx)\n",
    "TrAdaBoost_std1 = statistics.pstdev(TrAdaBoost_RMSE_NOx)\n",
    "AdaBoost_std1 = statistics.pstdev(AdaBoost_RMSE_NOx)\n",
    "\n",
    "STrAdaBoost_std2 = statistics.pstdev(STrAdaBoost_RMSE_NO2)\n",
    "TrAdaBoost_std2 = statistics.pstdev(TrAdaBoost_RMSE_NO2)\n",
    "AdaBoost_std2 = statistics.pstdev(AdaBoost_RMSE_NO2)\n",
    "\n",
    "STrAdaBoost_std3 = statistics.pstdev(STrAdaBoost_RMSE_O3)\n",
    "TrAdaBoost_std3 = statistics.pstdev(TrAdaBoost_RMSE_O3)\n",
    "AdaBoost_std3 = statistics.pstdev(AdaBoost_RMSE_O3)\n",
    "\n",
    "# STrAdaBoost_std3 = statistics.pstdev(STrAdaBoost_R2_NOx_Norm)\n",
    "# TrAdaBoost_std3 = statistics.pstdev(TrAdaBoost_R2_NOx_Norm)\n",
    "# AdaBoost_std3 = statistics.pstdev(AdaBoost_R2_NOx_Norm)\n",
    "#\n",
    "# STrAdaBoost_std4 = statistics.pstdev(STrAdaBoost_R2_NOx_Norm)\n",
    "# TrAdaBoost_std4 = statistics.pstdev(TrAdaBoost_R2_NOx_Norm)\n",
    "# AdaBoost_std4 = statistics.pstdev(AdaBoost_R2_NOx_Norm)\n",
    "\n",
    "\n",
    "y1 = [mean(STrAdaBoost_RMSE_NOx), mean(TrAdaBoost_RMSE_NOx), mean(AdaBoost_RMSE_NOx)]\n",
    "dy1 = [STrAdaBoost_std1, TrAdaBoost_std1, AdaBoost_std1]\n",
    "\n",
    "\n",
    "y2 = [mean(STrAdaBoost_RMSE_NO2), mean(TrAdaBoost_RMSE_NO2), mean(AdaBoost_RMSE_NO2)]\n",
    "dy2 = [STrAdaBoost_std2, TrAdaBoost_std2, AdaBoost_std2]\n",
    "\n",
    "y3 = [mean(STrAdaBoost_RMSE_O3), mean(TrAdaBoost_RMSE_O3), mean(AdaBoost_RMSE_O3)]\n",
    "dy3 = [STrAdaBoost_std3, TrAdaBoost_std3, AdaBoost_std3]\n",
    "\n",
    "# y3 = [mean(STrAdaBoost_R2_NOx_Norm), mean(TrAdaBoost_R2_NOx_Norm), mean(AdaBoost_R2_NOx_Norm)]\n",
    "# dy3 = [STrAdaBoost_std3, TrAdaBoost_std3, AdaBoost_std3]\n",
    "#\n",
    "# y4 = [mean(STrAdaBoost_R2_NO2_Norm), mean(TrAdaBoost_R2_NO2_Norm), mean(AdaBoost_R2_NO2_Norm)]\n",
    "# dy4 = [STrAdaBoost_std4, TrAdaBoost_std4, AdaBoost_std4]\n",
    "\n",
    "plus = mlines.Line2D([], [], marker='P', color='maroon', linestyle='None',\n",
    "                          markersize = 20, label='NO2')\n",
    "circle = mlines.Line2D([], [], marker='o', color='black', linestyle='None',\n",
    "                          markersize = 20, label='NOx')\n",
    "triangle = mlines.Line2D([], [], marker='v', color='blue', linestyle='None',\n",
    "                          markersize = 20, label='O3')\n",
    "\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "\n",
    "print(dy1)\n",
    "print(dy2)\n",
    "print(dy3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# trans1 = Affine2D().translate(-0.025, 0.0) + ax.transData\n",
    "# trans2 = Affine2D().translate(+0.025, 0.0) + ax.transData\n",
    "# trans3 = Affine2D().translate(+0.05, 0.0) + ax.transData\n",
    "# trans4 = Affine2D().translate(-1.5, 0.0) + ax.transData\n",
    "\n",
    "# er1 = ax.errorbar(x, y1, yerr = dy1, marker = \"o\", linestyle = \"None\", transform = trans1, elinewidth = 10, markersize = 20)\n",
    "# er2 = ax.errorbar(x, y2, yerr = dy2, marker = \"s\", linestyle = \"None\", transform = trans2, elinewidth = 6, markersize = 10)\n",
    "# er3 = ax.errorbar(x, y3, yerr = dy3, marker = \"o\", linestyle = \"None\", transform = trans3)\n",
    "# er4 = ax.errorbar(x, y4, yerr = dy4, marker = \"o\", linestyle = \":\", transform = trans4)\n",
    "\n",
    "\n",
    "plt.errorbar(x, y1, yerr = dy1, fmt='o', color='black', ecolor='black', elinewidth = 10, markersize = 20) #capsize=0)\n",
    "plt.errorbar(x, y2, yerr = dy2, fmt='P', color='maroon', ecolor='maroon', elinewidth = 10, markersize = 20)\n",
    "plt.errorbar(x, y3, yerr = dy3, fmt='v', color='blue', ecolor='blue', elinewidth = 10, markersize = 20) #capsize=0)\n",
    "# plt.xticks(x)\n",
    "plt.xticks(np.arange(3), ('S-TrAdaBoost.R2', 'two-stage TrAdaBoost.R2', 'AdaBoost.R2'), fontsize = 32)\n",
    "plt.yticks(fontsize = 30)\n",
    "plt.ylabel(\"RMS Error\", fontsize = 36)\n",
    "# plt.title('Mean RMSE for methodologies with Standard deviation error bars', fontsize=12)\n",
    "plt.legend(handles= [plus, circle, triangle], fontsize = 20, loc= 'center left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(x, y, yerr=dy, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "# ax.yticks(np.arange(0.25, 0.40, 0.02))\n",
    "# ax.set_ylabel('Coefficient of Thermal Expansion ($\\degree C^{-1}$)')\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(methods)\n",
    "# ax.set_title('Coefficent of Thermal Expansion (CTE) of Three Metals')\n",
    "# ax.yaxis.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing Data\n",
      "(506, 14)\n",
      "Target Set:  (186, 13)\n",
      "Source Set:  (155, 13)\n",
      "Test Set:  (165, 13)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "######################################################## Housing ################################################################\n",
    "## 'nox' found to be correlated at 0.4 :: [0.385 - 0.871] :: 50\n",
    "#################################################################################################################################\n",
    "HousingData_df = pd.read_csv('UCI_regression/BostonHousing/BostonHousing.csv') \n",
    "print(\"Housing Data\")\n",
    "print(HousingData_df.shape)\n",
    "\n",
    "drop_col_housing = ['nox']\n",
    "housing_tgt_df = HousingData_df.loc[(HousingData_df['nox'] > 0.475) & (HousingData_df['nox'] <= 0.600)]\n",
    "housing_tgt_df = housing_tgt_df.drop(drop_col_housing, axis = 1)\n",
    "housing_tgt_df = housing_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",housing_tgt_df.shape)\n",
    "\n",
    "\n",
    "housing_source_df = HousingData_df.loc[(HousingData_df['nox'] <= 0.475)]\n",
    "housing_source_df = housing_source_df.drop(drop_col_housing, axis = 1)\n",
    "housing_source_df = housing_source_df.reset_index(drop=True)\n",
    "print(\"Source Set: \",housing_source_df.shape)\n",
    "\n",
    "\n",
    "housing_test_df = HousingData_df.loc[(HousingData_df['nox'] > 0.600)]\n",
    "housing_test_df = housing_test_df.drop(drop_col_housing, axis = 1)\n",
    "housing_test_df = housing_test_df.reset_index(drop=True)\n",
    "print(\"Test Set: \",housing_test_df.shape)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_column_housing = ['medv']\n",
    "\n",
    "housing_tgt_df_y = housing_tgt_df[target_column_housing]\n",
    "housing_tgt_df_X = housing_tgt_df.drop(target_column_housing, axis = 1)\n",
    "\n",
    "housing_source_df_y = housing_source_df[target_column_housing]\n",
    "housing_source_df_X = housing_source_df.drop(target_column_housing, axis = 1)\n",
    "\n",
    "housing_test_df_y = housing_test_df[target_column_housing]\n",
    "housing_test_df_X = housing_test_df.drop(target_column_housing, axis = 1)\n",
    "\n",
    "############## Merging the datasets ##########################################\n",
    "housing_X_df = pd.concat([housing_tgt_df_X, housing_source_df_X], ignore_index=True)\n",
    "housing_y_df = pd.concat([housing_tgt_df_y, housing_source_df_y], ignore_index=True)\n",
    "\n",
    "housing_np_train_X = housing_X_df.to_numpy()\n",
    "housing_np_train_y = housing_y_df.to_numpy()\n",
    "\n",
    "housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "\n",
    "src_size_housing = len(housing_source_df_y)\n",
    "tgt_size_housing = len(housing_tgt_df_y)\n",
    "\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Transfer Learning specifications for Housing #########################################\n",
    "src_idx_housing = np.arange(start=0, stop=(src_size_housing - 1), step=1)\n",
    "tgt_idx_housing = np.arange(start=src_size_housing, stop=((src_size_housing + tgt_size_housing)-1), step=1)\n",
    "\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Two-Stage TrAdaboost.R2: 7.884293455585843\n",
      "R^2 of TrAdaboostR2: 0.4805068962601643\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Housing #######################################\n",
    "\n",
    "model_TwoTrAda_housing = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 1000, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_housing.fit(housing_np_train_X, housing_np_train_y_list, src_idx_housing, tgt_idx_housing)\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_housing = model_TwoTrAda_housing.predict(housing_np_test_X)\n",
    "mse_TwoTrAda_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_TwoTrAda_housing))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_housing)\n",
    "\n",
    "r2_score_TwoTrAda_housing = pearsonr(housing_np_test_y_list, y_pred_TwoTrAda_housing)\n",
    "r2_score_TwoTrAda_housing = (r2_score_TwoTrAda_housing[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_housing)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 7.910660690028172\n",
      "R^2 of TrAdaboostR2: 0.4786809614921828\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer LearningL Housing #####################################################\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_housing = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_housing.fit(housing_np_train_X, housing_np_train_y_list)\n",
    "\n",
    "y_pred_ada_housing = model_Ada_housing.predict(housing_np_test_X)\n",
    "mse_Ada_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_ada_housing))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_housing)\n",
    "\n",
    "r2_score_Ada_housing = pearsonr(housing_np_test_y_list, y_pred_ada_housing)\n",
    "r2_score_Ada_housing = (r2_score_Ada_housing[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_housing)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Adaboost.R2: 8.293328796156434\n",
      "R^2 of TrAdaboostR2: 0.4136328886364334\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Housing #####################################################\n",
    "print(\"Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_housing = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_housing.fit(housing_tgt_df_X, housing_tgt_df_y)\n",
    "\n",
    "y_pred_ada_housing = model_Ada_housing.predict(housing_np_test_X)\n",
    "mse_Ada_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_ada_housing))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_housing)\n",
    "\n",
    "r2_score_Ada_housing = pearsonr(housing_np_test_y_list, y_pred_ada_housing)\n",
    "r2_score_Ada_housing = (r2_score_Ada_housing[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_housing)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Mean Matching\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 8.583829778573469\n",
      "R^2 of TrAdaboostR2: 0.369751845685946\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Kernel Mean Matching Housing #######################################\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_KMM_housing = KMM(get_estimator = get_estimator)\n",
    "model_KMM_housing.fit(housing_np_train_X, housing_np_train_y_list, src_idx_housing, tgt_idx_housing)\n",
    "\n",
    "y_pred_KMM_housing = model_KMM_housing.predict(housing_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_KMM_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_KMM_housing))\n",
    "print(\"RMSE of KMM:\", mse_KMM_housing)\n",
    "\n",
    "r2_score_KMM_housing = pearsonr(housing_np_test_y_list, y_pred_KMM_housing)\n",
    "r2_score_KMM_housing = (r2_score_KMM_housing[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_KMM_housing)\n",
    "\n",
    "#model_KMM_concrete.weights_   #To get the weights of the algorithm\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################### Gradient Boosting Regression Transfer Learning Housing #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_housing = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_housing.fit(housing_np_train_X, housing_np_train_y_list)\n",
    "\n",
    "y_pred_GBR_housing = model_GBR_housing.predict(housing_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_GBR_housing))\n",
    "print(\"RMSE of KMM:\", mse_GBR_housing)\n",
    "\n",
    "r2_score_GBR_housing = pearsonr(housing_np_test_y_list, y_pred_GBR_housing)\n",
    "r2_score_GBR_housing = (r2_score_GBR_housing[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_housing)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of KMM: 7.858297178868333\n",
      "R^2 of TrAdaboostR2: 0.4850629881108619\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Housing #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_housing = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_housing.fit(housing_tgt_df_X, housing_tgt_df_y)\n",
    "\n",
    "y_pred_GBR_housing = model_GBR_housing.predict(housing_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_GBR_housing))\n",
    "print(\"RMSE of KMM:\", mse_GBR_housing)\n",
    "\n",
    "r2_score_GBR_housing = pearsonr(housing_np_test_y_list, y_pred_GBR_housing)\n",
    "r2_score_GBR_housing = (r2_score_GBR_housing[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_housing)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Transformed Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Two-Stage TrAdaboost.R2: 8.83919577983453\n",
      "R^2 of TrAdaboostR2: 0.32458544508387793\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################ Transformed TrAdaBoost.R2 Housing #############################################\n",
    "\n",
    "weights_KMM = model_KMM_housing.weights_\n",
    "\n",
    "val_mean = np.mean(weights_KMM)\n",
    "weights_KMM = np.append(weights_KMM, val_mean)\n",
    "\n",
    "housing_source_df_X_trans = housing_source_df_X.apply(lambda housing_source_df_X: housing_source_df_X * weights_KMM)\n",
    "#concrete_source_df_X.multiply(weights_KMM, axis=0)\n",
    "\n",
    "# concrete_np_train_X_trans = concrete_source_df_X_trans.to_numpy()\n",
    "\n",
    "housing_X_df = pd.concat([housing_tgt_df_X, housing_source_df_X_trans], ignore_index=True)\n",
    "housing_y_df = pd.concat([housing_tgt_df_y, housing_source_df_y], ignore_index=True)\n",
    "\n",
    "housing_np_train_X = housing_X_df.to_numpy()\n",
    "housing_np_train_y = housing_y_df.to_numpy()\n",
    "\n",
    "housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "\n",
    "# print(concrete_np_train_y_list.shape, concrete_np_train_X_trans.shape)\n",
    "\n",
    "##################################################################\n",
    "model_TwoTrAda_housing = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_housing.fit(housing_np_train_X, housing_np_train_y_list, src_idx_housing, tgt_idx_housing)\n",
    "\n",
    "print(\"Transformed Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_housing = model_TwoTrAda_housing.predict(housing_np_test_X)\n",
    "\n",
    "mse_TwoTrAda_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_TwoTrAda_housing))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_housing)\n",
    "\n",
    "r2_score_TwoTrAda_housing = pearsonr(housing_np_test_y_list, y_pred_TwoTrAda_housing)\n",
    "r2_score_TwoTrAda_housing = (r2_score_TwoTrAda_housing[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_housing)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "RMSE of STrAdaboostR2: 7.965035134947645\n",
      "R^2 of STrAdaboostR2: 0.48541805750622513\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Housing ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "sample_size = [len(housing_tgt_df_X), len(housing_source_df_X)]\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "model_stradaboost_housing = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                    n_estimators = n_estimators, sample_size = sample_size,\n",
    "                    steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "model_stradaboost_housing.fit(housing_np_train_X, housing_np_train_y_list)\n",
    "y_pred_stradaboost_housing = model_stradaboost_housing.predict(housing_np_test_X)\n",
    "\n",
    "mse_stradaboost_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_stradaboost_housing))\n",
    "print(\"RMSE of STrAdaboostR2:\", mse_stradaboost_housing)\n",
    "\n",
    "r2_score_stradaboost_housing = pearsonr(housing_np_test_y_list, y_pred_stradaboost_housing)\n",
    "r2_score_stradaboost_housing = (r2_score_stradaboost_housing[0])**2\n",
    "print(\"R^2 of STrAdaboostR2:\", r2_score_stradaboost_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Input data is:  (392, 8)\n",
      "Target Set:  (157, 7)\n",
      "Source Set:  (119, 7)\n",
      "Test Set:  (116, 7)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "######################################################## Automobile ################################################################\n",
    "## horsepower column has correlation 0.4 :: [46 - 230] :: 30\n",
    "#################################################################################################################################\n",
    "dropcol_initial_auto = ['name']\n",
    "AutoData_df = pd.read_csv('UCI_regression/MPG/Auto.csv') ## horsepower column has correlation 0.4 :: [46 - 230] :: 30\n",
    "AutoData_df = AutoData_df.drop(dropcol_initial_auto, axis = 1)\n",
    "print(\"The shape of the Input data is: \", AutoData_df.shape)\n",
    "\n",
    "drop_col_auto = ['horsepower']\n",
    "\n",
    "auto_tgt_df = AutoData_df.loc[(AutoData_df['horsepower'] > 80) & (AutoData_df['horsepower'] <= 110)]\n",
    "auto_tgt_df = auto_tgt_df.drop(drop_col_auto, axis = 1)\n",
    "auto_tgt_df = auto_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",auto_tgt_df.shape)\n",
    "\n",
    "auto_source_df = AutoData_df.loc[(AutoData_df['horsepower'] <= 80)]\n",
    "auto_source_df = auto_source_df.drop(drop_col_auto, axis = 1)\n",
    "auto_source_df = auto_source_df.reset_index(drop=True)\n",
    "print(\"Source Set: \",auto_source_df.shape)\n",
    "\n",
    "auto_test_df = AutoData_df.loc[(AutoData_df['horsepower'] > 110)]\n",
    "auto_test_df = auto_test_df.drop(drop_col_auto, axis = 1)\n",
    "auto_test_df = auto_test_df.reset_index(drop=True)\n",
    "print(\"Test Set: \",auto_test_df.shape)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_column_auto = ['mpg']\n",
    "\n",
    "auto_tgt_df_y = auto_tgt_df[target_column_auto]\n",
    "auto_tgt_df_X = auto_tgt_df.drop(target_column_auto, axis = 1)\n",
    "\n",
    "auto_source_df_y = auto_source_df[target_column_auto]\n",
    "auto_source_df_X = auto_source_df.drop(target_column_auto, axis = 1)\n",
    "\n",
    "auto_test_df_y = auto_test_df[target_column_auto]\n",
    "auto_test_df_X = auto_test_df.drop(target_column_auto, axis = 1)\n",
    "\n",
    "############## Merging the datasets ##########################################\n",
    "auto_X_df = pd.concat([auto_tgt_df_X, auto_source_df_X], ignore_index=True)\n",
    "auto_y_df = pd.concat([auto_tgt_df_y, auto_source_df_y], ignore_index=True)\n",
    "\n",
    "auto_np_train_X = auto_X_df.to_numpy()\n",
    "auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "\n",
    "src_size_auto = len(auto_source_df_y)\n",
    "tgt_size_auto = len(auto_tgt_df_y)\n",
    "\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## Transfer Learning specifications for Auto #########################################\n",
    "src_idx_auto = np.arange(start=0, stop=(src_size_auto - 1), step=1)\n",
    "tgt_idx_auto = np.arange(start=src_size_auto, stop=((src_size_auto + tgt_size_auto)-1), step=1)\n",
    "\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Two-Stage TrAdaboost.R2: 4.670580347561752\n",
      "R^2 of TrAdaboostR2: 0.5324325755832334\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Auto #######################################\n",
    "\n",
    "model_TwoTrAda_auto = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 1000, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_auto.fit(auto_np_train_X, auto_np_train_y_list, src_idx_auto, tgt_idx_auto)\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_auto = model_TwoTrAda_auto.predict(auto_np_test_X)\n",
    "mse_TwoTrAda_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_TwoTrAda_auto))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_auto)\n",
    "\n",
    "r2_score_TwoTrAda_auto = pearsonr(auto_np_test_y_list, y_pred_TwoTrAda_auto)\n",
    "r2_score_TwoTrAda_auto = (r2_score_TwoTrAda_auto[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_auto)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 4.363924315238744\n",
      "R^2 of TrAdaboostR2: 0.6080438774797282\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer LearningL Auto #####################################################\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_auto = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_auto.fit(auto_np_train_X, auto_np_train_y_list)\n",
    "\n",
    "y_pred_ada_auto = model_Ada_auto.predict(auto_np_test_X)\n",
    "mse_Ada_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_ada_auto))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_auto)\n",
    "\n",
    "r2_score_Ada_auto = pearsonr(auto_np_test_y_list, y_pred_ada_auto)\n",
    "r2_score_Ada_auto = (r2_score_Ada_auto[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_auto)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Adaboost.R2: 4.420810660355685\n",
      "R^2 of TrAdaboostR2: 0.5502620404767535\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Auto #####################################################\n",
    "print(\"Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_auto = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_auto.fit(auto_tgt_df_X, auto_tgt_df_y)\n",
    "\n",
    "y_pred_ada_auto = model_Ada_auto.predict(auto_np_test_X)\n",
    "mse_Ada_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_ada_auto))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_auto)\n",
    "\n",
    "r2_score_Ada_auto = pearsonr(auto_np_test_y_list, y_pred_ada_auto)\n",
    "r2_score_Ada_auto = (r2_score_Ada_auto[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_auto)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Mean Matching\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 4.111120791345881\n",
      "R^2 of TrAdaboostR2: 0.4065209586577796\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Kernel Mean Matching Auto #######################################\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_KMM_auto = KMM(get_estimator = get_estimator)\n",
    "model_KMM_auto.fit(auto_np_train_X, auto_np_train_y_list, src_idx_auto, tgt_idx_auto)\n",
    "\n",
    "y_pred_KMM_auto = model_KMM_auto.predict(auto_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_KMM_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_KMM_auto))\n",
    "print(\"RMSE of KMM:\", mse_KMM_auto)\n",
    "\n",
    "r2_score_KMM_auto = pearsonr(auto_np_test_y_list, y_pred_KMM_auto)\n",
    "r2_score_KMM_auto = (r2_score_KMM_auto[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_KMM_auto)\n",
    "\n",
    "#model_KMM_concrete.weights_   #To get the weights of the algorithm\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 6.382657961223332\n",
      "R^2 of TrAdaboostR2: 0.3405912128920165\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning Auto #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_auto = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_auto.fit(auto_np_train_X, auto_np_train_y_list)\n",
    "\n",
    "y_pred_GBR_auto = model_GBR_auto.predict(auto_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_GBR_auto))\n",
    "print(\"RMSE of KMM:\", mse_GBR_auto)\n",
    "\n",
    "r2_score_GBR_auto = pearsonr(auto_np_test_y_list, y_pred_GBR_auto)\n",
    "r2_score_GBR_auto = (r2_score_GBR_auto[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_auto)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of KMM: 6.200761352176353\n",
      "R^2 of TrAdaboostR2: 0.3313599754308558\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Auto #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_auto = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_auto.fit(auto_tgt_df_X, auto_tgt_df_y)\n",
    "\n",
    "y_pred_GBR_auto = model_GBR_auto.predict(auto_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_GBR_auto))\n",
    "print(\"RMSE of KMM:\", mse_GBR_auto)\n",
    "\n",
    "r2_score_GBR_auto = pearsonr(auto_np_test_y_list, y_pred_GBR_auto)\n",
    "r2_score_GBR_auto = (r2_score_GBR_auto[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_auto)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Transformed Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Two-Stage TrAdaboost.R2: 5.235239636298763\n",
      "R^2 of TrAdaboostR2: 0.37128819283084824\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################ Transformed TrAdaBoost.R2 Auto #############################################\n",
    "\n",
    "weights_KMM = model_KMM_auto.weights_\n",
    "\n",
    "val_mean = np.mean(weights_KMM)\n",
    "weights_KMM = np.append(weights_KMM, val_mean)\n",
    "\n",
    "auto_source_df_X_trans = auto_source_df_X.apply(lambda auto_source_df_X: auto_source_df_X * weights_KMM)\n",
    "#concrete_source_df_X.multiply(weights_KMM, axis=0)\n",
    "\n",
    "# concrete_np_train_X_trans = concrete_source_df_X_trans.to_numpy()\n",
    "\n",
    "auto_X_df = pd.concat([auto_tgt_df_X, auto_source_df_X_trans], ignore_index=True)\n",
    "auto_y_df = pd.concat([auto_tgt_df_y, auto_source_df_y], ignore_index=True)\n",
    "\n",
    "auto_np_train_X = auto_X_df.to_numpy()\n",
    "auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "\n",
    "# print(concrete_np_train_y_list.shape, concrete_np_train_X_trans.shape)\n",
    "\n",
    "##################################################################\n",
    "model_TwoTrAda_auto = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_auto.fit(auto_np_train_X, auto_np_train_y_list, src_idx_auto, tgt_idx_auto)\n",
    "\n",
    "print(\"Transformed Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_auto = model_TwoTrAda_auto.predict(auto_np_test_X)\n",
    "\n",
    "mse_TwoTrAda_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_TwoTrAda_auto))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_Two900TrAda_auto)\n",
    "\n",
    "r2_score_TwoTrAda_auto = pearsonr(auto_np_test_y_list, y_pred_TwoTrAda_auto)\n",
    "r2_score_TwoTrAda_auto = (r2_score_TwoTrAda_auto[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_auto)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "RMSE of STrAdaboostR2: 4.819470738317646\n",
      "R^2 of STrAdaboostR2: 0.617582863408081\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Auto ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "sample_size = [len(auto_tgt_df_X), len(auto_source_df_X)]\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "model_stradaboost_auto = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                    n_estimators = n_estimators, sample_size = sample_size,\n",
    "                    steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "model_stradaboost_auto.fit(auto_np_train_X, auto_np_train_y_list)\n",
    "y_pred_stradaboost_auto = model_stradaboost_auto.predict(auto_np_test_X)\n",
    "\n",
    "mse_stradaboost_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_stradaboost_auto))\n",
    "print(\"RMSE of STrAdaboostR2:\", mse_stradaboost_auto)\n",
    "\n",
    "r2_score_stradaboost_auto = pearsonr(auto_np_test_y_list, y_pred_stradaboost_auto)\n",
    "r2_score_stradaboost_auto = (r2_score_stradaboost_auto[0])**2\n",
    "print(\"R^2 of STrAdaboostR2:\", r2_score_stradaboost_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################ Ailerons ###############################################\n",
    "target_ailerons = ['goal']\n",
    "colnames_ailerons = ['climbRate', 'Sgz', 'p', 'q', 'curPitch', 'curRoll', 'absRoll', 'diffClb', 'diffRollRate', 'diffDiffClb', 'SeTime1',\n",
    "            'SeTime2', 'SeTime3', 'SeTime4', 'SeTime5', 'SeTime6', 'SeTime7', 'SeTime8', 'SeTime9', 'SeTime10', 'SeTime11', 'SeTime12', \n",
    "            'SeTime13', 'SeTime14', 'diffSeTime1', 'diffSeTime2', 'diffSeTime3', 'diffSeTime4', 'diffSeTime5', 'diffSeTime6', 'diffSeTime7',\n",
    "            'diffSeTime8', 'diffSeTime9', 'diffSeTime10', 'diffSeTime11', 'diffSeTime12', 'diffSeTime13', 'diffSeTime14', 'alpha', 'Se', 'goal']\n",
    "AileronsData_df_train = pd.read_csv('UCI_regression/Ailerons/ailerons.data', header = None, names = colnames_ailerons) \n",
    "print(\"Ailerons Data\")\n",
    "# print(AileronsData_df_train.shape)\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "AileronsData_df_test = pd.read_csv('UCI_regression/Ailerons/ailerons.test', header = None, names = colnames_ailerons) \n",
    "# print(AileronsData_df_test.shape)\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "AileronsData_df_source, AileronsData_df_tgt = train_test_split(AileronsData_df_train, test_size = 0.05) ## test_size = tgt size\n",
    "# print(AileronsData_df_tgt.shape, AileronsData_df_source.shape, AileronsData_df_test.shape)\n",
    "\n",
    "AileronsData_df_train = AileronsData_df_train.reset_index(drop = True)\n",
    "\n",
    "AileronsData_df_tgt = AileronsData_df_tgt.reset_index(drop = True)\n",
    "AileronsData_df_source = AileronsData_df_source.reset_index(drop = True)\n",
    "print(\"Target Set: \", AileronsData_df_tgt.shape)\n",
    "print(\"Source Set: \", AileronsData_df_source.shape)\n",
    "print(\"Test Set: \", AileronsData_df_test.shape)\n",
    "\n",
    "\n",
    "AileronsData_df_test_y = AileronsData_df_test[target_ailerons]\n",
    "AileronsData_df_test_X = AileronsData_df_test.drop(target_ailerons, axis = 1)\n",
    "\n",
    "AileronsData_df_tgt_y = AileronsData_df_tgt[target_ailerons]\n",
    "AileronsData_df_tgt_X = AileronsData_df_tgt.drop(target_ailerons, axis = 1)\n",
    "\n",
    "AileronsData_df_source_y = AileronsData_df_source[target_ailerons]\n",
    "AileronsData_df_source_X = AileronsData_df_source.drop(target_ailerons, axis = 1)\n",
    "\n",
    "\n",
    "############## Merging the datasets #################\n",
    "ailerons_X_df = pd.concat([AileronsData_df_tgt_X, AileronsData_df_source_X], ignore_index=True)\n",
    "ailerons_y_df = pd.concat([AileronsData_df_tgt_y, AileronsData_df_source_y], ignore_index=True)\n",
    "\n",
    "ailerons_np_train_X = ailerons_X_df.to_numpy()\n",
    "ailerons_np_train_y = ailerons_y_df.to_numpy()\n",
    "\n",
    "ailerons_np_test_X = AileronsData_df_test_X.to_numpy()\n",
    "ailerons_np_test_y = AileronsData_df_test_y.to_numpy()\n",
    "\n",
    "ailerons_np_train_y_list = ailerons_np_train_y.ravel()\n",
    "ailerons_np_test_y_list = ailerons_np_test_y.ravel()\n",
    "\n",
    "src_size_ailerons = len(AileronsData_df_source_y)\n",
    "tgt_size_ailerons = len(AileronsData_df_tgt_y)\n",
    "\n",
    "\n",
    "# AileronsData_df_train_y = AileronsData_df_train['goal']\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Transfer Learning specifications #########################\n",
    "src_idx_ailerons = np.arange(start=0, stop=(src_size_ailerons - 1), step=1)\n",
    "tgt_idx_ailerons = np.arange(start=src_size_ailerons, stop=((src_size_ailerons + tgt_size_ailerons)-1), step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Ailerons #######################################\n",
    "\n",
    "model_TwoTrAda_ailerons = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 1000, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_ailerons.fit(ailerons_np_train_X, ailerons_np_train_y_list, src_idx_ailerons, tgt_idx_ailerons)\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_ailerons = model_TwoTrAda_ailerons.predict(ailerons_np_test_X)\n",
    "mse_TwoTrAda_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_TwoTrAda_ailerons))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_ailerons)\n",
    "\n",
    "r2_score_TwoTrAda_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_TwoTrAda_ailerons)\n",
    "r2_score_TwoTrAda_ailerons = (r2_score_TwoTrAda_ailerons[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_ailerons)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 0.00017449887580011638\n",
      "R^2 of TrAdaboostR2: 0.8129890343240704\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer LearningL Ailerons #####################################################\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_ailerons = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_ailerons.fit(ailerons_np_train_X, ailerons_np_train_y_list)\n",
    "\n",
    "y_pred_ada_ailerons = model_Ada_ailerons.predict(ailerons_np_test_X)\n",
    "mse_Ada_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_ada_ailerons))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_ailerons)\n",
    "\n",
    "r2_score_Ada_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_ada_ailerons)\n",
    "r2_score_Ada_ailerons = (r2_score_Ada_ailerons[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_ailerons)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Adaboost.R2: 0.0002211541893347213\n",
      "R^2 of TrAdaboostR2: 0.6992253917998658\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Ailerons #####################################################\n",
    "print(\"Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_ailerons = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_ailerons.fit(AileronsData_df_tgt_X, AileronsData_df_tgt_y)\n",
    "\n",
    "y_pred_ada_ailerons = model_Ada_ailerons.predict(ailerons_np_test_X)\n",
    "mse_Ada_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_ada_ailerons))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_ailerons)\n",
    "\n",
    "r2_score_Ada_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_ada_ailerons)\n",
    "r2_score_Ada_ailerons = (r2_score_Ada_ailerons[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_ailerons)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Kernel Mean Matching #######################################\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_KMM_ailerons = KMM(get_estimator = get_estimator)\n",
    "model_KMM_ailerons.fit(ailerons_np_train_X, ailerons_np_train_y_list, src_idx_ailerons, tgt_idx_ailerons)\n",
    "\n",
    "y_pred_KMM_ailerons = model_KMM_concrete.predict(AileronsData_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_KMM_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_KMM_ailerons))\n",
    "print(\"RMSE of KMM:\", mse_KMM_ailerons)\n",
    "\n",
    "r2_score_KMM_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_KMM_ailerons)\n",
    "r2_score_KMM_ailerons = (r2_score_KMM_ailerons[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_KMM_ailerons)\n",
    "\n",
    "#model_KMM_concrete.weights_   #To get the weights of the algorithm\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 0.00016086118104770237\n",
      "R^2 of TrAdaboostR2: 0.8410246331188738\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBRTL_ailerons = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBRTL_ailerons.fit(ailerons_np_train_X, ailerons_np_train_y_list)\n",
    "\n",
    "y_pred_GBRTL_ailerons = model_GBRTL_ailerons.predict(AileronsData_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBRTL_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_GBRTL_ailerons))\n",
    "print(\"RMSE of KMM:\", mse_GBRTL_ailerons)\n",
    "\n",
    "r2_score_GBRTL_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_GBRTL_ailerons)\n",
    "r2_score_GBRTL_ailerons = (r2_score_GBRTL_ailerons[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBRTL_ailerons)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of KMM: 0.00019240831285250804\n",
      "R^2 of TrAdaboostR2: 0.7720629536034364\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_ailerons = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_ailerons.fit(AileronsData_df_tgt_X, AileronsData_df_tgt_y)\n",
    "\n",
    "y_pred_GBR_ailerons = model_GBR_ailerons.predict(AileronsData_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_GBR_ailerons))\n",
    "print(\"RMSE of KMM:\", mse_GBR_ailerons)\n",
    "\n",
    "r2_score_GBR_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_GBR_ailerons)\n",
    "r2_score_GBR_ailerons = (r2_score_GBR_ailerons[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_ailerons)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_KMM_ailerons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-04017b81c8ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m################ Transformed TrAdaBoost.R2 Ailerons #############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mweights_KMM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_KMM_ailerons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_KMM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_KMM_ailerons' is not defined"
     ]
    }
   ],
   "source": [
    "################ Transformed TrAdaBoost.R2 Ailerons #############################################\n",
    "\n",
    "weights_KMM = model_KMM_ailerons.weights_\n",
    "\n",
    "val_mean = np.mean(weights_KMM)\n",
    "weights_KMM = np.append(weights_KMM, val_mean)\n",
    "\n",
    "ailerons_source_df_X_trans = ailerons_source_df_X.apply(lambda ailerons_source_df_X: ailerons_source_df_X * weights_KMM)\n",
    "#concrete_source_df_X.multiply(weights_KMM, axis=0)\n",
    "\n",
    "# concrete_np_train_X_trans = concrete_source_df_X_trans.to_numpy()\n",
    "\n",
    "ailerons_X_df = pd.concat([ailerons_tgt_df_X, ailerons_source_df_X_trans], ignore_index=True)\n",
    "ailerons_y_df = pd.concat([ailerons_tgt_df_y, ailerons_source_df_y], ignore_index=True)\n",
    "\n",
    "ailerons_np_train_X = ailerons_X_df.to_numpy()\n",
    "ailerons_np_train_y = ailerons_y_df.to_numpy()\n",
    "\n",
    "ailerons_np_test_X = ailerons_test_df_X.to_numpy()\n",
    "ailerons_np_test_y = ailerons_test_df_y.to_numpy()\n",
    "\n",
    "ailerons_np_train_y_list = ailerons_np_train_y.ravel()\n",
    "ailerons_np_test_y_list = ailerons_np_test_y.ravel()\n",
    "\n",
    "# print(concrete_np_train_y_list.shape, concrete_np_train_X_trans.shape)\n",
    "\n",
    "##################################################################\n",
    "model_TwoTrAda_ailerons = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_ailerons.fit(ailerons_np_train_X, ailerons_np_train_y_list, src_idx_ailerons, tgt_idx_ailerons)\n",
    "\n",
    "print(\"Transformed Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_ailerons = model_TwoTrAda_ailerons.predict(ailerons_np_test_X)\n",
    "\n",
    "mse_TwoTrAda_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_TwoTrAda_ailerons))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_ailerons)\n",
    "\n",
    "r2_score_TwoTrAda_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_TwoTrAda_ailerons)\n",
    "r2_score_TwoTrAda_ailerons = (r2_score_TwoTrAda_ailerons[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_ailerons)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "RMSE of STrAdaboostR2: 0.00017697035377550353\n",
      "R^2 of STrAdaboostR2: 0.8151835442224004\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Ailerons ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "sample_size = [len(AileronsData_df_tgt_X), len(AileronsData_df_source_X)]\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "model_stradaboost_ailerons = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                    n_estimators = n_estimators, sample_size = sample_size,\n",
    "                    steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "model_stradaboost_ailerons.fit(ailerons_np_train_X, ailerons_np_train_y_list)\n",
    "y_pred_stradaboost_ailerons = model_stradaboost_ailerons.predict(ailerons_np_test_X)\n",
    "\n",
    "mse_stradaboost_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_stradaboost_ailerons))\n",
    "print(\"RMSE of STrAdaboostR2:\", mse_stradaboost_ailerons)\n",
    "\n",
    "r2_score_stradaboost_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_stradaboost_ailerons)\n",
    "r2_score_stradaboost_ailerons = (r2_score_stradaboost_ailerons[0])**2\n",
    "print(\"R^2 of STrAdaboostR2:\", r2_score_stradaboost_ailerons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevators Data\n",
      "(8752, 19)\n",
      "(7847, 19)\n",
      "Target Set:  (438, 19)\n",
      "Source Set:  (8314, 19)\n",
      "Test Set:  (7847, 19)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################### Elevators ###########################################\n",
    "target_elevators = ['Goal']\n",
    "colnames_elevators = ['climbRate', 'Sgz', 'p', 'q', 'curRoll', 'absRoll', 'diffClb', 'diffRollRate', 'diffDiffClb', 'SaTime1', 'SaTime2', \n",
    "                      'SaTime3', 'SaTime4', 'diffSaTime1', 'diffSaTime2', 'diffSaTime3', 'diffSaTime4', 'Sa', 'Goal']\n",
    "Elevators_df_train = pd.read_csv('UCI_regression/Elevators/elevators.data', header = None, names = colnames_elevators)\n",
    "print(\"Elevators Data\")\n",
    "print(Elevators_df_train.shape)\n",
    "\n",
    "Elevators_df_test = pd.read_csv('UCI_regression/Elevators/elevators.test', header = None, names = colnames_elevators)\n",
    "print(Elevators_df_test.shape)\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "Elevators_df_source, Elevators_df_tgt = train_test_split(Elevators_df_train, test_size = 0.05) ## test_size = tgt size\n",
    "# print(Elevators_df_tgt.shape, Elevators_df_source.shape, Elevators_df_test.shape)\n",
    "\n",
    "Elevators_df_tgt = Elevators_df_tgt.reset_index(drop = True)\n",
    "Elevators_df_source = Elevators_df_source.reset_index(drop = True)\n",
    "print(\"Target Set: \", Elevators_df_tgt.shape)\n",
    "print(\"Source Set: \", Elevators_df_source.shape)\n",
    "print(\"Test Set: \", Elevators_df_test.shape)\n",
    "\n",
    "\n",
    "Elevators_df_test_y = Elevators_df_test[target_elevators]\n",
    "Elevators_df_test_X = Elevators_df_test.drop(target_elevators, axis = 1)\n",
    "\n",
    "Elevators_df_tgt_y = Elevators_df_tgt[target_elevators]\n",
    "Elevators_df_tgt_X = Elevators_df_tgt.drop(target_elevators, axis = 1)\n",
    "\n",
    "Elevators_df_source_y = Elevators_df_source[target_elevators]\n",
    "Elevators_df_source_X = Elevators_df_source.drop(target_elevators, axis = 1)\n",
    "\n",
    "\n",
    "############## Merging the datasets #################\n",
    "elevators_X_df = pd.concat([Elevators_df_tgt_X, Elevators_df_source_X], ignore_index=True)\n",
    "elevators_y_df = pd.concat([Elevators_df_tgt_y, Elevators_df_source_y], ignore_index=True)\n",
    "\n",
    "elevators_np_train_X = elevators_X_df.to_numpy()\n",
    "elevators_np_train_y = elevators_y_df.to_numpy()\n",
    "\n",
    "elevators_np_test_X = Elevators_df_test_X.to_numpy()\n",
    "elevators_np_test_y = Elevators_df_test_y.to_numpy()\n",
    "\n",
    "elevators_np_train_y_list = elevators_np_train_y.ravel()\n",
    "elevators_np_test_y_list = elevators_np_test_y.ravel()\n",
    "\n",
    "src_size_elevators = len(Elevators_df_source_y)\n",
    "tgt_size_elevators = len(AileronsData_df_tgt_y)\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Transfer Learning specifications #########################\n",
    "src_idx_elevators = np.arange(start=0, stop=(src_size_elevators - 1), step=1)\n",
    "tgt_idx_elevators = np.arange(start=src_size_elevators, stop=((src_size_elevators + tgt_size_elevators)-1), step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Elevators #######################################\n",
    "\n",
    "model_TwoTrAda_elevators = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 1000, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_elevators.fit(elevators_np_train_X, elevators_np_train_y_list, src_idx_elevators, tgt_idx_elevators)\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_elevators = model_TwoTrAda_elevators.predict(elevators_np_test_X)\n",
    "mse_TwoTrAda_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_TwoTrAda_elevators))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_elevators)\n",
    "\n",
    "r2_score_TwoTrAda_elevators = pearsonr(elevators_np_test_y_list, y_pred_TwoTrAda_elevators)\n",
    "r2_score_TwoTrAda_elevators = (r2_score_TwoTrAda_elevators[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_elevators)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 0.0033531239365182726\n",
      "R^2 of TrAdaboostR2: 0.7310570733716446\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning Elevators #####################################################\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_Ada_elevators = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_elevators.fit(elevators_np_train_X, elevators_np_train_y_list)\n",
    "\n",
    "y_pred_ada_elevators = model_Ada_elevators.predict(elevators_np_test_X)\n",
    "mse_Ada_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_ada_elevators))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_elevators)\n",
    "\n",
    "r2_score_Ada_elevators = pearsonr(elevators_np_test_y_list, y_pred_ada_elevators)\n",
    "r2_score_Ada_elevators = (r2_score_Ada_elevators[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_elevators)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 0.0033468167448132517\n",
      "R^2 of TrAdaboostR2: 0.7322875513444026\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Elevators #####################################################\n",
    "print(\"Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_elevators = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_elevators.fit(elevators_np_train_X, elevators_np_train_y_list)\n",
    "\n",
    "y_pred_ada_elevators = model_Ada_elevators.predict(elevators_np_test_X)\n",
    "mse_Ada_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_ada_elevators))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_elevators)\n",
    "\n",
    "r2_score_Ada_elevators = pearsonr(elevators_np_test_y_list, y_pred_ada_elevators)\n",
    "r2_score_Ada_elevators = (r2_score_Ada_elevators[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_elevators)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Mean Matching\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-058b30befff8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_KMM_elevators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_KMM_elevators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melevators_np_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melevators_np_train_y_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_idx_elevators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_idx_elevators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_pred_KMM_elevators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_KMM_elevators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melevators_df_test_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##Using dataframe instead of the numpy matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/adapt/instance_based/_kmm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, src_index, tgt_index, tgt_index_labeled, **fit_params)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         weights = minimize(func,\n\u001b[0m\u001b[1;32m    191\u001b[0m                            \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                            \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cobyla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'slsqp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         return _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    618\u001b[0m                                constraints, callback=callback, **options)\n\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trust-constr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/optimize/slsqp.py\u001b[0m in \u001b[0;36m_minimize_slsqp\u001b[0;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, **unknown_options)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;31m# Compute the derivatives of the objective function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;31m# For some reason SLSQP wants g dimensioned to n+1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfprime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;31m# Compute the normals of the constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/optimize/slsqp.py\u001b[0m in \u001b[0;36mapprox_jacobian\u001b[0;34m(x, func, epsilon, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mjac\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mdx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/adapt/instance_based/_kmm.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         weights = minimize(func,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######################### Kernel Mean Matching Elevators #######################################\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_KMM_elevators = KMM(get_estimator = get_estimator)\n",
    "model_KMM_elevators.fit(elevators_np_train_X, elevators_np_train_y_list, src_idx_elevators, tgt_idx_elevators)\n",
    "\n",
    "y_pred_KMM_elevators = model_KMM_elevators.predict(elevators_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_KMM_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_KMM_elevators))\n",
    "print(\"RMSE of KMM:\", mse_KMM_elevators)\n",
    "\n",
    "r2_score_KMM_elevators = pearsonr(elevators_np_test_y_list, y_pred_KMM_elevators)\n",
    "r2_score_KMM_elevators = (r2_score_KMM_elevators[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_KMM_elevators)\n",
    "\n",
    "#model_KMM_concrete.weights_   #To get the weights of the algorithm\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 0.00290000061975912\n",
      "R^2 of TrAdaboostR2: 0.7993369840871682\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning Elevators #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBRTL_elevators = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBRTL_elevators.fit(elevators_np_train_X, elevators_np_train_y_list)\n",
    "\n",
    "y_pred_GBRTL_elevators = model_GBRTL_elevators.predict(Elevators_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBRTL_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_GBRTL_elevators))\n",
    "print(\"RMSE of KMM:\", mse_GBRTL_elevators)\n",
    "\n",
    "r2_score_GBRTL_elevators = pearsonr(elevators_np_test_y_list, y_pred_GBRTL_elevators)\n",
    "r2_score_GBRTL_elevators = (r2_score_GBRTL_elevators[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBRTL_elevators)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of KMM: 0.004249983595276213\n",
      "R^2 of TrAdaboostR2: 0.5688668075278818\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Elevators #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_elevators = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_elevators.fit(Elevators_df_tgt_X, Elevators_df_tgt_y)\n",
    "\n",
    "y_pred_GBR_elevators = model_GBR_elevators.predict(Elevators_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_GBR_elevators))\n",
    "print(\"RMSE of KMM:\", mse_GBR_elevators)\n",
    "\n",
    "r2_score_GBR_elevators = pearsonr(elevators_np_test_y_list, y_pred_GBR_elevators)\n",
    "r2_score_GBR_elevators = (r2_score_GBR_elevators[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_elevators)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KMM' object has no attribute 'weights_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-7ecdc731731a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m################ Transformed TrAdaBoost.R2 Elevators #############################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mweights_KMM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_KMM_elevators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_KMM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KMM' object has no attribute 'weights_'"
     ]
    }
   ],
   "source": [
    "################ Transformed TrAdaBoost.R2 Elevators #############################################\n",
    "\n",
    "weights_KMM = model_KMM_elevators.weights_\n",
    "\n",
    "val_mean = np.mean(weights_KMM)\n",
    "weights_KMM = np.append(weights_KMM, val_mean)\n",
    "\n",
    "elevators_source_df_X_trans = Elevators_source_df_X.apply(lambda Elevators_source_df_X: Elevators_source_df_X * weights_KMM)\n",
    "#concrete_source_df_X.multiply(weights_KMM, axis=0)\n",
    "\n",
    "# concrete_np_train_X_trans = concrete_source_df_X_trans.to_numpy()\n",
    "\n",
    "elevators_X_df = pd.concat([elevators_tgt_df_X, elevators_source_df_X_trans], ignore_index=True)\n",
    "elevators_y_df = pd.concat([elevators_tgt_df_y, elevators_source_df_y], ignore_index=True)\n",
    "\n",
    "elevators_np_train_X = elevators_X_df.to_numpy()\n",
    "elevators_np_train_y = elevators_y_df.to_numpy()\n",
    "\n",
    "elevators_np_test_X = elevators_test_df_X.to_numpy()\n",
    "elevators_np_test_y = elevators_test_df_y.to_numpy()\n",
    "\n",
    "elevators_np_train_y_list = elevators_np_train_y.ravel()\n",
    "elevators_np_test_y_list = elevators_np_test_y.ravel()\n",
    "\n",
    "# print(concrete_np_train_y_list.shape, concrete_np_train_X_trans.shape)\n",
    "\n",
    "##################################################################\n",
    "model_TwoTrAda_elevators = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_elevators.fit(elevators_np_train_X, elevators_np_train_y_list, src_idx_elevators, tgt_idx_elevators)\n",
    "\n",
    "print(\"Transformed Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_elevators = model_TwoTrAda_elevators.predict(elevators_np_test_X)\n",
    "\n",
    "mse_TwoTrAda_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_TwoTrAda_elevators))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_elevators)\n",
    "\n",
    "r2_score_TwoTrAda_elevators = pearsonr(elevators_np_test_y_list, y_pred_TwoTrAda_elevators)\n",
    "r2_score_TwoTrAda_elevators = (r2_score_TwoTrAda_elevators[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_elevators)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "RMSE of STrAdaboostR2: 0.0038173854763371958\n",
      "R^2 of STrAdaboostR2: 0.774423111177669\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Elevators ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "sample_size = [len(Elevators_df_tgt_X), len(Elevators_df_source_X)]\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "model_stradaboost_elevators = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                    n_estimators = n_estimators, sample_size = sample_size,\n",
    "                    steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "model_stradaboost_elevators.fit(elevators_np_train_X, elevators_np_train_y_list)\n",
    "y_pred_stradaboost_elevators = model_stradaboost_elevators.predict(elevators_np_test_X)\n",
    "\n",
    "mse_stradaboost_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_stradaboost_elevators))\n",
    "print(\"RMSE of STrAdaboostR2:\", mse_stradaboost_elevators)\n",
    "\n",
    "r2_score_stradaboost_elevators = pearsonr(elevators_np_test_y_list, y_pred_stradaboost_elevators)\n",
    "r2_score_stradaboost_elevators = (r2_score_stradaboost_elevators[0])**2\n",
    "print(\"R^2 of STrAdaboostR2:\", r2_score_stradaboost_elevators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pole Telecomm Data\n",
      "(5000, 49)\n",
      "(10000, 49)\n",
      "Target Set:  (250, 49)\n",
      "Source Set:  (4750, 49)\n",
      "Test Set:  (10000, 49)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "############################ PoleTelecomm ####################################################################\n",
    "target_poleTelecomm = ['foo']\n",
    "colnames_poleTelecomm = ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20',\n",
    "                        'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39',\n",
    "                        'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'foo']\n",
    "poleTelecomm_df_train = pd.read_csv('UCI_regression/PoleTelecomm/pol.data', header = None, names = colnames_poleTelecomm)\n",
    "print(\"Pole Telecomm Data\")\n",
    "print(poleTelecomm_df_train.shape)\n",
    "\n",
    "poleTelecomm_df_test = pd.read_csv('UCI_regression/PoleTelecomm/pol.test', header = None, names = colnames_poleTelecomm)\n",
    "print(poleTelecomm_df_test.shape)\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "poleTelecomm_df_source, poleTelecomm_df_tgt = train_test_split(poleTelecomm_df_train, test_size = 0.05) ## test_size = tgt size\n",
    "\n",
    "poleTelecomm_df_tgt = poleTelecomm_df_tgt.reset_index(drop = True)\n",
    "poleTelecomm_df_source = poleTelecomm_df_source.reset_index(drop = True)\n",
    "print(\"Target Set: \", poleTelecomm_df_tgt.shape)\n",
    "print(\"Source Set: \", poleTelecomm_df_source.shape)\n",
    "print(\"Test Set: \", poleTelecomm_df_test.shape)\n",
    "\n",
    "\n",
    "poleTelecomm_df_test_y = poleTelecomm_df_test[target_poleTelecomm]\n",
    "poleTelecomm_df_test_X = poleTelecomm_df_test.drop(target_poleTelecomm, axis = 1)\n",
    "\n",
    "poleTelecomm_df_tgt_y = poleTelecomm_df_tgt[target_poleTelecomm]\n",
    "poleTelecomm_df_tgt_X = poleTelecomm_df_tgt.drop(target_poleTelecomm, axis = 1)\n",
    "\n",
    "poleTelecomm_df_source_y = poleTelecomm_df_source[target_poleTelecomm]\n",
    "poleTelecomm_df_source_X = poleTelecomm_df_source.drop(target_poleTelecomm, axis = 1)\n",
    "\n",
    "############## Merging the datasets #################\n",
    "poleTelecomm_X_df = pd.concat([poleTelecomm_df_tgt_X, poleTelecomm_df_source_X], ignore_index=True)\n",
    "poleTelecomm_y_df = pd.concat([poleTelecomm_df_tgt_y, poleTelecomm_df_source_y], ignore_index=True)\n",
    "\n",
    "poleTelecomm_np_train_X = poleTelecomm_X_df.to_numpy()\n",
    "poleTelecomm_np_train_y = poleTelecomm_y_df.to_numpy()\n",
    "\n",
    "poleTelecomm_np_test_X = poleTelecomm_df_test_X.to_numpy()\n",
    "poleTelecomm_np_test_y = poleTelecomm_df_test_y.to_numpy()\n",
    "\n",
    "poleTelecomm_np_train_y_list = poleTelecomm_np_train_y.ravel()\n",
    "poleTelecomm_np_test_y_list = poleTelecomm_np_test_y.ravel()\n",
    "\n",
    "src_size_poleTelecomm = len(poleTelecomm_df_source_y)\n",
    "tgt_size_poleTelecomm = len(poleTelecomm_df_tgt_y)\n",
    "\n",
    "print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Transfer Learning specifications #########################################################\n",
    "src_idx_poleTelecomm = np.arange(start=0, stop=(src_size_poleTelecomm - 1), step=1)\n",
    "tgt_idx_poleTelecomm = np.arange(start=src_size_poleTelecomm, stop=((src_size_poleTelecomm + tgt_size_poleTelecomm)-1), step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### TwoStagetrAdaBoostR2 PoleTelecomm #######################################\n",
    "\n",
    "model_TwoTrAda_poleTelecomm = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 1000, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_poleTelecomm.fit(poleTelecomm_np_train_X, poleTelecomm_np_train_y_list, src_idx_poleTelecomm, tgt_idx_poleTelecomm)\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_poleTelecomm = model_TwoTrAda_poleTelecomm.predict(poleTelecomm_np_test_X)\n",
    "mse_TwoTrAda_poleTelecomm = sqrt(mean_squared_error(poleTelecomm_np_test_y, y_pred_TwoTrAda_poleTelecomm))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_poleTelecomm)\n",
    "\n",
    "r2_score_TwoTrAda_poleTelecomm = pearsonr(poleTelecomm_np_test_y_list, y_pred_TwoTrAda_poleTelecomm)\n",
    "r2_score_TwoTrAda_poleTelecomm = (r2_score_TwoTrAda_poleTelecomm[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_poleTelecomm)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 7.215295917108106\n",
      "R^2 of TrAdaboostR2: 0.9710338730753431\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning PoleTelecomm #####################################################\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_Ada_poleTelecomm = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_poleTelecomm.fit(poleTelecomm_np_train_X, poleTelecomm_np_train_y_list)\n",
    "\n",
    "y_pred_ada_poleTelecomm = model_Ada_poleTelecomm.predict(poleTelecomm_np_test_X)\n",
    "mse_Ada_poleTelecomm = sqrt(mean_squared_error(poleTelecomm_np_test_y, y_pred_ada_poleTelecomm))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_poleTelecomm)\n",
    "\n",
    "r2_score_Ada_poleTelecomm = pearsonr(poleTelecomm_np_test_y_list, y_pred_ada_poleTelecomm)\n",
    "r2_score_Ada_poleTelecomm = (r2_score_Ada_poleTelecomm[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_poleTelecomm)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 7.227106916829483\n",
      "R^2 of TrAdaboostR2: 0.9709137106368763\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 PoleTelecomm #####################################################\n",
    "print(\"Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_poleTelecomm = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_poleTelecomm.fit(poleTelecomm_np_train_X, poleTelecomm_np_train_y_list)\n",
    "\n",
    "y_pred_ada_poleTelecomm = model_Ada_poleTelecomm.predict(poleTelecomm_np_test_X)\n",
    "mse_Ada_poleTelecomm = sqrt(mean_squared_error(poleTelecomm_np_test_y, y_pred_ada_poleTelecomm))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_poleTelecomm)\n",
    "\n",
    "r2_score_Ada_poleTelecomm = pearsonr(poleTelecomm_np_test_y_list, y_pred_ada_poleTelecomm)\n",
    "r2_score_Ada_poleTelecomm = (r2_score_Ada_poleTelecomm[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_poleTelecomm)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Kernel Mean Matching PoleTelecomm #######################################\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_KMM_poleTelecomm = KMM(get_estimator = get_estimator)\n",
    "model_KMM_poleTelecomm.fit(poleTelecomm_np_train_X, poleTelecomm_np_train_y_list, src_idx_poleTelecomm, tgt_idx_poleTelecomm)\n",
    "\n",
    "y_pred_KMM_poleTelecomm = model_KMM_elevators.predict(poleTelecomm_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_KMM_poleTelecomm = sqrt(mean_squared_error(poleTelecomm_np_test_y, y_pred_KMM_poleTelecomm))\n",
    "print(\"RMSE of KMM:\", mse_KMM_poleTelecomm)\n",
    "\n",
    "r2_score_KMM_poleTelecomm = pearsonr(poleTelecomm_np_test_y_list, y_pred_KMM_poleTelecomm)\n",
    "r2_score_KMM_poleTelecomm = (r2_score_KMM_poleTelecomm[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_KMM_poleTelecomm)\n",
    "\n",
    "#model_KMM_concrete.weights_   #To get the weights of the algorithm\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 7.886908269088648\n",
      "R^2 of TrAdaboostR2: 0.9645003396543416\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning PoleTelecomm #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBRTL_poleTelecomm = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBRTL_poleTelecomm.fit(poleTelecomm_np_train_X, poleTelecomm_np_train_y_list)\n",
    "\n",
    "y_pred_GBRTL_poleTelecomm = model_GBRTL_poleTelecomm.predict(poleTelecomm_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBRTL_poleTelecomm = sqrt(mean_squared_error(poleTelecomm_np_test_y, y_pred_GBRTL_poleTelecomm))\n",
    "print(\"RMSE of KMM:\", mse_GBRTL_poleTelecomm)\n",
    "\n",
    "r2_score_GBRTL_poleTelecomm = pearsonr(poleTelecomm_np_test_y_list, y_pred_GBRTL_poleTelecomm)\n",
    "r2_score_GBRTL_poleTelecomm = (r2_score_GBRTL_poleTelecomm[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBRTL_poleTelecomm)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of KMM: 14.44710686981929\n",
      "R^2 of TrAdaboostR2: 0.8804730765202913\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression PoleTelecomm #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_poleTelecomm = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_poleTelecomm.fit(poleTelecomm_df_tgt_X, poleTelecomm_df_tgt_y)\n",
    "\n",
    "y_pred_GBR_poleTelecomm = model_GBR_poleTelecomm.predict(poleTelecomm_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_poleTelecomm = sqrt(mean_squared_error(poleTelecomm_np_test_y, y_pred_GBR_poleTelecomm))\n",
    "print(\"RMSE of KMM:\", mse_GBR_poleTelecomm)\n",
    "\n",
    "r2_score_GBR_poleTelecomm = pearsonr(poleTelecomm_np_test_y_list, y_pred_GBR_poleTelecomm)\n",
    "r2_score_GBR_poleTelecomm = (r2_score_GBR_poleTelecomm[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_poleTelecomm)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Transformed TrAdaBoost.R2 PoleTelecomm #############################################\n",
    "\n",
    "weights_KMM = model_KMM_poleTelecomm.weights_\n",
    "\n",
    "val_mean = np.mean(weights_KMM)\n",
    "weights_KMM = np.append(weights_KMM, val_mean)\n",
    "\n",
    "poleTelecomm_source_df_X_trans = poleTelecomm_source_df_X.apply(lambda poleTelecomm_source_df_X: poleTelecomm_source_df_X * weights_KMM)\n",
    "#concrete_source_df_X.multiply(weights_KMM, axis=0)\n",
    "\n",
    "# concrete_np_train_X_trans = concrete_source_df_X_trans.to_numpy()\n",
    "\n",
    "poleTelecomm_X_df = pd.concat([poleTelecomm_tgt_df_X, poleTelecomm_source_df_X_trans], ignore_index=True)\n",
    "poleTelecomm_y_df = pd.concat([poleTelecomm_tgt_df_y, poleTelecomm_source_df_y], ignore_index=True)\n",
    "\n",
    "poleTelecomm_np_train_X = poleTelecomm_X_df.to_numpy()\n",
    "poleTelecomm_np_train_y = poleTelecomm_y_df.to_numpy()\n",
    "\n",
    "poleTelecomm_np_test_X = poleTelecomm_test_df_X.to_numpy()\n",
    "poleTelecomm_np_test_y = poleTelecomm_test_df_y.to_numpy()\n",
    "\n",
    "poleTelecomm_np_train_y_list = poleTelecomm_np_train_y.ravel()\n",
    "poleTelecomm_np_test_y_list = poleTelecomm_np_test_y.ravel()\n",
    "\n",
    "# print(concrete_np_train_y_list.shape, concrete_np_train_X_trans.shape)\n",
    "\n",
    "##################################################################\n",
    "model_TwoTrAda_poleTelecomm = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_poleTelecomm.fit(poleTelecomm_np_train_X, poleTelecomm_np_train_y_list, src_idx_poleTelecomm, tgt_idx_poleTelecomm)\n",
    "\n",
    "print(\"Transformed Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_poleTelecomm = model_TwoTrAda_poleTelecomm.predict(poleTelecomm_np_test_X)\n",
    "\n",
    "mse_TwoTrAda_poleTelecomm = sqrt(mean_squared_error(poleTelecomm_np_test_y, y_pred_TwoTrAda_poleTelecomm))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_poleTelecomm)\n",
    "\n",
    "r2_score_TwoTrAda_poleTelecomm = pearsonr(poleTelecomm_np_test_y_list, y_pred_TwoTrAda_poleTelecomm)\n",
    "r2_score_TwoTrAda_poleTelecomm = (r2_score_TwoTrAda_poleTelecomm[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_poleTelecomm)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "RMSE of STrAdaboostR2: 11.70628467573206\n",
      "R^2 of STrAdaboostR2: 0.9640301238839806\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 PoleTelecomm ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "sample_size = [len(poleTelecomm_df_tgt_X), len(poleTelecomm_df_source_X)]\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "model_stradaboost_poleTelecomm = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                    n_estimators = n_estimators, sample_size = sample_size,\n",
    "                    steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "model_stradaboost_poleTelecomm.fit(poleTelecomm_np_train_X, poleTelecomm_np_train_y_list)\n",
    "y_pred_stradaboost_poleTelecomm = model_stradaboost_poleTelecomm.predict(poleTelecomm_np_test_X)\n",
    "\n",
    "mse_stradaboost_poleTelecomm = sqrt(mean_squared_error(poleTelecomm_np_test_y, y_pred_stradaboost_poleTelecomm))\n",
    "print(\"RMSE of STrAdaboostR2:\", mse_stradaboost_poleTelecomm)\n",
    "\n",
    "r2_score_stradaboost_poleTelecomm = pearsonr(poleTelecomm_np_test_y_list, y_pred_stradaboost_poleTelecomm)\n",
    "r2_score_stradaboost_poleTelecomm = (r2_score_stradaboost_poleTelecomm[0])**2\n",
    "print(\"R^2 of STrAdaboostR2:\", r2_score_stradaboost_poleTelecomm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data\n",
      "(4177, 9)\n",
      "Target Set:  (1241, 8)\n",
      "Source Set:  (1465, 8)\n",
      "Test Set:  (1471, 8)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################### Abalone ###########################################\n",
    "#### range: [0.0 - 1.130]\n",
    "#### Mid of correlation variable: Whole_weight\n",
    "#### [0, 0.12] [0.12, 0.15], [0.15, 1.130]\n",
    "#### Target variable: Rings\n",
    "#######################################################################################\n",
    "target_var_abalone = ['Rings']\n",
    "colnames_abalone = ['Sex', 'Length', 'Diameter', 'Height', 'Whole_weight', 'Shucked_weight', 'Viscera_weight', 'Shell_weight', 'Rings']\n",
    "AbaloneData_df = pd.read_csv('UCI_regression/Abalone/abalone.data', header = None, names = colnames_abalone)\n",
    "\n",
    "gender = {'M': 1,'F': 2, 'I': 3} \n",
    "AbaloneData_df.Sex = [gender[item] for item in AbaloneData_df.Sex] \n",
    "\n",
    "print(\"Abalone Data\")\n",
    "print(AbaloneData_df.shape)\n",
    "\n",
    "########## Corr Abalone ################\n",
    "# print(\"The correlation matrix is: \")\n",
    "# print(AbaloneData_df.corr()['Rings'])\n",
    "\n",
    "##################### Splitting in 3 equal parts #######################################\n",
    "# print(AbaloneData_df.sort_values('Whole_weight')['Whole_weight'])\n",
    "# print(len(AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] <= 0.5)]))\n",
    "# print(len(AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] > 0.5) & (AbaloneData_df['Whole_weight'] <= 1.0)]))\n",
    "# print(len(AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] > 1.0)]))\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "# AbaloneData_df_remain, AbaloneData_df_tgt = train_test_split(AbaloneData_df, test_size = 0.05) ## test_size = tgt size\n",
    "# AbaloneData_df_source, AbaloneData_df_test = train_test_split(AbaloneData_df_remain, test_size = 0.3) ## test_size = tgt size\n",
    "# print(AbaloneData_df_tgt.shape, AbaloneData_df_source.shape, AbaloneData_df_test.shape)\n",
    "\n",
    "\n",
    "drop_col_abalone = ['Whole_weight']\n",
    "\n",
    "abalone_tgt_df = AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] <= 0.5)]\n",
    "abalone_tgt_df = abalone_tgt_df.drop(drop_col_abalone, axis = 1)\n",
    "abalone_tgt_df = abalone_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",abalone_tgt_df.shape)\n",
    "\n",
    "abalone_source_df = AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] > 0.5) & (AbaloneData_df['Whole_weight'] <= 1.0)]\n",
    "abalone_source_df = abalone_source_df.drop(drop_col_abalone, axis = 1)\n",
    "abalone_source_df = abalone_source_df.reset_index(drop=True)\n",
    "print(\"Source Set: \",abalone_source_df.shape)\n",
    "\n",
    "abalone_test_df = AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] > 1.0)]\n",
    "abalone_test_df = abalone_test_df.drop(drop_col_abalone, axis = 1)\n",
    "abalone_test_df = abalone_test_df.reset_index(drop=True)\n",
    "print(\"Test Set: \",abalone_test_df.shape)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_column_abalone = ['Rings']\n",
    "\n",
    "abalone_tgt_df_y = abalone_tgt_df[target_column_abalone]\n",
    "abalone_tgt_df_X = abalone_tgt_df.drop(target_column_abalone, axis = 1)\n",
    "\n",
    "abalone_source_df_y = abalone_source_df[target_column_abalone]\n",
    "abalone_source_df_X = abalone_source_df.drop(target_column_abalone, axis = 1)\n",
    "\n",
    "abalone_test_df_y = abalone_test_df[target_column_abalone]\n",
    "abalone_test_df_X = abalone_test_df.drop(target_column_abalone, axis = 1)\n",
    "\n",
    "############## Merging the datasets ##########################################\n",
    "abalone_X_df = pd.concat([abalone_tgt_df_X, abalone_source_df_X], ignore_index=True)\n",
    "abalone_y_df = pd.concat([abalone_tgt_df_y, abalone_source_df_y], ignore_index=True)\n",
    "\n",
    "abalone_np_train_X = abalone_X_df.to_numpy()\n",
    "abalone_np_train_y = abalone_y_df.to_numpy()\n",
    "\n",
    "abalone_np_test_X = abalone_test_df_X.to_numpy()\n",
    "abalone_np_test_y = abalone_test_df_y.to_numpy()\n",
    "\n",
    "abalone_np_train_y_list = abalone_np_train_y.ravel()\n",
    "abalone_np_test_y_list = abalone_np_test_y.ravel()\n",
    "\n",
    "src_size_abalone = len(abalone_source_df_y)\n",
    "tgt_size_abalone = len(abalone_tgt_df_y)\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Transfer Learning specifications #########################\n",
    "src_idx_abalone = np.arange(start=0, stop=(src_size_abalone - 1), step=1)\n",
    "tgt_idx_abalone = np.arange(start=src_size_abalone, stop=((src_size_abalone + tgt_size_abalone)-1), step=1)\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Two-Stage TrAdaboost.R2: 3.1250656467146656\n",
      "R^2 of TrAdaboostR2: 0.04265365181479114\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Abalone #######################################\n",
    "\n",
    "model_TwoTrAda_abalone = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 1000, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_abalone.fit(abalone_np_train_X, abalone_np_train_y_list, src_idx_abalone, tgt_idx_abalone)\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_abalone = model_TwoTrAda_abalone.predict(abalone_np_test_X)\n",
    "mse_TwoTrAda_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_TwoTrAda_abalone))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_abalone)\n",
    "\n",
    "r2_score_TwoTrAda_abalone = pearsonr(abalone_np_test_y_list, y_pred_TwoTrAda_abalone)\n",
    "r2_score_TwoTrAda_abalone = (r2_score_TwoTrAda_abalone[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_abalone)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 3.0283148106334967\n",
      "R^2 of TrAdaboostR2: 0.149804197168237\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning Abalone #####################################################\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_AdaTr_abalone = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_AdaTr_abalone.fit(abalone_np_train_X, abalone_np_train_y_list)\n",
    "\n",
    "y_pred_AdaTr_abalone = model_AdaTr_abalone.predict(abalone_np_test_X)\n",
    "mse_AdaTr_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_AdaTr_abalone))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_AdaTr_abalone)\n",
    "\n",
    "r2_score_AdaTr_abalone = pearsonr(abalone_np_test_y_list, y_pred_AdaTr_abalone)\n",
    "r2_score_AdaTr_abalone = (r2_score_AdaTr_abalone[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_AdaTr_abalone)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 3.0298705815237588\n",
      "R^2 of TrAdaboostR2: 0.14310861479304007\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Abalone #####################################################\n",
    "print(\"Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_abalone = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_abalone.fit(abalone_np_train_X, abalone_np_train_y_list)\n",
    "\n",
    "y_pred_ada_abalone = model_Ada_abalone.predict(abalone_np_test_X)\n",
    "mse_Ada_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_ada_abalone))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_abalone)\n",
    "\n",
    "r2_score_Ada_abalone = pearsonr(abalone_np_test_y_list, y_pred_ada_abalone)\n",
    "r2_score_Ada_abalone = (r2_score_Ada_abalone[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_abalone)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Mean Matching\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-0f3905ad1b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_KMM_abalone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_KMM_abalone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabalone_np_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabalone_np_train_y_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_idx_abalone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_idx_abalone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_pred_KMM_abalone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_KMM_elevators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabalone_df_test_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##Using dataframe instead of the numpy matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/adapt/instance_based/_kmm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, src_index, tgt_index, tgt_index_labeled, **fit_params)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         weights = minimize(func,\n\u001b[0m\u001b[1;32m    191\u001b[0m                            \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                            \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cobyla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'slsqp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         return _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    618\u001b[0m                                constraints, callback=callback, **options)\n\u001b[1;32m    619\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trust-constr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/scipy/optimize/slsqp.py\u001b[0m in \u001b[0;36m_minimize_slsqp\u001b[0;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, **unknown_options)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# Call SLSQP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         slsqp(m, meq, x, xl, xu, fx, c, g, a, acc, majiter, mode, w, jw,\n\u001b[0m\u001b[1;32m    447\u001b[0m               \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m               \u001b[0miexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mireset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitermx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######################### Kernel Mean Matching Abalone #######################################\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_KMM_abalone = KMM(get_estimator = get_estimator)\n",
    "model_KMM_abalone.fit(abalone_np_train_X, abalone_np_train_y_list, src_idx_abalone, tgt_idx_abalone)\n",
    "\n",
    "y_pred_KMM_abalone = model_KMM_elevators.predict(abalone_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_KMM_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_KMM_abalone))\n",
    "print(\"RMSE of KMM:\", mse_KMM_abalone)\n",
    "\n",
    "r2_score_KMM_abalone = pearsonr(abalone_np_test_y_list, y_pred_KMM_abalone)\n",
    "r2_score_KMM_abalone = (r2_score_KMM_abalone[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_KMM_abalone)\n",
    "\n",
    "#model_KMM_concrete.weights_   #To get the weights of the algorithm\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 3.1659095016420817\n",
      "R^2 of TrAdaboostR2: 0.035792803563995765\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning Abalone #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBRTL_abalone = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBRTL_abalone.fit(abalone_np_train_X, abalone_np_train_y_list)\n",
    "\n",
    "y_pred_GBRTL_abalone = model_GBRTL_abalone.predict(abalone_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBRTL_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_GBRTL_abalone))\n",
    "print(\"RMSE of KMM:\", mse_GBRTL_abalone)\n",
    "\n",
    "r2_score_GBRTL_abalone = pearsonr(abalone_np_test_y_list, y_pred_GBRTL_abalone)\n",
    "r2_score_GBRTL_abalone = (r2_score_GBRTL_abalone[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBRTL_abalone)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of KMM: 3.043731919181302\n",
      "R^2 of TrAdaboostR2: 0.010571438214392102\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression PoleTelecomm #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_abalone = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_abalone.fit(abalone_tgt_df_X, abalone_tgt_df_y)\n",
    "\n",
    "y_pred_GBR_abalone = model_GBR_abalone.predict(abalone_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_GBR_abalone))\n",
    "print(\"RMSE of KMM:\", mse_GBR_abalone)\n",
    "\n",
    "r2_score_GBR_abalone = pearsonr(abalone_np_test_y_list, y_pred_GBR_abalone)\n",
    "r2_score_GBR_abalone = (r2_score_GBR_abalone[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_abalone)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Transformed TrAdaBoost.R2 Abalone ########################################################\n",
    "\n",
    "weights_KMM = model_KMM_abalone.weights_\n",
    "\n",
    "val_mean = np.mean(weights_KMM)\n",
    "weights_KMM = np.append(weights_KMM, val_mean)\n",
    "\n",
    "abalone_source_df_X_trans = abalone_source_df_X.apply(lambda abalone_source_df_X: abalone_source_df_X * weights_KMM)\n",
    "#concrete_source_df_X.multiply(weights_KMM, axis=0)\n",
    "\n",
    "# concrete_np_train_X_trans = concrete_source_df_X_trans.to_numpy()\n",
    "\n",
    "abalone_X_df = pd.concat([abalone_tgt_df_X, abalone_source_df_X_trans], ignore_index=True)\n",
    "abalone_y_df = pd.concat([abalone_tgt_df_y, abalone_source_df_y], ignore_index=True)\n",
    "\n",
    "abalone_np_train_X = abalone_X_df.to_numpy()\n",
    "abalone_np_train_y = abalone_y_df.to_numpy()\n",
    "\n",
    "abalone_np_test_X = abalone_test_df_X.to_numpy()\n",
    "abalone_np_test_y = abalone_test_df_y.to_numpy()\n",
    "\n",
    "abalone_np_train_y_list = abalone_np_train_y.ravel()\n",
    "abalone_np_test_y_list = abalone_np_test_y.ravel()\n",
    "\n",
    "# print(concrete_np_train_y_list.shape, concrete_np_train_X_trans.shape)\n",
    "\n",
    "##################################################################\n",
    "model_TwoTrAda_abalone = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_abalone.fit(abalone_np_train_X, abalone_np_train_y_list, src_idx_abalone, tgt_idx_abalone)\n",
    "\n",
    "print(\"Transformed Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_abalone = model_TwoTrAda_abalone.predict(abalone_np_test_X)\n",
    "\n",
    "mse_TwoTrAda_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_TwoTrAda_abalone))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_abalone)\n",
    "\n",
    "r2_score_TwoTrAda_abalone = pearsonr(abalone_np_test_y_list, y_pred_TwoTrAda_abalone)\n",
    "r2_score_TwoTrAda_abalone = (r2_score_TwoTrAda_abalone[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_abalone)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "RMSE of STrAdaboostR2: 3.091666842196879\n",
      "R^2 of STrAdaboostR2: 0.030949749633660227\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Abalone ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "sample_size = [len(abalone_tgt_df_X), len(abalone_source_df_X)]\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "model_stradaboost_abalone = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                    n_estimators = n_estimators, sample_size = sample_size,\n",
    "                    steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "model_stradaboost_abalone.fit(abalone_np_train_X, abalone_np_train_y_list)\n",
    "y_pred_stradaboost_abalone = model_stradaboost_abalone.predict(abalone_np_test_X)\n",
    "\n",
    "mse_stradaboost_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_stradaboost_abalone))\n",
    "print(\"RMSE of STrAdaboostR2:\", mse_stradaboost_abalone)\n",
    "\n",
    "r2_score_stradaboost_abalone = pearsonr(abalone_np_test_y_list, y_pred_stradaboost_abalone)\n",
    "r2_score_stradaboost_abalone = (r2_score_stradaboost_abalone[0])**2\n",
    "print(\"R^2 of STrAdaboostR2:\", r2_score_stradaboost_abalone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinematics Data\n",
      "(8192, 9)\n",
      "Target Set:  (2755, 8)\n",
      "Source Set:  (2598, 8)\n",
      "Test Set:  (2839, 8)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################################## Kinematics ######################################################################\n",
    "#### range: [0.04 - 1.45]\n",
    "#### Mid of correlation variable: theta7\n",
    "#### [0, 0.6] [0.6, 0.85], [0.6, 0.85]\n",
    "####################################################################################################################################\n",
    "target_var_Kinematics = ['y']\n",
    "colnames_Kinematics = ['theta1', 'theta2', 'theta3', 'theta4', 'theta5', 'theta6', 'theta7', 'theta8', 'y']\n",
    "KinematicsData_df = pd.read_csv('UCI_regression/Kinematics/kin8nm.data', header = None,  names = colnames_Kinematics)\n",
    "print(\"Kinematics Data\")\n",
    "print(KinematicsData_df.shape)\n",
    "\n",
    "########## Corr Kinematics ################\n",
    "# print(\"The correlation matrix is: \")\n",
    "# print(KinematicsData_df.corr().sort_values('y')['y'])\n",
    "\n",
    "##################### Splitting in 3 equal parts #######################################\n",
    "# print(KinematicsData_df.sort_values('theta7')['theta7'])\n",
    "\n",
    "drop_col_kinematics = ['theta7']\n",
    "\n",
    "kinematics_tgt_df = KinematicsData_df.loc[(KinematicsData_df['theta7'] <= -0.5)]\n",
    "kinematics_tgt_df = kinematics_tgt_df.drop(drop_col_kinematics, axis = 1)\n",
    "kinematics_tgt_df = kinematics_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",kinematics_tgt_df.shape)\n",
    "\n",
    "\n",
    "kinematics_source_df = KinematicsData_df.loc[(KinematicsData_df['theta7'] > -0.5) & (KinematicsData_df['theta7'] <= 0.5)]\n",
    "kinematics_source_df = kinematics_source_df.drop(drop_col_kinematics, axis = 1)\n",
    "kinematics_source_df = kinematics_source_df.reset_index(drop=True)\n",
    "print(\"Source Set: \",kinematics_source_df.shape)\n",
    "\n",
    "\n",
    "kinematics_test_df = KinematicsData_df.loc[(KinematicsData_df['theta7'] > 0.5)]\n",
    "kinematics_test_df = kinematics_test_df.drop(drop_col_kinematics, axis = 1)\n",
    "kinematics_test_df = kinematics_test_df.reset_index(drop=True)\n",
    "print(\"Test Set: \",kinematics_test_df.shape)\n",
    "\n",
    "\n",
    "# #################### Splitting with small target set and large source and test set #############\n",
    "# KinematicsData_df_remain, KinematicsData_df_tgt = train_test_split(KinematicsData_df, test_size = 0.05) ## test_size = tgt size\n",
    "# KinematicsData_df_source, KinematicsData_df_test = train_test_split(KinematicsData_df_remain, test_size = 0.3) ## test_size = tgt size\n",
    "# print(KinematicsData_df_tgt.shape, KinematicsData_df_source.shape, KinematicsData_df_test.shape)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_column_kinematics = ['y']\n",
    "\n",
    "kinematics_tgt_df_y = kinematics_tgt_df[target_column_kinematics]\n",
    "kinematics_tgt_df_X = kinematics_tgt_df.drop(target_column_kinematics, axis = 1)\n",
    "\n",
    "kinematics_source_df_y = kinematics_source_df[target_column_kinematics]\n",
    "kinematics_source_df_X = kinematics_source_df.drop(target_column_kinematics, axis = 1)\n",
    "\n",
    "kinematics_test_df_y = kinematics_test_df[target_column_kinematics]\n",
    "kinematics_test_df_X = kinematics_test_df.drop(target_column_kinematics, axis = 1)\n",
    "\n",
    "############## Merging the datasets ##########################################\n",
    "kinematics_X_df = pd.concat([kinematics_tgt_df_X, kinematics_source_df_X], ignore_index=True)\n",
    "kinematics_y_df = pd.concat([kinematics_tgt_df_y, kinematics_source_df_y], ignore_index=True)\n",
    "\n",
    "kinematics_np_train_X = kinematics_X_df.to_numpy()\n",
    "kinematics_np_train_y = kinematics_y_df.to_numpy()\n",
    "\n",
    "kinematics_np_test_X = kinematics_test_df_X.to_numpy()\n",
    "kinematics_np_test_y = kinematics_test_df_y.to_numpy()\n",
    "\n",
    "kinematics_np_train_y_list = kinematics_np_train_y.ravel()\n",
    "kinematics_np_test_y_list = kinematics_np_test_y.ravel()\n",
    "\n",
    "src_size_kinematics = len(kinematics_source_df_y)\n",
    "tgt_size_kinematics = len(kinematics_tgt_df_y)\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2598, 2599, 2600, ..., 5349, 5350, 5351]),\n",
       " array([2598, 2599, 2600, ..., 5349, 5350, 5351]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# Transfer Learning specifications #########################\n",
    "src_idx_kinematics = np.arange(start=0, stop=(src_size_kinematics - 1), step=1)\n",
    "src_idx_kinematics = np.arange(start=src_size_kinematics, stop=((src_size_kinematics + tgt_size_kinematics)-1), step=1)\n",
    "src_idx_kinematics, src_idx_kinematics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'get_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-3322a4ee13ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m########################### TwoStagetrAdaBoostR2 Kinematics #######################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel_TwoTrAda_kinematics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwoStageTrAdaBoostR2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, kwargs_TwoTrAda)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel_TwoTrAda_kinematics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkinematics_np_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkinematics_np_train_y_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_idx_kinematics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_idx_kinematics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'get_estimator'"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Kinematics #######################################\n",
    "\n",
    "model_TwoTrAda_kinematics = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 1000, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list, src_idx_kinematics, tgt_idx_kinematics)\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_kinematics = model_TwoTrAda_kinematics.predict(kinematics_np_test_X)\n",
    "mse_TwoTrAda_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_TwoTrAda_kinematics))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_kinematics)\n",
    "\n",
    "r2_score_TwoTrAda_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_TwoTrAda_kinematics)\n",
    "r2_score_TwoTrAda_kinematics = (r2_score_TwoTrAda_kinematics[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_kinematics)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 0.2604143796356598\n",
      "R^2 of TrAdaboostR2: 0.2228593521941291\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning Kinematics #####################################################\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_Ada_kinematics = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list)\n",
    "\n",
    "y_pred_ada_kinematics = model_Ada_kinematics.predict(kinematics_np_test_X)\n",
    "mse_Ada_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_ada_kinematics))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_kinematics)\n",
    "\n",
    "r2_score_Ada_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_ada_kinematics)\n",
    "r2_score_Ada_kinematics = (r2_score_Ada_kinematics[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_kinematics)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 0.2607164590801618\n",
      "R^2 of TrAdaboostR2: 0.22154664510146269\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Kinematics #####################################################\n",
    "print(\"Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_kinematics = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list)\n",
    "\n",
    "y_pred_ada_kinematics = model_Ada_kinematics.predict(kinematics_np_test_X)\n",
    "mse_Ada_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_ada_kinematics))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_kinematics)\n",
    "\n",
    "r2_score_Ada_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_ada_kinematics)\n",
    "r2_score_Ada_kinematics = (r2_score_Ada_kinematics[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_kinematics)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Kernel Mean Matching Kinematics #######################################\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_KMM_kinematics = KMM(get_estimator = get_estimator)\n",
    "model_KMM_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list, src_idx_kinematics, tgt_idx_kinematics)\n",
    "\n",
    "y_pred_KMM_kinematics = model_KMM_kinematics.predict(kinematics_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_KMM_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_KMM_kinematics))\n",
    "print(\"RMSE of KMM:\", mse_KMM_kinematics)\n",
    "\n",
    "r2_score_KMM_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_KMM_kinematics)\n",
    "r2_score_KMM_kinematics = (r2_score_KMM_kinematics[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_KMM_kinematics)\n",
    "\n",
    "#model_KMM_concrete.weights_   #To get the weights of the algorithm\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 0.25586133995157134\n",
      "R^2 of TrAdaboostR2: 0.2538128608441631\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning Kinematics #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBRTL_kinematics = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBRTL_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list)\n",
    "\n",
    "y_pred_GBRTL_kinematics = model_GBRTL_kinematics.predict(kinematics_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBRTL_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_GBRTL_kinematics))\n",
    "print(\"RMSE of KMM:\", mse_GBRTL_kinematics)\n",
    "\n",
    "r2_score_GBRTL_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_GBRTL_kinematics)\n",
    "r2_score_GBRTL_kinematics = (r2_score_GBRTL_kinematics[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBRTL_kinematics)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of KMM: 0.30639546537425716\n",
      "R^2 of TrAdaboostR2: 0.06941572878514127\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Kinematics #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_kinematics = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_kinematics.fit(kinematics_tgt_df_X, kinematics_tgt_df_y)\n",
    "\n",
    "y_pred_GBR_kinematics = model_GBR_kinematics.predict(kinematics_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_GBR_kinematics))\n",
    "print(\"RMSE of KMM:\", mse_GBR_kinematics)\n",
    "\n",
    "r2_score_GBR_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_GBR_kinematics)\n",
    "r2_score_GBR_kinematics = (r2_score_GBR_kinematics[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_kinematics)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Transformed TrAdaBoost.R2 Kinematics #############################################\n",
    "\n",
    "weights_KMM = model_KMM_kinematics.weights_\n",
    "\n",
    "val_mean = np.mean(weights_KMM)\n",
    "weights_KMM = np.append(weights_KMM, val_mean)\n",
    "\n",
    "kinematics_source_df_X_trans = kinematics_source_df_X.apply(lambda kinematics_source_df_X: kinematics_source_df_X * weights_KMM)\n",
    "#concrete_source_df_X.multiply(weights_KMM, axis=0)\n",
    "\n",
    "# concrete_np_train_X_trans = concrete_source_df_X_trans.to_numpy()\n",
    "\n",
    "kinematics_X_df = pd.concat([kinematics_tgt_df_X, kinematics_source_df_X_trans], ignore_index=True)\n",
    "kinematics_y_df = pd.concat([kinematics_tgt_df_y, kinematics_source_df_y], ignore_index=True)\n",
    "\n",
    "kinematics_np_train_X = kinematics_X_df.to_numpy()\n",
    "kinematics_np_train_y = kinematics_y_df.to_numpy()\n",
    "\n",
    "kinematics_np_test_X = kinematics_test_df_X.to_numpy()\n",
    "kinematics_np_test_y = kinematics_test_df_y.to_numpy()\n",
    "\n",
    "kinematics_np_train_y_list = kinematics_np_train_y.ravel()\n",
    "kinematics_np_test_y_list = kinematics_np_test_y.ravel()\n",
    "\n",
    "# print(concrete_np_train_y_list.shape, concrete_np_train_X_trans.shape)\n",
    "\n",
    "##################################################################\n",
    "model_TwoTrAda_kinematics = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list, src_idx_kinematics, tgt_idx_kinematics)\n",
    "\n",
    "print(\"Transformed Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_kinematics = model_TwoTrAda_kinematics.predict(kinematics_np_test_X)\n",
    "\n",
    "mse_TwoTrAda_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_TwoTrAda_kinematics))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_kinematics)\n",
    "\n",
    "r2_score_TwoTrAda_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_TwoTrAda_kinematics)\n",
    "r2_score_TwoTrAda_kinematics = (r2_score_TwoTrAda_kinematics[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_kinematics)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "RMSE of STrAdaboostR2: 0.23854389626490993\n",
      "R^2 of STrAdaboostR2: 0.2799693293860748\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Kinematics ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "sample_size = [len(kinematics_tgt_df_X), len(kinematics_source_df_X)]\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "model_stradaboost_kinematics = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                    n_estimators = n_estimators, sample_size = sample_size,\n",
    "                    steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "model_stradaboost_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list)\n",
    "y_pred_stradaboost_kinematics = model_stradaboost_kinematics.predict(kinematics_np_test_X)\n",
    "\n",
    "mse_stradaboost_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_stradaboost_kinematics))\n",
    "print(\"RMSE of STrAdaboostR2:\", mse_stradaboost_kinematics)\n",
    "\n",
    "r2_score_stradaboost_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_stradaboost_kinematics)\n",
    "r2_score_stradaboost_kinematics = (r2_score_stradaboost_kinematics[0])**2\n",
    "print(\"R^2 of STrAdaboostR2:\", r2_score_stradaboost_kinematics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer Activity Data\n",
      "(8192, 22)\n",
      "Target Set:  (2766, 21)\n",
      "Source Set:  (2539, 21)\n",
      "Test Set:  (2887, 21)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################### Computer Activity ###########################################\n",
    "colnames_CompAct = ['lread', 'lwrite', 'scall', 'sread', 'swrite', 'fork', 'exec', 'rchar', 'wchar', 'pgout', 'ppgout', \n",
    "                    'pgfree', 'pgscan', 'atch', 'pgin', 'ppgin', 'pflt', 'vflt', 'runqsz', 'freemem', 'freeswap', 'usr' ]\n",
    "CompActData_df = pd.read_csv('UCI_regression/ComputerActivity/cpu_act.data', header = None, names = colnames_CompAct)\n",
    "print(\"Computer Activity Data\")\n",
    "print(CompActData_df.shape)\n",
    "\n",
    "########## Corr Computer Activity ################\n",
    "# print(\"The correlation matrix is: \")\n",
    "# print(CompActData_df.corr().sort_values('usr')['usr'])\n",
    "\n",
    "##################### Splitting in 3 equal parts #######################################\n",
    "# print(CompActData_df.sort_values('pgin')['pgin'])\n",
    "\n",
    "drop_col_compact = ['pgin']\n",
    "\n",
    "compact_tgt_df = CompActData_df.loc[(CompActData_df['pgin'] <= 1.0)]\n",
    "compact_tgt_df = compact_tgt_df.drop(drop_col_compact, axis = 1)\n",
    "compact_tgt_df = compact_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",compact_tgt_df.shape)\n",
    "\n",
    "\n",
    "compact_source_df = CompActData_df.loc[(CompActData_df['pgin'] > 1.0) & (CompActData_df['pgin'] <= 6.0)]\n",
    "compact_source_df = compact_source_df.drop(drop_col_compact, axis = 1)\n",
    "compact_source_df = compact_source_df.reset_index(drop=True)\n",
    "print(\"Source Set: \",compact_source_df.shape)\n",
    "\n",
    "\n",
    "compact_test_df = CompActData_df.loc[(CompActData_df['pgin'] > 6.0)]\n",
    "compact_test_df = compact_test_df.drop(drop_col_compact, axis = 1)\n",
    "compact_test_df = compact_test_df.reset_index(drop=True)\n",
    "print(\"Test Set: \",compact_test_df.shape)\n",
    "\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "# KinematicsData_df_remain, KinematicsData_df_tgt = train_test_split(KinematicsData_df, test_size = 0.05) ## test_size = tgt size\n",
    "# KinematicsData_df_source, KinematicsData_df_test = train_test_split(KinematicsData_df_remain, test_size = 0.3) ## test_size = tgt size\n",
    "# print(KinematicsData_df_tgt.shape, KinematicsData_df_source.shape, KinematicsData_df_test.shape)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_column_compact = ['usr']\n",
    "\n",
    "compact_tgt_df_y = compact_tgt_df[target_column_compact]\n",
    "compact_tgt_df_X = compact_tgt_df.drop(target_column_compact, axis = 1)\n",
    "\n",
    "compact_source_df_y = compact_source_df[target_column_compact]\n",
    "compact_source_df_X = compact_source_df.drop(target_column_compact, axis = 1)\n",
    "\n",
    "compact_test_df_y = compact_test_df[target_column_compact]\n",
    "compact_test_df_X = compact_test_df.drop(target_column_compact, axis = 1)\n",
    "\n",
    "############## Merging the datasets ##########################################\n",
    "compact_X_df = pd.concat([compact_tgt_df_X, compact_source_df_X], ignore_index=True)\n",
    "compact_y_df = pd.concat([compact_tgt_df_y, compact_source_df_y], ignore_index=True)\n",
    "\n",
    "compact_np_train_X = compact_X_df.to_numpy()\n",
    "compact_np_train_y = compact_y_df.to_numpy()\n",
    "\n",
    "compact_np_test_X = compact_test_df_X.to_numpy()\n",
    "compact_np_test_y = compact_test_df_y.to_numpy()\n",
    "\n",
    "compact_np_train_y_list = compact_np_train_y.ravel()\n",
    "compact_np_test_y_list = compact_np_test_y.ravel()\n",
    "\n",
    "src_size_compact = len(compact_source_df_y)\n",
    "tgt_size_compact = len(compact_tgt_df_y)\n",
    "\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2539, 2540, 2541, ..., 5301, 5302, 5303]),\n",
       " array([2539, 2540, 2541, ..., 5301, 5302, 5303]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# Transfer Learning specifications #########################\n",
    "src_idx_compact = np.arange(start=0, stop=(src_size_compact - 1), step=1)\n",
    "src_idx_compact = np.arange(start=src_size_compact, stop=((src_size_compact + tgt_size_compact)-1), step=1)\n",
    "src_idx_compact, src_idx_compact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### TwoStagetrAdaBoostR2 compAct #######################################\n",
    "\n",
    "model_TwoTrAda_compact = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 1000, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_compact.fit(compact_np_train_X, compact_np_train_y_list, src_idx_compact, tgt_idx_compact)\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_compact = model_TwoTrAda_compact.predict(compact_np_test_X)\n",
    "mse_TwoTrAda_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_TwoTrAda_compact))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_compact)\n",
    "\n",
    "r2_score_TwoTrAda_compact = pearsonr(compact_np_test_y_list, y_pred_TwoTrAda_compact)\n",
    "r2_score_TwoTrAda_compact = (r2_score_TwoTrAda_compact[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_compact)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 3.9460278220363523\n",
      "R^2 of TrAdaboostR2: 0.970225964792705\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning compAct #####################################################\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_Ada_compact = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_compact.fit(compact_np_train_X, compact_np_train_y_list)\n",
    "\n",
    "y_pred_ada_compact = model_Ada_compact.predict(compact_np_test_X)\n",
    "mse_Ada_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_ada_compact))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_compact)\n",
    "\n",
    "r2_score_Ada_compact = pearsonr(compact_np_test_y_list, y_pred_ada_compact)\n",
    "r2_score_Ada_compact = (r2_score_Ada_compact[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_compact)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE of Adaboost.R2: 3.933592655266186\n",
      "R^2 of TrAdaboostR2: 0.9703048050814059\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 compAct #####################################################\n",
    "print(\"Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_Ada_compact = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500) \n",
    "model_Ada_compact.fit(compact_np_train_X, compact_np_train_y_list)\n",
    "\n",
    "y_pred_ada_compact = model_Ada_compact.predict(compact_np_test_X)\n",
    "mse_Ada_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_ada_compact))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_Ada_compact)\n",
    "\n",
    "r2_score_Ada_compact = pearsonr(compact_np_test_y_list, y_pred_ada_compact)\n",
    "r2_score_Ada_compact = (r2_score_Ada_compact[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_Ada_compact)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Kernel Mean Matching compAct #######################################\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "model_KMM_compact = KMM(get_estimator = get_estimator)\n",
    "model_KMM_compact.fit(kinematics_np_train_X, kinematics_np_train_y_list, src_idx_kinematics, tgt_idx_kinematics)\n",
    "\n",
    "y_pred_KMM_compact = model_KMM_compact.predict(kinematics_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_KMM_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_KMM_compact))\n",
    "print(\"RMSE of KMM:\", mse_KMM_compact)\n",
    "\n",
    "r2_score_KMM_compact = pearsonr(compact_np_test_y_list, y_pred_KMM_compact)\n",
    "r2_score_KMM_compact = (r2_score_KMM_compact[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_KMM_compact)\n",
    "\n",
    "#model_KMM_concrete.weights_   #To get the weights of the algorithm\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE of KMM: 3.2122237003651817\n",
      "R^2 of TrAdaboostR2: 0.9761264178149078\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning compAct #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBRTL_compact = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBRTL_compact.fit(compact_np_train_X, compact_np_train_y_list)\n",
    "\n",
    "y_pred_GBRTL_compact = model_GBRTL_compact.predict(compact_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBRTL_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_GBRTL_compact))\n",
    "print(\"RMSE of KMM:\", mse_GBRTL_compact)\n",
    "\n",
    "r2_score_GBRTL_compact = pearsonr(compact_np_test_y_list, y_pred_GBRTL_compact)\n",
    "r2_score_GBRTL_compact = (r2_score_GBRTL_compact[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBRTL_compact)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of KMM: 4.103227316601275\n",
      "R^2 of TrAdaboostR2: 0.9639686110913217\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression compAct #######################################\n",
    "\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "model_GBR_compact = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "model_GBR_compact.fit(compact_tgt_df_X, compact_tgt_df_y)\n",
    "\n",
    "y_pred_GBR_compact = model_GBR_compact.predict(compact_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "mse_GBR_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_GBR_compact))\n",
    "print(\"RMSE of KMM:\", mse_GBR_compact)\n",
    "\n",
    "r2_score_GBR_compact = pearsonr(compact_np_test_y_list, y_pred_GBR_compact)\n",
    "r2_score_GBR_compact = (r2_score_GBR_compact[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_GBR_compact)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## Transformed TrAdaBoost.R2 compAct ###############################################################\n",
    "\n",
    "weights_KMM = model_KMM_compact.weights_\n",
    "\n",
    "val_mean = np.mean(weights_KMM)\n",
    "weights_KMM = np.append(weights_KMM, val_mean)\n",
    "\n",
    "compact_source_df_X_trans = compact_source_df_X.apply(lambda compact_source_df_X: compact_source_df_X * weights_KMM)\n",
    "#concrete_source_df_X.multiply(weights_KMM, axis=0)\n",
    "# concrete_np_train_X_trans = concrete_source_df_X_trans.to_numpy()\n",
    "\n",
    "compact_X_df = pd.concat([compact_tgt_df_X, compact_source_df_X_trans], ignore_index=True)\n",
    "compact_y_df = pd.concat([compact_tgt_df_y, compact_source_df_y], ignore_index=True)\n",
    "\n",
    "compact_np_train_X = compact_X_df.to_numpy()\n",
    "compact_np_train_y = compact_y_df.to_numpy()\n",
    "\n",
    "compact_np_test_X = compact_test_df_X.to_numpy()\n",
    "compact_np_test_y = compact_test_df_y.to_numpy()\n",
    "\n",
    "compact_np_train_y_list = compact_np_train_y.ravel()\n",
    "compact_np_test_y_list = compact_np_test_y.ravel()\n",
    "\n",
    "# print(concrete_np_train_y_list.shape, concrete_np_train_X_trans.shape)\n",
    "\n",
    "##################################################################\n",
    "model_TwoTrAda_compact = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv=10) #, kwargs_TwoTrAda)\n",
    "model_TwoTrAda_compact.fit(compact_np_train_X, compact_np_train_y_list, src_idx_compact, tgt_idx_compact)\n",
    "\n",
    "print(\"Transformed Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "y_pred_TwoTrAda_compact = model_TwoTrAda_kinematics.predict(compact_np_test_X)\n",
    "\n",
    "mse_TwoTrAda_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_TwoTrAda_compact))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda_compact)\n",
    "\n",
    "r2_score_TwoTrAda_compact = pearsonr(compact_np_test_y_list, y_pred_TwoTrAda_compact)\n",
    "r2_score_TwoTrAda_compact = (r2_score_TwoTrAda_compact[0])**2\n",
    "print(\"R^2 of TrAdaboostR2:\", r2_score_TwoTrAda_compact)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "RMSE of STrAdaboostR2: 3.767416563517102\n",
      "R^2 of STrAdaboostR2: 0.9679352328179658\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 compAct ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "sample_size = [len(compact_tgt_df_X), len(compact_source_df_X)]\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "model_stradaboost_compact = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                    n_estimators = n_estimators, sample_size = sample_size,\n",
    "                    steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "model_stradaboost_compact.fit(compact_np_train_X, compact_np_train_y_list)\n",
    "y_pred_stradaboost_compact = model_stradaboost_compact.predict(compact_np_test_X)\n",
    "\n",
    "mse_stradaboost_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_stradaboost_compact))\n",
    "print(\"RMSE of STrAdaboostR2:\", mse_stradaboost_compact)\n",
    "\n",
    "r2_score_stradaboost_compact = pearsonr(compact_np_test_y_list, y_pred_stradaboost_compact)\n",
    "r2_score_stradaboost_compact = (r2_score_stradaboost_compact[0])**2\n",
    "print(\"R^2 of STrAdaboostR2:\", r2_score_stradaboost_compact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## UNWANTED DATASETS ######################################################################\n",
    "\n",
    "################################### FriedmanExample ###########################################\n",
    "target_var_FE = ['y']\n",
    "colnames_FE = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'y']\n",
    "FriedmanData_df = pd.read_csv('UCI_regression/FriedmanExample/fried_delve.data', header = None) #, names = colnames_FE)\n",
    "print(\"Friedman Data\")\n",
    "print(FriedmanData_df.shape)\n",
    "\n",
    "########## Corr Friedman Example ################\n",
    "# print(\"The correlation matrix is: \")\n",
    "# print(FriedmanData_df)\n",
    "# print(FriedmanData_df.corr()['y'])\n",
    "\n",
    "print(\"---------------------------\")\n",
    "####################################################################################################################################\n",
    "\n",
    "################################### Diabetes ###############################################\n",
    "### Very small dataset, can be removed\n",
    "#### Mid of correlation variable: , range: \n",
    "#### \n",
    "#######################################################################################\n",
    "target_var_diabetes = ['c_peptide']\n",
    "colnames_diabetes = ['age', 'deficit', 'c_peptide']\n",
    "DiabetesData_df = pd.read_csv('UCI_regression/Diabetes/diabetes.data', header = None, names = colnames_diabetes)\n",
    "print(\"Diabetes Data\")\n",
    "print(DiabetesData_df.shape)\n",
    "\n",
    "######### Corr Diabetes ################\n",
    "# print(\"The correlation matrix is: \")\n",
    "# print(DiabetesData_df.corr()['c_peptide'])\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "# DiabetesData_df_remain, DiabetesData_df_tgt = train_test_split(DiabetesData_df, test_size = 0.025) ## test_size = tgt size\n",
    "# DiabetesData_df_source, DiabetesData_df_test = train_test_split(DiabetesData_df_remain, test_size = 0.3) ## test_size = tgt size\n",
    "# print(DiabetesData_df_tgt.shape, DiabetesData_df_source.shape, DiabetesData_df_test.shape)\n",
    "\n",
    "print(\"---------------------------\")\n",
    "##############################################################################################################################################\n",
    "\n",
    "# ################################### Pyrimidines ###########################################\n",
    "# ###########################################################################################\n",
    "# ### Very small dataset, can be removed\n",
    "# #### Mid of correlation variable: , range: \n",
    "# #### \n",
    "# ###########################################################################################\n",
    "# colnames_Pyrimidines = ['p1_polar', 'p1_size', 'p1_flex', 'p1_h_doner', 'p1_h_acceptor', 'p1_pi_doner', 'p1_pi_acceptor', 'p1_polarisable', 'p1_sigma',\n",
    "#                         'p2_polar', 'p2_size', 'p2_flex', 'p2_h_doner', 'p2_h_acceptor', 'p2_pi_doner', 'p2_pi_acceptor', 'p2_polarisable', 'p2_sigma', \n",
    "#                         'p3_polar', 'p3_size', 'p3_flex', 'p3_h_doner', 'p3_h_acceptor', 'p3_pi_doner', 'p3_pi_acceptor', 'p3_polarisable', 'p3_sigma', 'activity']\n",
    "# PyrimidinesData_df = pd.read_csv('UCI_regression/Pyrimidines/pyrim.data', header = None, names = colnames_Pyrimidines)\n",
    "# print(\"Pyrimidines Data\")\n",
    "# print(PyrimidinesData_df.shape)\n",
    "# print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "# ################################### Machine-Cpu ##################################################\n",
    "# #### range: [0 - 52]\n",
    "# #### Mid of correlation variable: CHMIN\n",
    "# #### \n",
    "# #### No correlation required since all attributes are integer variables\n",
    "# ##############################################################################################################################################\n",
    "\n",
    "################################### Stock ###########################################\n",
    "colnames_Stock = ['company1', 'company2', 'company3', 'company4', 'company5', 'company6', 'company7', 'company8', 'company9', 'company10']\n",
    "StockData_df = pd.read_csv('UCI_regression/Stock/stock.data', header = None, names = colnames_Stock) \n",
    "print(\"Stock Data\")\n",
    "print(StockData_df.shape)\n",
    "\n",
    "############################### Corr Stock ##########################################\n",
    "print(\"The correlation matrix is: \")\n",
    "print(StockData_df.corr().sort_values('y')['y'])\n",
    "\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing Data\n",
      "(506, 14)\n",
      "---------------------------\n",
      "Auto Data\n",
      "(392, 8)\n",
      "---------------------------\n",
      "Abalone Data\n",
      "(4177, 9)\n",
      "(209, 9) (2777, 9) (1191, 9)\n",
      "---------------------------\n",
      "Friedman Data\n",
      "(40768, 1)\n",
      "---------------------------\n",
      "Kinematics Data\n",
      "(8192, 9)\n",
      "2844\n",
      "2804\n",
      "2544\n",
      "(410, 9) (5447, 9) (2335, 9)\n",
      "---------------------------\n",
      "Stock Data\n",
      "(950, 10)\n",
      "---------------------------\n",
      "Computer Activity Data\n",
      "(950, 22)\n",
      "---------------------------\n",
      "Ailerons Data\n",
      "(7154, 41)\n",
      "(6596, 41)\n",
      "(358, 41) (6796, 41) (6596, 41)\n",
      "---------------------------\n",
      "Elevators Data\n",
      "(8752, 19)\n",
      "(7847, 19)\n",
      "(438, 19) (8314, 19) (7847, 19)\n",
      "---------------------------\n",
      "Pole Telecomm Data\n",
      "(5000, 49)\n",
      "(10000, 49)\n",
      "(438, 19) (8314, 19) (7847, 19)\n",
      "---------------------------\n",
      "(157, 7)\n",
      "(119, 7)\n",
      "(116, 7)\n"
     ]
    }
   ],
   "source": [
    "###################################################### Regression Datasets ################################################################################\n",
    "\n",
    "# colnames_MachineCPU = ['MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMX', 'class']\n",
    "# MachineCPUData_df = pd.read_csv('UCI_regression/Machine-Cpu/machine.data', header = None, names = colnames_MachineCPU)\n",
    "# print(\"Machine CPU Data\")\n",
    "# print(MachineCPUData_df.shape)\n",
    "\n",
    "# ########## Corr Machine-Cpu ################\n",
    "# # print(\"The correlation matrix is: \")\n",
    "# # print(MachineCPUData_df.corr().sort_values('class')['class'])\n",
    "\n",
    "# ##################### Splitting in 3 equal parts #######################################\n",
    "# # print(MachineCPUData_df.sort_values('CHMIN')['CHMIN'])\n",
    "# # print(len(MachineCPUData_df.loc[(MachineCPUData_df['CHMIN'] <= 0)]))\n",
    "# # print(len(MachineCPUData_df.loc[(MachineCPUData_df['y'] > 0.6) & (MachineCPUData_df['y'] <= 0.85)]))\n",
    "# # print(len(MachineCPUData_df.loc[(MachineCPUData_df['y'] > 0.85)]))\n",
    "\n",
    "# print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "# ################################### Wisconsin Breast Cancer ###########################################\n",
    "# colnames_WBC = ['Lymph_node', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', \n",
    "#                   'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', \n",
    "#                   'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', \n",
    "#                   'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst', \n",
    "#                   'fractal_dimension_worst', 'Tumor_size', 'Time']\n",
    "# WBCData_df = pd.read_csv('UCI_regression/WiscoinBreastCancer/r_wpbc.data', header = None, names = colnames_WBC)\n",
    "# print(\"Wisconsin Breast Cancer Data\")\n",
    "# print(WBCData_df.shape)\n",
    "# print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################\n",
    "\n",
    "############################# Preprocessing Data ################################################################\n",
    "############ Finding the correlation first ####################\n",
    "# print(\"The correlation matrix is: \")\n",
    "# print(ConcreteData_df.corr())\n",
    "\n",
    "# col = ConcreteData_df['Cement']\n",
    "# ConcreteData_df = ConcreteData_df.sort_values(by=['Cement'])\n",
    "# col = HousingData_df['nox']\n",
    "\n",
    "\n",
    "# drop_col = ['Cement']\n",
    "drop_col = ['horsepower']\n",
    "# drop_col = ['nox']\n",
    "\n",
    "# Train_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] <= 225)]\n",
    "# Train_df = HousingData_df.loc[(HousingData_df['nox'] > 0.475) & (HousingData_df['nox'] <= 0.600)]\n",
    "Train_df = AutoData_df.loc[(AutoData_df['horsepower'] > 80) & (AutoData_df['horsepower'] <= 110)]\n",
    "\n",
    "Train_df = Train_df.drop(drop_col, axis = 1)\n",
    "Train_df = Train_df.reset_index(drop=True)\n",
    "print(Train_df.shape)\n",
    "\n",
    "# Source_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] > 225) & (ConcreteData_df['Cement'] <= 350)]\n",
    "# Source_df = HousingData_df.loc[(HousingData_df['nox'] <= 0.475)]\n",
    "Source_df = AutoData_df.loc[(AutoData_df['horsepower'] <= 80)]\n",
    "\n",
    "Source_df = Source_df.drop(drop_col, axis = 1)\n",
    "Source_df = Source_df.reset_index(drop=True)\n",
    "print(Source_df.shape)\n",
    "\n",
    "# Test_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] > 350)]\n",
    "# Test_df = HousingData_df.loc[(HousingData_df['nox'] > 0.600)]\n",
    "Test_df = AutoData_df.loc[(AutoData_df['horsepower'] > 110)]\n",
    "\n",
    "Test_df = Test_df.drop(drop_col, axis = 1)\n",
    "Test_df = Test_df.reset_index(drop=True)\n",
    "print(Test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Two-Stage TrAdaboost.R2: 0.00020420204780042573\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 #######################################\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "\n",
    "src_idx = np.arange(start=0, stop=(src_size_ailerons-1), step=1)\n",
    "tgt_idx = np.arange(start=src_size_ailerons, stop=((src_size_ailerons + tgt_size_ailerons)-1), step=1)\n",
    "\n",
    "#range(0, src_size_ailerons)\n",
    "#range(src_size_ailerons, src_size_ailerons + tgt_size_ailerons)\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth=6)\n",
    "\n",
    "model_TwoTrAda = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, fit_intercept=False)\n",
    "model_TwoTrAda.fit(np_train_X, np_train_y_list, src_idx, tgt_idx)\n",
    "\n",
    "y_pred_TwoTrAda = model_TwoTrAda.predict(AileronsData_df_test_X)\n",
    "mse_TwoTrAda = sqrt(mean_squared_error(AileronsData_df_test_y, y_pred_TwoTrAda))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda)\n",
    "\n",
    "# r2_score_twostageboost_values = pearsonr(AileronsData_df_test_y, y_pred_TwoTrAda)\n",
    "# r2_score_twostageboost = (r2_score_twostageboost_values[0])**2\n",
    "# print(\"R^2 of TrAdaboostR2:\", r2_score_twostageboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Adaboost.R2: 0.0001772920248843519\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 ###############################################\n",
    "model_Ada = AdaBoostRegressor(DecisionTreeRegressor(max_depth=6), n_estimators = 100)\n",
    "model_Ada.fit(np_train_X, np_train_y_list)\n",
    "\n",
    "y_pred_ada = model_Ada.predict(AileronsData_df_test_X)\n",
    "mse_ada = sqrt(mean_squared_error(AileronsData_df_test_y, y_pred_ada))\n",
    "print(\"RMSE of Adaboost.R2:\", mse_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Kernel Mean Matching #######################################\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "model_KMM = KMM(get_estimator = get_estimator)\n",
    "model_KMM.fit(np_train_X, np_train_y_list, src_idx, tgt_idx)\n",
    "\n",
    "print(model_KMM.weights_)\n",
    "\n",
    "y_pred_TwoTrAda = model_TwoTrAda.predict(AileronsData_df_test_X)\n",
    "mse_TwoTrAda = sqrt(mean_squared_error(AileronsData_df_test_y, y_pred_TwoTrAda))\n",
    "print(\"RMSE of Two-Stage TrAdaboost.R2:\", mse_TwoTrAda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1c04534650b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid_TwoTrAda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_TwoTrAda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters_TwoTrAda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid_TwoTrAda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_train_y_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msrc_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_idx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Results from Grid Search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_TwoTrAda = TwoStageTrAdaBoostR2(get_estimator = get_estimator)\n",
    "parameters_TwoTrAda = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "                    'n_estimators_fs'    : [10, 50, 100, 200],\n",
    "                    'n_estimators' : [10,50,100, 200],\n",
    "                    'cv'    : [4,6,8,10]\n",
    "                     }\n",
    "\n",
    "grid_TwoTrAda = GridSearchCV(estimator = model_TwoTrAda, param_grid = parameters_TwoTrAda, cv = 10, n_jobs=-1)\n",
    "grid_TwoTrAda.fit(np_train_X, np_train_y_list, {src_idx, tgt_idx})\n",
    "\n",
    "# Results from Grid Search\n",
    "print(\" Results from Grid Search \" )\n",
    "print()\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "      grid_TwoTrAda.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",\n",
    "      grid_TwoTrAda.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "      grid_TwoTrAda.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000,\n",
      "                          subsample=0.5)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.8474244872852686\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 1000, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#Using GridSearchCV\n",
    "GBR = GradientBoostingRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "              'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "              'n_estimators' : [100,500,1000, 1500],\n",
    "              'max_depth'    : [4,6,8,10]\n",
    "             }\n",
    "grid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_GBR.fit(np_train_X, np_train_y_list)\n",
    "\n",
    "# Results from Grid Search\n",
    "print(\" Results from Grid Search \" )\n",
    "print()\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "      grid_GBR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",\n",
    "      grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "      grid_GBR.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      "\n",
      " The best estimator across ALL searched params:\n",
      " GradientBoostingRegressor(learning_rate=0.01, max_depth=8, n_estimators=500,\n",
      "                          subsample=0.2)\n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.8476612703679458\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 500, 'subsample': 0.2}\n"
     ]
    }
   ],
   "source": [
    "ABR = AdaBoostRegressor()\n",
    "parameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n",
    "              'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
    "              'n_estimators' : [100,500,1000, 1500],\n",
    "              'max_depth'    : [4,6,8,10]\n",
    "             }\n",
    "grid_ABR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\n",
    "grid_ABR.fit(np_train_X, np_train_y_list)\n",
    "\n",
    "# Results from Grid Search\n",
    "print(\" Results from Grid Search \" )\n",
    "print()\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "      grid_ABR.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\",\n",
    "      grid_ABR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "      grid_ABR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapt.utils import toy_regression\n",
    "\n",
    "X, y, src_index, tgt_index, tgt_index_labeled = toy_regression()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
