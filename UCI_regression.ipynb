{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories uploaded!!\n"
     ]
    }
   ],
   "source": [
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2 ##STrAdaBoost.R2\n",
    "from TwoStageTrAdaBoostR2 import TwoStageTrAdaBoostR2 ##two-stage TrAdaBoost.R2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Dropout, Flatten\n",
    "from keras import optimizers, utils, initializers, regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler #Importing the StandardScaler\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "#Geo plotting libraries\n",
    "import geopandas as gdp\n",
    "from matplotlib.colors import ListedColormap\n",
    "# import geoplot as glpt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "print(\"Repositories uploaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation matrix is: \n",
      "                               Cement  BlastFurnaceSlag    FlyAsh     Water  \\\n",
      "Cement                       1.000000         -0.275193 -0.397475 -0.081544   \n",
      "BlastFurnaceSlag            -0.275193          1.000000 -0.323569  0.107286   \n",
      "FlyAsh                      -0.397475         -0.323569  1.000000 -0.257044   \n",
      "Water                       -0.081544          0.107286 -0.257044  1.000000   \n",
      "Superplasticizer             0.092771          0.043376  0.377340 -0.657464   \n",
      "CoarseAggregate             -0.109356         -0.283998 -0.009977 -0.182312   \n",
      "FineAggregate               -0.222720         -0.281593  0.079076 -0.450635   \n",
      "Age                          0.081947         -0.044246 -0.154370  0.277604   \n",
      "ConcreteCompressiveStrength  0.497833          0.134824 -0.105753 -0.289613   \n",
      "\n",
      "                             Superplasticizer  CoarseAggregate  FineAggregate  \\\n",
      "Cement                               0.092771        -0.109356      -0.222720   \n",
      "BlastFurnaceSlag                     0.043376        -0.283998      -0.281593   \n",
      "FlyAsh                               0.377340        -0.009977       0.079076   \n",
      "Water                               -0.657464        -0.182312      -0.450635   \n",
      "Superplasticizer                     1.000000        -0.266303       0.222501   \n",
      "CoarseAggregate                     -0.266303         1.000000      -0.178506   \n",
      "FineAggregate                        0.222501        -0.178506       1.000000   \n",
      "Age                                 -0.192717        -0.003016      -0.156094   \n",
      "ConcreteCompressiveStrength          0.366102        -0.164928      -0.167249   \n",
      "\n",
      "                                  Age  ConcreteCompressiveStrength  \n",
      "Cement                       0.081947                     0.497833  \n",
      "BlastFurnaceSlag            -0.044246                     0.134824  \n",
      "FlyAsh                      -0.154370                    -0.105753  \n",
      "Water                        0.277604                    -0.289613  \n",
      "Superplasticizer            -0.192717                     0.366102  \n",
      "CoarseAggregate             -0.003016                    -0.164928  \n",
      "FineAggregate               -0.156094                    -0.167249  \n",
      "Age                          1.000000                     0.328877  \n",
      "ConcreteCompressiveStrength  0.328877                     1.000000  \n",
      "(368, 8)\n",
      "(406, 8)\n",
      "(256, 8)\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################################################################\n",
    "ConcreteData_df = pd.read_excel('UCI_regression/Concrete_Data.xls') ## 'Cement' found to be correlated at 0.4 :: 100\n",
    "# HousingData_df = pd.read_csv('UCI_regression/BostonHousing/BostonHousing.csv') ## 'nox' found to be correlated at 0.4 :: [0.385 - 0.871] :: 50\n",
    "# dropcol_initial = ['name']\n",
    "# AutoData_df = pd.read_csv('UCI_regression/MPG/Auto.csv') ## horsepower column has correlation 0.4 :: [46 - 230] :: 30\n",
    "# AutoData_df = AutoData_df.drop(dropcol_initial, axis = 1)\n",
    "# print(\"The shape of the Input data is: \", AutoData_df.shape)\n",
    "\n",
    "############################# Preprocessing Data ################################################################\n",
    "## Finding the correlation first\n",
    "print(\"The correlation matrix is: \")\n",
    "print(ConcreteData_df.corr())\n",
    "\n",
    "col = ConcreteData_df['Cement']\n",
    "ConcreteData_df = ConcreteData_df.sort_values(by=['Cement'])\n",
    "# print(AutoData_df[(col <= 80)].shape)\n",
    "# print(AutoData_df[(col > 80) & (col <= 110)].shape)\n",
    "# print(AutoData_df[(col > 110)].shape)\n",
    "\n",
    "# col = HousingData_df['nox']\n",
    "# print(HousingData_df[(col < 0.450)].shape)\n",
    "# print(HousingData_df[(col > 0.450) & (col < 0.600)].shape)\n",
    "\n",
    "\n",
    "drop_col = ['Cement']\n",
    "# drop_col = ['horsepower']\n",
    "# drop_col = ['nox']\n",
    "\n",
    "Train_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] <= 225)]\n",
    "# Train_df = HousingData_df.loc[(HousingData_df['nox'] > 0.475) & (HousingData_df['nox'] <= 0.600)]\n",
    "# Train_df = AutoData_df.loc[(AutoData_df['horsepower'] > 80) & (AutoData_df['horsepower'] <= 110)]\n",
    "Train_df = Train_df.drop(drop_col, axis = 1)\n",
    "Train_df = Train_df.reset_index(drop=True)\n",
    "print(Train_df.shape)\n",
    "\n",
    "Source_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] > 225) & (ConcreteData_df['Cement'] <= 350)]\n",
    "# Source_df = HousingData_df.loc[(HousingData_df['nox'] <= 0.475)]\n",
    "# Source_df = AutoData_df.loc[(AutoData_df['horsepower'] <= 80)]\n",
    "Source_df = Source_df.drop(drop_col, axis = 1)\n",
    "Source_df = Source_df.reset_index(drop=True)\n",
    "print(Source_df.shape)\n",
    "\n",
    "Test_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] > 350)]\n",
    "# Test_df = HousingData_df.loc[(HousingData_df['nox'] > 0.600)]\n",
    "# Test_df = AutoData_df.loc[(AutoData_df['horsepower'] > 110)]\n",
    "Test_df = Test_df.drop(drop_col, axis = 1)\n",
    "Test_df = Test_df.reset_index(drop=True)\n",
    "print(Test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################### Finding best instances from the source dataset ################################################################\n",
    "# Source_df[\"ManDis\"] = \"\"\n",
    "#\n",
    "# train_df_mean = []\n",
    "# prow = Train_df.mean()\n",
    "# train_df_mean = [prow.BlastFurnaceSlag, prow.FlyAsh, prow.Water, prow.Superplasticizer, prow.CoarseAggregate, prow.FineAggregate, prow.Age, prow.ConcreteCompressiveStrength]\n",
    "# # train_df_mean = [prow.crim, prow.zn, prow.indus, prow.chas, prow.rm, prow.age, prow.dis, prow.rad, prow.tax, prow.ptratio, prow.b, prow.lstat, prow.medv]\n",
    "# # train_df_mean = [prow.mpg, prow.cylinders, prow.displacement, prow.weight, prow.acceleration, prow.year, prow.origin]\n",
    "#\n",
    "# rowidx = 0\n",
    "# for row in Source_df.itertuples():\n",
    "#     row_list =[row.BlastFurnaceSlag, row.FlyAsh, row.Water, row.Superplasticizer, row.CoarseAggregate, row.FineAggregate, row.Age, row.ConcreteCompressiveStrength]\n",
    "#     # row_list =[row.crim, row.zn, row.indus, row.chas, row.rm, row.age, row.dis, row.rad, row.tax, row.ptratio, row.b, row.lstat, row.medv]\n",
    "#     # row_list =[row.mpg, row.cylinders, row.displacement, row.weight, row.acceleration, row.year, row.origin]\n",
    "#\n",
    "#     man_dis = 0\n",
    "#     for i in range(0, len(row_list)):\n",
    "#         tempval = train_df_mean[i] - row_list[i]\n",
    "#         man_dis = man_dis + abs(tempval)\n",
    "#\n",
    "#     Source_df.loc[rowidx,\"ManDis\"] = man_dis\n",
    "#     # print(Source_df.loc[rowidx,\"ManDis\"])\n",
    "#     rowidx = rowidx + 1\n",
    "#\n",
    "# # print(Source_df)\n",
    "# Source_df = Source_df.sort_values('ManDis')\n",
    "# Train_source_df = Source_df.head(100) ## For housing 70 was taken, For auto 40 was taken, For concrete 100 was taken\n",
    "# Source_df = Source_df.iloc[100:]\n",
    "# Source_df = Source_df.drop(['ManDis'], axis =1)\n",
    "# Train_source_df = Train_source_df.drop(['ManDis'], axis =1)\n",
    "#\n",
    "# # print(Train_source_df.shape)\n",
    "# # print(Source_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(774, 7)\n",
      "(256, 7)\n",
      "(406, 7)\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################################################\n",
    "\n",
    "target_column = ['ConcreteCompressiveStrength']\n",
    "# target_column = ['medv']\n",
    "# target_column = ['mpg']\n",
    "\n",
    "Train_df = pd.concat([Train_df, Source_df], ignore_index=True)\n",
    "\n",
    "Train_df_y = Train_df[target_column]\n",
    "Train_df_X = Train_df.drop(target_column, axis = 1)\n",
    "\n",
    "Test_df_y = Test_df[target_column]\n",
    "Test_df_X = Test_df.drop(target_column, axis = 1)\n",
    "\n",
    "Source_df_y = Source_df[target_column]\n",
    "Source_df_X = Source_df.drop(target_column, axis = 1)\n",
    "\n",
    "print(Train_df_X.shape)\n",
    "print(Test_df_X.shape)\n",
    "print(Source_df_X.shape)\n",
    "\n",
    "## Merging the datasets\n",
    "X_df = pd.concat([Train_df_X, Test_df_X], ignore_index=True)\n",
    "y_df = pd.concat([Train_df_y, Test_df_y], ignore_index=True)\n",
    "\n",
    "np_train_X = X_df.to_numpy()\n",
    "np_train_y = y_df.to_numpy()\n",
    "\n",
    "np_source_X = Source_df_X.to_numpy()\n",
    "np_source_y = Source_df_y.to_numpy()\n",
    "\n",
    "np_train_y_list = np_train_y.ravel()\n",
    "\n",
    "# sample_size = [len(Target_df_X), len(Source_df_X)]\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of updated TrAdaboost.R2: 13.304089493657921\n",
      "RMSE of updated TrAdaboost.R2: 14.91072696784535\n",
      "Mean RMSE:  14.107408230751634\n"
     ]
    }
   ],
   "source": [
    "################################################TwoStageAdaBoostR2############################################################################\n",
    "\n",
    "kf = KFold(n_splits = 2) ## Create no. of CV Folds\n",
    "error = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_df):\n",
    "    X_train, X_test = np_train_X[train_idx], np_train_X[test_idx]\n",
    "    y_train, y_test = np_train_y[train_idx], np_train_y[test_idx]\n",
    "\n",
    "    sample_size = [len(Source_df_X), len(X_train)]\n",
    "\n",
    "    X_train_new = np.concatenate((np_source_X, X_train))\n",
    "    y_train_new = np.concatenate((np_source_y, y_train))\n",
    "\n",
    "    np_y_train_new_list = y_train_new.ravel()\n",
    "\n",
    "    regr_1 = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth = 6),\n",
    "                      n_estimators = n_estimators, sample_size = sample_size,\n",
    "                      steps = steps, fold = fold,\n",
    "                      random_state = random_state)\n",
    "    regr_1.fit(X_train_new, np_y_train_new_list)\n",
    "    y_pred2 = regr_1.predict(X_test)\n",
    "    mse_adaboost = sqrt(mean_squared_error(y_test, y_pred2))\n",
    "    print(\"RMSE of updated TrAdaboost.R2:\", mse_adaboost)\n",
    "    error.append(mse_adaboost)\n",
    "\n",
    "print(\"Mean RMSE: \", sum(error)/len(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
