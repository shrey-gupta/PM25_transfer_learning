{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories uploaded!!\n",
      "Second Upload Completed!!\n",
      "Third Upload Completed!!\n"
     ]
    }
   ],
   "source": [
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2 ##STrAdaBoost.R2\n",
    "# from TwoStageTrAdaBoostR2 import TwoStageTrAdaBoostR2 ##two-stage TrAdaBoost.R2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Dropout, Flatten\n",
    "from keras import optimizers, utils, initializers, regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler #Importing the StandardScaler\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "#Geo plotting libraries\n",
    "import geopandas as gdp\n",
    "from matplotlib.colors import ListedColormap\n",
    "# import geoplot as glpt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import statistics\n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import *\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "######### Instance Transfer repositories ####################\n",
    "from adapt.instance_based import TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Repositories uploaded!!\")\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "print(\"Second Upload Completed!!\")\n",
    "\n",
    "# Importing required Libraries for Plotting the Map\n",
    "\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Third Upload Completed!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 60627 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pm25_value', 'narr_dpt', 'narr_vis', 'nldas_pevapsfc',\n",
      "       'nldas_dlwrfsfc', 'nldas_dswrfsfc', 'nldas_cape', 'nldas_pressfc',\n",
      "       'nldas_tmp2m', 'nldas_rh2m', 'nldas_ugrd10m', 'nldas_vgrd10m',\n",
      "       'forest_cover', 'elev', 'emissi11', 'local', 'ISS', 'pd', 'gc_aod'],\n",
      "      dtype='object')\n",
      "(2856, 21)\n",
      "(1310, 21)\n",
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f236c4a08710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mmodel_GBRTL_us\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_TF_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_TF_train_y_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0my_pred_GBRTL_us\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_GBRTL_us\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_US_df_test_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# trees use different types for X and y, checking them separately.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[1;32m    410\u001b[0m                                    dtype=DTYPE, multi_output=True)\n\u001b[1;32m    411\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    646\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     96\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "########################################## Shorter Individual Datasets (US) ###############################################################\n",
    "\n",
    "US_df_train = pd.read_csv('US_data/US_10_slice/Train/Train_3.csv')\n",
    "US_train_droplist = ['cmaq_id', 'cmaq_x', 'cmaq_y', 'Latitude', 'Longitude', 'year', 'month', 'rid', 'clust']\n",
    "US_df_train = US_df_train.drop(US_train_droplist, axis = 1)\n",
    "US_df_train = US_df_train.rename(columns={\"is\": \"ISS\"})\n",
    "print(US_df_train.columns)\n",
    "\n",
    "US_df_transfer = pd.read_csv('US_data/US_10_slice/Transfer/Transfer_3.csv')\n",
    "# 'Latitude', 'Longitude',\n",
    "US_transfer_droplist = ['cmaq_id', 'cmaq_x', 'cmaq_y', 'year', 'month', 'rid', 'clust']\n",
    "US_df_transfer = US_df_transfer.drop(US_transfer_droplist, axis = 1)\n",
    "US_df_transfer = US_df_transfer.rename(columns={\"is\": \"ISS\"})\n",
    "print(US_df_transfer.shape)\n",
    "\n",
    "US_df_test = pd.read_csv('US_data/US_10_slice/Test/Test_3.csv')\n",
    "# 'Latitude', 'Longitude',\n",
    "US_test_droplist = ['cmaq_id', 'cmaq_x', 'cmaq_y', 'year', 'month', 'rid']\n",
    "US_df_test = US_df_test.drop(US_test_droplist, axis = 1)\n",
    "US_df_test = US_df_test.rename(columns={\"is\": \"ISS\"})\n",
    "print(US_df_test.shape)\n",
    "\n",
    "target_column = ['pm25_value']\n",
    "US_df_train_y = US_df_train[target_column]\n",
    "US_df_train_X = US_df_train.drop(target_column, axis = 1)\n",
    "\n",
    "US_df_transfer_y = US_df_transfer[target_column]\n",
    "US_df_transfer_X = US_df_transfer.drop(target_column, axis = 1)\n",
    "\n",
    "US_df_test_y = US_df_test[target_column]\n",
    "US_df_test_X = US_df_test.drop(target_column, axis = 1)\n",
    "\n",
    "TF_train_X = pd.concat([US_df_transfer_X, US_df_train_X], sort= False)\n",
    "TF_train_y = pd.concat([US_df_transfer_y, US_df_train_y], sort= False)\n",
    "\n",
    "np_TF_train_X = TF_train_X.to_numpy()\n",
    "np_TF_train_y = TF_train_y.to_numpy()\n",
    "\n",
    "# np_TF_train_X = US_df_train_X.to_numpy()\n",
    "# np_TF_train_y = US_df_train_y.to_numpy()\n",
    "\n",
    "np_US_df_test_X = US_df_test_X.to_numpy()\n",
    "np_US_df_test_y = US_df_test_y.to_numpy()\n",
    "\n",
    "np_TF_train_y_list = np_TF_train_y.ravel()\n",
    "np_US_df_test_y_list = np_US_df_test_y.ravel()\n",
    "\n",
    "# ####################### STrAdaBoost.R2 #########################################################\n",
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "# # sample_size = [166, 800]\n",
    "# sample_size = [len(US_df_train_X), len(US_df_transfer_X)]\n",
    "# n_estimators = 100\n",
    "# steps = 30\n",
    "# fold = 10\n",
    "# random_state = np.random.RandomState(1)\n",
    "\n",
    "# print(\"STrAdaBoost.R2 AS\")\n",
    "# print(\"-------------------------------------------\")\n",
    "\n",
    "# r2scorelist_stradaboost_us = []\n",
    "# rmselist_stradaboost_us = []\n",
    "\n",
    "# for x in range(0, 2):\n",
    "\n",
    "#     model_stradaboost_us = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth = 4),\n",
    "#                           n_estimators = n_estimators, sample_size = sample_size,\n",
    "#                           steps = steps, fold = fold,\n",
    "#                           random_state = random_state)\n",
    "    \n",
    "#     with joblib.parallel_backend('dask'):\n",
    "#         model_stradaboost_us.fit(np_TF_train_X, np_TF_train_y_list)\n",
    "#         y_pred_us = model_stradaboost_us.predict(np_US_df_test_X)\n",
    "\n",
    "#     mse_stradaboost_us = sqrt(mean_squared_error(np_US_df_test_y_list, y_pred_us))\n",
    "#     rmselist_stradaboost_us.append(mse_stradaboost_us)\n",
    "\n",
    "#     r2_score_stradaboost_us = pearsonr(np_US_df_test_y_list, y_pred_us)\n",
    "#     r2_score_stradaboost_us = (r2_score_stradaboost_us[0])**2\n",
    "#     r2scorelist_stradaboost_us.append(r2_score_stradaboost_us)\n",
    "    \n",
    "    \n",
    "# print(\"RMSE of STrAdaboost:\", statistics.mean(rmselist_stradaboost_us))\n",
    "# print(\"R^2 of STrAdaboost:\", statistics.mean(r2scorelist_stradaboost_us))\n",
    "# print(\"\\n\")\n",
    "# print(\"RMSE of STrAdaboost:\", rmselist_stradaboost_us)\n",
    "# print(\"R^2 of STrAdaboost:\", r2scorelist_stradaboost_us)\n",
    "\n",
    "# print(\"-------------------------------------------\")\n",
    "\n",
    "####################### GBR #########################################################\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_us = []\n",
    "rmselist_GBRTL_us = []\n",
    "\n",
    "for x in range(0, 10):\n",
    "\n",
    "    model_GBRTL_us = GradientBoostingRegressor(learning_rate=0.01, max_depth = 4, n_estimators=1000, subsample=0.5)\n",
    "    \n",
    "    with joblib.parallel_backend('dask'):\n",
    "        model_GBRTL_us.fit(np_TF_train_X, np_TF_train_y_list)\n",
    "        y_pred_GBRTL_us = model_GBRTL_us.predict(np_US_df_test_X) \n",
    "\n",
    "    rmse_GBRTL_us = sqrt(mean_squared_error(np_US_df_test_y_list, y_pred_GBRTL_us))\n",
    "    rmselist_GBRTL_us.append(rmse_GBRTL_us)\n",
    "    \n",
    "    r2_score_GBRTL_us = pearsonr(np_US_df_test_y_list, y_pred_GBRTL_us)\n",
    "    r2_score_GBRTL_us = (r2_score_GBRTL_us[0])**2\n",
    "    r2scorelist_GBRTL_us.append(r2_score_GBRTL_us)\n",
    "    \n",
    "print(\"RMSE of GBR:\", statistics.mean(rmselist_GBRTL_us))\n",
    "print(\"R^2 of GBR:\", statistics.mean(r2scorelist_GBRTL_us))\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of GBR:\", rmselist_GBRTL_us)\n",
    "print(\"R^2 of GBR:\", r2scorelist_GBRTL_us)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset extracted: \n",
      "(15, 21)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################################## Phase 1: Seeding Technique (US) ###################################################\n",
    "\n",
    "kmeans = KMeans(n_clusters = 15, random_state=0).fit(US_df_transfer)\n",
    "\n",
    "US_alternate_df = US_df_transfer.copy()\n",
    "US_alternate_df_np = US_df_transfer.to_numpy()\n",
    "\n",
    "idxlist = []\n",
    "US_new_df_list = []\n",
    "\n",
    "for rowkm in kmeans.cluster_centers_:\n",
    "    mindist = -99\n",
    "    rowidx = 0\n",
    "    idx = 0\n",
    "    for row in US_alternate_df_np:\n",
    "        dst = distance.euclidean(row, rowkm)\n",
    "\n",
    "        if(dst >= mindist):\n",
    "            mindist = dst\n",
    "            rowidx = idx\n",
    "            rowval = row\n",
    "\n",
    "        idx = idx + 1\n",
    "\n",
    "#     print(\"Row selected: \", rowidx) #Alternate_df.loc[rowidx,:]\\\n",
    "#     print(\"Min. distance: \", mindist)\n",
    "#     print(\"Matrix shape: \", kinematics_alternate_df_np.shape)\n",
    "    US_new_df_list.append(rowval)\n",
    "    US_alternate_df = np.delete(US_alternate_df_np, rowidx, 0)\n",
    "    idxlist.append(rowidx)\n",
    "\n",
    "\n",
    "US_new_df = pd.DataFrame(np.vstack(US_new_df_list))\n",
    "\n",
    "print(\"Shape of dataset extracted: \")\n",
    "print(US_new_df.shape)\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Shape of source before : (3173, 21)\n",
      "Shape of source after : (3157, 21)\n",
      "----------------------------------------------\n",
      "Shape of target before : (151, 19)\n",
      "Shape of target after : (166, 21)\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##################################################### Phase 2: Seeding (US) ################################################\n",
    "\n",
    "US_alternate_transfer_df = US_df_transfer[1:].copy()\n",
    "US_alternate_transfer_df_np = US_alternate_transfer_df.to_numpy()\n",
    "\n",
    "idxlist2 = []\n",
    "US_final_df_list = []\n",
    "\n",
    "for row_nm in US_new_df_list:\n",
    "    min_dist = -99\n",
    "    row_idx = 0\n",
    "    idx_val = 0\n",
    "    for row_alt in US_alternate_transfer_df_np:\n",
    "        dst = distance.euclidean(row_alt, row_nm)\n",
    "        if(dst >= mindist):\n",
    "            min_dist = dst\n",
    "            row_idx = idx_val\n",
    "            row_val = row_alt\n",
    "\n",
    "        idx_val = idx_val + 1\n",
    "\n",
    "#     print(\"Row selected: \", row_idx) #Alternate_df.loc[rowidx,:]\\\n",
    "#     print(\"Min. distance: \", min_dist)\n",
    "#     print(\"Matrix shape: \", Elevators_alternate_source_df_np.shape)\n",
    "    US_final_df_list.append(row_val)\n",
    "    US_alternate_transfer_df_np = np.delete(US_alternate_transfer_df_np, row_idx, 0)\n",
    "    idxlist2.append(row_idx)\n",
    "\n",
    "\n",
    "US_final_df = pd.DataFrame(np.vstack(US_final_df_list), columns = US_df_transfer.columns)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Shape of source before :\",US_df_transfer.shape)\n",
    "US_df_transfer = pd.DataFrame(np.vstack(US_alternate_transfer_df_np), columns= US_df_transfer.columns)\n",
    "print(\"Shape of source after :\", US_df_transfer.shape)\n",
    "\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"Shape of target before :\", US_df_train.shape)\n",
    "US_df_train = pd.concat([US_df_train, US_final_df], ignore_index=True)\n",
    "print(\"Shape of target after :\", US_df_train.shape)\n",
    "\n",
    "print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Set:  (166, 21)\n",
      "Source Set:  (800, 21)\n",
      "Test Set:  (1312, 21)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################## Finding best instances from the source dataset (US) ######################################################\n",
    "\n",
    "US_df_transfer[\"ManDis\"] = \"\"\n",
    "\n",
    "US_df_train_mean = []\n",
    "prow = US_df_train.mean()\n",
    "US_df_train_mean = [prow.pm25_value, prow.narr_dpt, prow.narr_vis, prow.nldas_pevapsfc, prow.nldas_dlwrfsfc, prow.nldas_dswrfsfc, \n",
    "                          prow.nldas_cape, prow.nldas_pressfc, prow.nldas_tmp2m, prow.nldas_rh2m, prow.nldas_ugrd10m, prow.nldas_vgrd10m,\n",
    "                          prow.forest_cover, prow.elev, prow.emissi11, prow.local, prow.ISS, prow.pd, prow.gc_aod]\n",
    "\n",
    "rowidx = 0\n",
    "\n",
    "for row in US_df_transfer.itertuples():\n",
    "    row_list =[row.pm25_value, row.narr_dpt, row.narr_vis, row.nldas_pevapsfc, row.nldas_dlwrfsfc, row.nldas_dswrfsfc, \n",
    "            row.nldas_cape, row.nldas_pressfc, row.nldas_tmp2m, row.nldas_rh2m, row.nldas_ugrd10m, row.nldas_vgrd10m,\n",
    "            row.forest_cover, row.elev, row.emissi11, row.local, row.ISS, row.pd, row.gc_aod]\n",
    "\n",
    "    man_dis = 0\n",
    "    for i in range(0, len(row_list)):\n",
    "        tempval = US_df_train_mean[i] - row_list[i]\n",
    "        man_dis = man_dis + abs(tempval)\n",
    "\n",
    "    US_df_transfer.loc[rowidx,\"ManDis\"] = man_dis\n",
    "    rowidx = rowidx + 1\n",
    "\n",
    "US_df_transfer = US_df_transfer.sort_values(by =['ManDis'])\n",
    "US_df_transfer = US_df_transfer.head(800) \n",
    "US_df_transfer = US_df_transfer.drop(['ManDis'], axis =1)\n",
    "US_df_transfer = US_df_transfer.reset_index(drop=True)\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "print(\"Target Set: \", US_df_train.shape)\n",
    "print(\"Source Set: \", US_df_transfer.shape)\n",
    "print(\"Test Set: \", US_df_test.shape)\n",
    "\n",
    "\n",
    "target_column = ['pm25_value']\n",
    "US_df_train_y = US_df_train[target_column]\n",
    "US_df_train_X = US_df_train.drop(target_column, axis = 1)\n",
    "\n",
    "US_df_transfer_y = US_df_transfer[target_column]\n",
    "US_df_transfer_X = US_df_transfer.drop(target_column, axis = 1)\n",
    "\n",
    "US_df_test_y = US_df_test[target_column]\n",
    "US_df_test_X = US_df_test.drop(target_column, axis = 1)\n",
    "\n",
    "TF_train_X = pd.concat([US_df_transfer_X, US_df_train_X], sort= False)\n",
    "TF_train_y = pd.concat([US_df_transfer_y, US_df_train_y], sort= False)\n",
    "\n",
    "np_TF_train_X = TF_train_X.to_numpy()\n",
    "np_TF_train_y = TF_train_y.to_numpy()\n",
    "\n",
    "# np_TF_train_X = US_df_train_X.to_numpy()\n",
    "# np_TF_train_y = US_df_train_y.to_numpy()\n",
    "\n",
    "np_US_df_test_X = US_df_test_X.to_numpy()\n",
    "np_US_df_test_y = US_df_test_y.to_numpy()\n",
    "\n",
    "np_TF_train_y_list = np_TF_train_y.ravel()\n",
    "np_US_df_test_y_list = np_US_df_test_y.ravel()\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n",
      "RMSE of GBR: 4.783353178405265\n",
      "R^2 of GBR: 0.3917969715012284\n",
      "\n",
      "\n",
      "RMSE of GBR: [4.777167680246299, 4.776656488331672, 4.792167633971575, 4.77982172902257, 4.819662721441523, 4.805859486893886, 4.831131502066503, 4.759630307946516, 4.79899446865215, 4.808078307972538, 4.7689097926498025, 4.761545761751902, 4.793867387103472, 4.8147914093882695, 4.7655625937951696, 4.765246636291876, 4.779461469008211, 4.761944550174594, 4.791395899000361, 4.769362149103635, 4.765730449509007, 4.811249776692141, 4.779585665372544, 4.743549312680322, 4.780654938545946, 4.7927558303344835, 4.785782876923928, 4.810800610707273, 4.772524942200618, 4.745572891314459, 4.734878251732028, 4.804620211382785, 4.780356293136857, 4.790355004233136, 4.77102131260422, 4.812287978346956, 4.788217867993365, 4.8012932096556415, 4.765265950503049, 4.721781386814165, 4.737439532293898, 4.810729928548911, 4.751732121372508, 4.80832855705341, 4.816462301067072, 4.792097163774371, 4.7897926580084285, 4.81020141698841, 4.792438625035763, 4.778893880625029]\n",
      "R^2 of GBR: [0.38916955133305936, 0.39037782721383596, 0.3861871773811096, 0.3953369879322334, 0.3812010394553908, 0.3849627978582112, 0.3841074230103126, 0.395341645956269, 0.3839589129137966, 0.3880321095992463, 0.39927748102916477, 0.39746121807111323, 0.3858000845257915, 0.3795166568191789, 0.3967760051565094, 0.3943938715397229, 0.39662299710993276, 0.4005223150880656, 0.3895640581046315, 0.39763343566084874, 0.4001617771234316, 0.3859955461632285, 0.3925803686370709, 0.40383179437731415, 0.3942094496384139, 0.3842582952057179, 0.3953884692909665, 0.3813714413945278, 0.39646075778754025, 0.39643253779334947, 0.4021623584630275, 0.3872082635271912, 0.3958375420753303, 0.3899998937289111, 0.4016818586480059, 0.38257468988235344, 0.3895390138605489, 0.3925255536806325, 0.3947933941618586, 0.40879255101961304, 0.40553132427320987, 0.3837773089849632, 0.40199466992639005, 0.38366046870530224, 0.3825173268230283, 0.38452050173360225, 0.3888370756021678, 0.3857012057238791, 0.38388949839340286, 0.3973700426780148]\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "####################### GBR #########################################################\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_us = []\n",
    "rmselist_GBRTL_us = []\n",
    "\n",
    "for x in range(0, 50):\n",
    "\n",
    "    model_GBRTL_us = GradientBoostingRegressor(learning_rate=0.01, max_depth = 4, n_estimators=1000, subsample=0.5)\n",
    "    model_GBRTL_us.fit(np_TF_train_X, np_TF_train_y_list)\n",
    "\n",
    "\n",
    "    y_pred_GBRTL_us = model_GBRTL_us.predict(np_US_df_test_X) \n",
    "\n",
    "    rmse_GBRTL_us = sqrt(mean_squared_error(np_US_df_test_y_list, y_pred_GBRTL_us))\n",
    "    rmselist_GBRTL_us.append(rmse_GBRTL_us)\n",
    "    \n",
    "    r2_score_GBRTL_us = pearsonr(np_US_df_test_y_list, y_pred_GBRTL_us)\n",
    "    r2_score_GBRTL_us = (r2_score_GBRTL_us[0])**2\n",
    "    r2scorelist_GBRTL_us.append(r2_score_GBRTL_us)\n",
    "    \n",
    "print(\"RMSE of GBR:\", statistics.mean(rmselist_GBRTL_us))\n",
    "print(\"R^2 of GBR:\", statistics.mean(r2scorelist_GBRTL_us))\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of GBR:\", rmselist_GBRTL_us)\n",
    "print(\"R^2 of GBR:\", r2scorelist_GBRTL_us)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
