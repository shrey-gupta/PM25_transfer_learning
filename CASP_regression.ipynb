{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories uploaded!!\n",
      "Second Upload Completed!!\n",
      "CASP Data\n",
      "-------------------------------------------\n",
      "(45730, 10)\n",
      "Training Set:  (15195, 9)\n",
      "Source Set 1:  (15546, 9)\n",
      "Source Set 2:  (14989, 9)\n",
      "Final Source Set:  (30535, 9)\n",
      "Adaboost.R2 Transfer Learning (M + H, L)\n",
      "-------------------------------------------\n",
      "(1520, 8) (13675, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidwang/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2 ##STrAdaBoost.R2\n",
    "# from TwoStageTrAdaBoostR2 import TwoStageTrAdaBoostR2 ##two-stage TrAdaBoost.R2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Dropout, Flatten\n",
    "from keras import optimizers, utils, initializers, regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler #Importing the StandardScaler\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "#Geo plotting libraries\n",
    "import geopandas as gdp\n",
    "from matplotlib.colors import ListedColormap\n",
    "# import geoplot as glpt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import statistics\n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import *\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "######### Instance Transfer repositories ####################\n",
    "from adapt.instance_based import TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Repositories uploaded!!\")\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "print(\"Second Upload Completed!!\")\n",
    "\n",
    "\n",
    "################################### CASP ###########################################################################################################\n",
    "## Target Data: RMSD\n",
    "## Correlation col: F6\n",
    "## Cuts at: 105.0 and 160.0\n",
    "##########################################################################################################################################################\n",
    "\n",
    "casp_df = pd.read_csv(\"UCI_regression/Casp/CASP.csv\")\n",
    "\n",
    "print(\"CASP Data\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(casp_df.shape)\n",
    "\n",
    "# print(\"The correlation matrix is: \")\n",
    "# casp_df.corr()['RMSD'].abs().sort_values()\n",
    "\n",
    "drop_col_casp = ['F6']\n",
    "# casp_df['F6'].sort_values()\n",
    "\n",
    "\n",
    "casp_train_df = casp_df.loc[(casp_df['F6'] >= 105.0) & (casp_df['F6'] < 160.0)] \n",
    "casp_train_df = casp_train_df.drop(drop_col_casp, axis = 1)\n",
    "casp_train_df = casp_train_df.reset_index(drop = True)\n",
    "print(\"Training Set: \", casp_train_df.shape)\n",
    "\n",
    "casp_source1_df = casp_df.loc[(casp_df['F6'] < 105.0)]\n",
    "casp_source1_df = casp_source1_df.drop(drop_col_casp, axis = 1)\n",
    "casp_source1_df = casp_source1_df.reset_index(drop = True)\n",
    "print(\"Source Set 1: \", casp_source1_df.shape)\n",
    "\n",
    "casp_source2_df = casp_df.loc[(casp_df['F6'] >= 160.0)]\n",
    "casp_source2_df = casp_source2_df.drop(drop_col_casp, axis = 1)\n",
    "casp_source2_df = casp_source2_df.reset_index(drop = True)\n",
    "print(\"Source Set 2: \",casp_source2_df.shape)\n",
    "\n",
    "\n",
    "casp_source_df = pd.concat([casp_source1_df, casp_source2_df], ignore_index=True)\n",
    "print(\"Final Source Set: \",casp_source_df.shape)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_column_casp = ['RMSD']\n",
    "\n",
    "casp_train_df_y = casp_train_df[target_column_casp]\n",
    "casp_train_df_X = casp_train_df.drop(target_column_casp, axis = 1)\n",
    "\n",
    "casp_source_df_y = casp_source_df[target_column_casp]\n",
    "casp_source_df_X = casp_source_df.drop(target_column_casp, axis = 1)\n",
    "\n",
    "\n",
    "########################### Transfer Learning casp #####################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "\n",
    "\n",
    "print(\"Adaboost.R2 Transfer Learning (M + H, L)\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_AdaTL_casp = []\n",
    "rmselist_AdaTL_casp = []\n",
    "\n",
    "r2scorelist_Ada_casp = []\n",
    "rmselist_Ada_casp = []\n",
    "\n",
    "r2scorelist_KMM_casp = []\n",
    "rmselist_KMM_casp = []\n",
    "\n",
    "r2scorelist_GBRTL_casp = []\n",
    "rmselist_GBRTL_casp = []\n",
    "\n",
    "r2scorelist_GBR_casp = []\n",
    "rmselist_GBR_casp = []\n",
    "\n",
    "r2scorelist_TwoTrAda_casp = []\n",
    "rmselist_TwoTrAda_casp = []\n",
    "\n",
    "r2scorelist_stradaboost_casp = []\n",
    "rmselist_stradaboost_casp = []\n",
    "\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state=42, shuffle=False)\n",
    "\n",
    "for train_ix, test_ix in kfold.split(casp_train_df_X):\n",
    "    ############### get data ###############\n",
    "    casp_test_df_X, casp_tgt_df_X  = casp_train_df_X.iloc[train_ix], casp_train_df_X.iloc[test_ix] #### Make it opposite, so target size is small.\n",
    "    casp_test_df_y, casp_tgt_df_y  = casp_train_df_y.iloc[train_ix], casp_train_df_y.iloc[test_ix] #### Make it opposite, so target size is small.\n",
    "\n",
    "    print(casp_tgt_df_X.shape, casp_test_df_X.shape)\n",
    "\n",
    "    ############### Merging the datasets ##########################################\n",
    "    casp_X_df = pd.concat([casp_tgt_df_X, casp_source_df_X], ignore_index=True)\n",
    "    casp_y_df = pd.concat([casp_tgt_df_y, casp_source_df_y], ignore_index=True)\n",
    "\n",
    "    casp_np_train_X = casp_X_df.to_numpy()\n",
    "    casp_np_train_y = casp_y_df.to_numpy()\n",
    "\n",
    "    casp_np_test_X = casp_test_df_X.to_numpy()\n",
    "    casp_np_test_y = casp_test_df_y.to_numpy()\n",
    "\n",
    "    casp_np_train_y_list = casp_np_train_y.ravel()\n",
    "    casp_np_test_y_list = casp_np_test_y.ravel()\n",
    "\n",
    "    src_size_casp = len(casp_source_df_y)\n",
    "    tgt_size_casp = len(casp_tgt_df_y)\n",
    "\n",
    "    src_idx = np.arange(start=0, stop=(src_size_casp - 1), step=1)\n",
    "    tgt_idx = np.arange(start=src_size_casp, stop=((src_size_casp + tgt_size_casp)-1), step=1)\n",
    "\n",
    "\n",
    "    ################### AdaBoost Tl ###################\n",
    "    model_AdaTL_casp = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500)\n",
    "    model_AdaTL_casp.fit(casp_np_train_X, casp_np_train_y_list)\n",
    "\n",
    "    y_pred_AdaTL_casp = model_AdaTL_casp.predict(casp_np_test_X)\n",
    "\n",
    "    mse_AdaTL_casp = sqrt(mean_squared_error(casp_np_test_y, y_pred_AdaTL_casp))\n",
    "    rmselist_AdaTL_casp.append(mse_AdaTL_casp)\n",
    "\n",
    "    r2_score_AdaTL_casp = pearsonr(casp_np_test_y_list, y_pred_AdaTL_casp)\n",
    "    r2_score_AdaTL_casp = (r2_score_AdaTL_casp[0])**2\n",
    "    r2scorelist_AdaTL_casp.append(r2_score_AdaTL_casp)\n",
    "\n",
    "\n",
    "    ################### AdaBoost ###################\n",
    "    model_Ada_casp = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 8), learning_rate=0.01, n_estimators=500)\n",
    "    model_Ada_casp.fit(casp_tgt_df_X, casp_tgt_df_y)\n",
    "\n",
    "    y_pred_ada_casp = model_Ada_casp.predict(casp_np_test_X)\n",
    "\n",
    "    mse_Ada_casp = sqrt(mean_squared_error(casp_np_test_y, y_pred_ada_casp))\n",
    "    rmselist_Ada_casp.append(mse_Ada_casp)\n",
    "\n",
    "    r2_score_Ada_casp = pearsonr(casp_np_test_y_list, y_pred_ada_casp)\n",
    "    r2_score_Ada_casp = (r2_score_Ada_casp[0])**2\n",
    "    r2scorelist_Ada_casp.append(r2_score_Ada_casp)\n",
    "\n",
    "\n",
    "   ################### KMM ###################\n",
    "    model_KMM_casp = KMM(get_estimator = get_estimator)\n",
    "    model_KMM_casp.fit(casp_np_train_X, casp_np_train_y_list, src_idx, tgt_idx)\n",
    "\n",
    "    y_pred_KMM_casp = model_KMM_casp.predict(casp_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_KMM_casp = sqrt(mean_squared_error(casp_np_test_y, y_pred_KMM_casp))\n",
    "    rmselist_KMM_casp.append(mse_KMM_casp)\n",
    "\n",
    "    r2_score_KMM_casp = pearsonr(casp_np_test_y_list, y_pred_KMM_casp)\n",
    "    r2_score_KMM_casp = (r2_score_KMM_casp[0])**2\n",
    "    r2scorelist_KMM_casp.append(r2_score_KMM_casp)\n",
    "\n",
    "\n",
    "    ################### GBRTL ###################\n",
    "    model_GBRTL_casp = GradientBoostingRegressor(learning_rate = 0.01, max_depth = 4, n_estimators = 1000, subsample = 0.5)\n",
    "    model_GBRTL_casp.fit(casp_np_train_X, casp_np_train_y_list)\n",
    "\n",
    "    y_pred_GBRTL_casp = model_GBRTL_casp.predict(casp_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBRTL_casp = sqrt(mean_squared_error(casp_np_test_y, y_pred_GBRTL_casp))\n",
    "    rmselist_GBRTL_casp.append(mse_GBRTL_casp)\n",
    "\n",
    "    r2_score_GBRTL_casp = pearsonr(casp_np_test_y_list, y_pred_GBRTL_casp)\n",
    "    r2_score_GBRTL_casp = (r2_score_GBRTL_casp[0])**2\n",
    "    r2scorelist_GBRTL_casp.append(r2_score_GBRTL_casp)\n",
    "\n",
    "\n",
    "    ################### GBR ###################\n",
    "    model_GBR_casp = GradientBoostingRegressor(learning_rate=0.01, max_depth=4, n_estimators=1000, subsample=0.5)\n",
    "    model_GBR_casp.fit(casp_tgt_df_X, casp_tgt_df_y)\n",
    "\n",
    "    y_pred_GBR_casp = model_GBR_casp.predict(casp_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBR_casp = sqrt(mean_squared_error(casp_np_test_y, y_pred_GBR_casp))\n",
    "    rmselist_GBR_casp.append(mse_GBR_casp)\n",
    "\n",
    "    r2_score_GBR_casp = pearsonr(casp_np_test_y_list, y_pred_GBR_casp)\n",
    "    r2_score_GBR_casp = (r2_score_GBR_casp[0])**2\n",
    "    r2scorelist_GBR_casp.append(r2_score_GBR_casp)\n",
    "\n",
    "\n",
    "    ################### Two-TrAdaBoost ###################\n",
    "    from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "\n",
    "    model_TwoTrAda_casp = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 1000, cv=10) #, kwargs_TwoTrAda)\n",
    "    model_TwoTrAda_casp.fit(casp_np_train_X, casp_np_train_y_list, src_idx, tgt_idx)\n",
    "\n",
    "    y_pred_TwoTrAda_casp = model_TwoTrAda_casp.predict(casp_np_test_X)\n",
    "\n",
    "    mse_TwoTrAda_casp = sqrt(mean_squared_error(casp_np_test_y, y_pred_TwoTrAda_casp))\n",
    "    rmselist_TwoTrAda_casp.append(mse_TwoTrAda_casp)\n",
    "\n",
    "    r2_score_TwoTrAda_casp = pearsonr(casp_np_test_y_list, y_pred_TwoTrAda_casp)\n",
    "    r2_score_TwoTrAda_casp = (r2_score_TwoTrAda_casp[0])**2\n",
    "    r2scorelist_TwoTrAda_casp.append(r2_score_TwoTrAda_casp)\n",
    "\n",
    "\n",
    "    ################### STrAdaBoost ###################\n",
    "    from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "    sample_size = [len(casp_tgt_df_X), len(casp_source_df_X)]\n",
    "    n_estimators = 100\n",
    "    steps = 30\n",
    "    fold = 10\n",
    "    random_state = np.random.RandomState(1)\n",
    "\n",
    "\n",
    "    model_stradaboost_casp = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                        n_estimators = n_estimators, sample_size = sample_size,\n",
    "                        steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "    model_stradaboost_casp.fit(casp_np_train_X, casp_np_train_y_list)\n",
    "    y_pred_stradaboost_casp = model_stradaboost_casp.predict(casp_np_test_X)\n",
    "\n",
    "\n",
    "    mse_stradaboost_casp = sqrt(mean_squared_error(casp_np_test_y, y_pred_stradaboost_casp))\n",
    "    rmselist_stradaboost_casp.append(mse_stradaboost_casp)\n",
    "\n",
    "    r2_score_stradaboost_casp = pearsonr(casp_np_test_y_list, y_pred_stradaboost_casp)\n",
    "    r2_score_stradaboost_casp = (r2_score_stradaboost_casp[0])**2\n",
    "    r2scorelist_stradaboost_casp.append(r2_score_stradaboost_casp)\n",
    "\n",
    "\n",
    "\n",
    "with open('casp_rmse.txt', 'w') as casp_handle_rmse:\n",
    "    casp_handle_rmse.write(\"AdaBoost TL:\\n \")\n",
    "    casp_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_AdaTL_casp)\n",
    "\n",
    "    casp_handle_rmse.write(\"\\n\\nAdaBoost:\\n \")\n",
    "    casp_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_Ada_casp)\n",
    "\n",
    "    casp_handle_rmse.write(\"\\n\\nKMM:\\n \")\n",
    "    casp_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_KMM_casp)\n",
    "\n",
    "    casp_handle_rmse.write(\"\\n\\nGBRT:\\n \")\n",
    "    casp_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_GBRTL_casp)\n",
    "\n",
    "    casp_handle_rmse.write(\"\\n\\nGBR:\\n \")\n",
    "    casp_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_GBR_casp)\n",
    "\n",
    "    casp_handle_rmse.write(\"\\n\\nTrAdaBoost:\\n \")\n",
    "    casp_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_TwoTrAda_casp)\n",
    "\n",
    "    casp_handle_rmse.write(\"\\n\\nSTrAdaBoost:\\n \")\n",
    "    casp_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_stradaboost_casp)\n",
    "\n",
    "\n",
    "with open('casp_r2.txt', 'w') as casp_handle_r2:\n",
    "    casp_handle_r2.write(\"AdaBoost TL:\\n \")\n",
    "    casp_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_AdaTL_casp)\n",
    "\n",
    "    casp_handle_r2.write(\"\\n\\nAdaBoost:\\n \")\n",
    "    casp_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_Ada_casp)\n",
    "\n",
    "    casp_handle_r2.write(\"\\n\\nKMM:\\n \")\n",
    "    casp_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_KMM_casp)\n",
    "\n",
    "    casp_handle_r2.write(\"\\n\\nGBRT:\\n \")\n",
    "    casp_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_GBRTL_casp)\n",
    "\n",
    "    casp_handle_r2.write(\"\\n\\nGBR:\\n \")\n",
    "    casp_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_GBR_casp)\n",
    "\n",
    "    casp_handle_r2.write(\"\\n\\nTrAdaBoost:\\n \")\n",
    "    casp_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_TwoTrAda_casp)\n",
    "\n",
    "    casp_handle_r2.write(\"\\n\\nSTrAdaBoost:\\n \")\n",
    "    casp_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_stradaboost_casp)\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "# print(\"RMSE of Adaboost.R2(TL):\", statistics.mean(rmselist_AdaTL_casp))\n",
    "# print(\"R^2 of AdaboostR2(TL):\", statistics.mean(r2scorelist_AdaTL_casp))\n",
    "# print(\"\\n\")\n",
    "# print(\"RMSE of Adaboost.R2(TL):\", rmselist_AdaTL_casp)\n",
    "# print(\"R^2 of AdaboostR2(TL):\", r2scorelist_AdaTL_casp)\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
