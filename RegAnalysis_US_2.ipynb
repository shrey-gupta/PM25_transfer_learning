{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories uploaded!!\n"
     ]
    }
   ],
   "source": [
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2 ##STrAdaBoost.R2\n",
    "# from TwoStageTrAdaBoostR2 import TwoStageTrAdaBoostR2 ##two-stage TrAdaBoost.R2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Dropout, Flatten\n",
    "from keras import optimizers, utils, initializers, regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler #Importing the StandardScaler\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "#Geo plotting libraries\n",
    "import geopandas as gdp\n",
    "from matplotlib.colors import ListedColormap\n",
    "# import geoplot as glpt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import statistics\n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import *\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "######### Instance Transfer repositories ####################\n",
    "from adapt.instance_based import TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Repositories uploaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Upload Completed!!\n"
     ]
    }
   ],
   "source": [
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "print(\"Second Upload Completed!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5353, 62)\n",
      "(2881, 62)\n"
     ]
    }
   ],
   "source": [
    "########################################## Larger Dataset (US) ###############################################################\n",
    "\n",
    "US_df = pd.read_csv('US_Monthly_2011.csv')\n",
    "# US_df = US_df.sort_values(by = ['rid'])\n",
    "# print(\"Count values before the drop: \")\n",
    "# print(US_df['rid'].value_counts())\n",
    "# print(US_df.isnull().sum().sum())\n",
    "US_df = US_df.dropna()\n",
    "# print(\"Count values after the drop: \")\n",
    "# print(US_df['rid'].value_counts())\n",
    "\n",
    "\n",
    "Source_US_df = US_df.loc[US_df['rid'].isin(['3', '4', '5', '9'])]\n",
    "Target_US_df = US_df.loc[US_df['rid'].isin(['1','2','6','7','8'])]\n",
    "\n",
    "train_Target_US_df = Target_US_df.loc[Target_US_df['rid'].isin(['2','7','8'])]\n",
    "test_Target_US_df = Target_US_df.loc[Target_US_df['rid'].isin(['1','6'])]\n",
    "\n",
    "drop_rid = ['rid']\n",
    "Source_US_df = Source_US_df.drop(drop_rid, axis =1)\n",
    "train_Target_US_df = train_Target_US_df.drop(drop_rid, axis =1)\n",
    "test_Target_US_df = test_Target_US_df.drop(drop_rid, axis =1)\n",
    "\n",
    "target_column = ['pm25_value']\n",
    "Source_US_df_y = Source_US_df[target_column]\n",
    "Source_US_df_X = Source_US_df.drop(target_column, axis = 1)\n",
    "\n",
    "train_Target_US_df_y = train_Target_US_df[target_column]\n",
    "train_Target_US_df_X = train_Target_US_df.drop(target_column, axis = 1)\n",
    "\n",
    "test_Target_US_df_y = test_Target_US_df[target_column]\n",
    "test_Target_US_df_X = test_Target_US_df.drop(target_column, axis = 1)\n",
    "\n",
    "TF_train_X = pd.concat([Source_US_df_X, train_Target_US_df_X], sort= False)\n",
    "TF_train_y = pd.concat([Source_US_df_y, train_Target_US_df_y], sort= False)\n",
    "\n",
    "np_TF_train_X = TF_train_X.to_numpy()\n",
    "np_TF_train_y = TF_train_y.to_numpy()\n",
    "np_test_Target_US_df_X = test_Target_US_df_X.to_numpy()\n",
    "np_test_Target_US_df_y = test_Target_US_df_y.to_numpy()\n",
    "\n",
    "np_TF_train_y_list = np_TF_train_y.ravel()\n",
    "np_test_Target_US_df_y_list = np_test_Target_US_df_y.ravel()\n",
    "\n",
    "print(Source_US_df_X.shape)\n",
    "print(train_Target_US_df_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 19)\n",
      "(3442, 19)\n",
      "(1310, 19)\n"
     ]
    }
   ],
   "source": [
    "########################################## Shorter Individual Datasets (US) ###############################################################\n",
    "\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "US_df_train = pd.read_csv('US_data/US_10_slice/Train/Train_5.csv')\n",
    "US_train_droplist = ['cmaq_id', 'cmaq_x', 'cmaq_y', 'Latitude', 'Longitude', 'year', 'month', 'rid', 'clust']\n",
    "US_df_train = US_df_train.drop(US_train_droplist, axis = 1)\n",
    "US_df_train = US_df_train.rename(columns={\"is\": \"ISS\"})\n",
    "\n",
    "US_cols = US_df_train.columns.difference(['pm25_value'])\n",
    "\n",
    "US_df_train[US_cols] = ss.fit_transform(US_df_train[US_cols])\n",
    "print(US_df_train.shape)\n",
    "\n",
    "US_df_transfer = pd.read_csv('US_data/US_10_slice/Transfer/Transfer_5.csv')\n",
    "US_transfer_droplist = ['cmaq_id', 'cmaq_x', 'cmaq_y', 'Latitude', 'Longitude', 'year', 'month', 'rid', 'clust']\n",
    "US_df_transfer = US_df_transfer.drop(US_transfer_droplist, axis = 1)\n",
    "US_df_transfer = US_df_transfer.rename(columns={\"is\": \"ISS\"})\n",
    "\n",
    "US_df_transfer[US_cols] = ss.fit_transform(US_df_transfer[US_cols])\n",
    "print(US_df_transfer.shape)\n",
    "\n",
    "US_df_test = pd.read_csv('US_data/US_10_slice/Test/Test_5.csv')\n",
    "US_test_droplist = ['cmaq_id', 'cmaq_x', 'cmaq_y', 'Latitude', 'Longitude', 'year', 'month', 'rid']\n",
    "US_df_test = US_df_test.drop(US_test_droplist, axis = 1)\n",
    "US_df_test = US_df_test.rename(columns={\"is\": \"ISS\"})\n",
    "\n",
    "US_df_test[US_cols] = ss.fit_transform(US_df_test[US_cols])\n",
    "print(US_df_test.shape)\n",
    "\n",
    "\n",
    "############## Split into predictor and features ################\n",
    "target_column = ['pm25_value']\n",
    "US_df_train_y = US_df_train[target_column]\n",
    "US_df_train_X = US_df_train.drop(target_column, axis = 1)\n",
    "\n",
    "US_df_transfer_y = US_df_transfer[target_column]\n",
    "US_df_transfer_X = US_df_transfer.drop(target_column, axis = 1)\n",
    "\n",
    "US_df_test_y = US_df_test[target_column]\n",
    "US_df_test_X = US_df_test.drop(target_column, axis = 1)\n",
    "\n",
    "############ Merge and make a numpy array #########################\n",
    "TF_train_X = pd.concat([US_df_transfer_X, US_df_train_X], sort= False)\n",
    "TF_train_y = pd.concat([US_df_transfer_y, US_df_train_y], sort= False)\n",
    "\n",
    "np_TF_train_X = TF_train_X.to_numpy()\n",
    "np_TF_train_y = TF_train_y.to_numpy()\n",
    "\n",
    "# np_TF_train_X = US_df_train_X.to_numpy()\n",
    "# np_TF_train_y = US_df_train_y.to_numpy()\n",
    "\n",
    "np_US_df_test_X = US_df_test_X.to_numpy()\n",
    "np_US_df_test_y = US_df_test_y.to_numpy()\n",
    "\n",
    "np_TF_train_y_list = np_TF_train_y.ravel()\n",
    "np_US_df_test_y_list = np_US_df_test_y.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Set:  (153, 19)\n",
      "Source Set:  (714, 19)\n",
      "Test Set:  (1310, 19)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################## Finding best instances from the source dataset (US) ######################################################\n",
    "\n",
    "US_df_transfer[\"ManDis\"] = \"\"\n",
    "\n",
    "US_df_train_mean = []\n",
    "prow = US_df_train.mean()\n",
    "US_df_train_mean = [prow.pm25_value, prow.narr_dpt, prow.narr_vis, prow.nldas_pevapsfc, prow.nldas_dlwrfsfc, prow.nldas_dswrfsfc, \n",
    "                          prow.nldas_cape, prow.nldas_pressfc, prow.nldas_tmp2m, prow.nldas_rh2m, prow.nldas_ugrd10m, prow.nldas_vgrd10m,\n",
    "                          prow.forest_cover, prow.elev, prow.emissi11, prow.local, prow.ISS, prow.pd, prow.gc_aod]\n",
    "\n",
    "rowidx = 0\n",
    "\n",
    "for row in US_df_transfer.itertuples():\n",
    "    row_list =[row.pm25_value, row.narr_dpt, row.narr_vis, row.nldas_pevapsfc, row.nldas_dlwrfsfc, row.nldas_dswrfsfc, \n",
    "            row.nldas_cape, row.nldas_pressfc, row.nldas_tmp2m, row.nldas_rh2m, row.nldas_ugrd10m, row.nldas_vgrd10m,\n",
    "            row.forest_cover, row.elev, row.emissi11, row.local, row.ISS, row.pd, row.gc_aod]\n",
    "\n",
    "    man_dis = 0\n",
    "    for i in range(0, len(row_list)):\n",
    "        tempval = US_df_train_mean[i] - row_list[i]\n",
    "        man_dis = man_dis + abs(tempval)\n",
    "\n",
    "    US_df_transfer.loc[rowidx,\"ManDis\"] = man_dis\n",
    "    rowidx = rowidx + 1\n",
    "\n",
    "US_df_transfer = US_df_transfer.sort_values(by =['ManDis'])\n",
    "US_df_transfer = US_df_transfer.head(714) \n",
    "US_df_transfer = US_df_transfer.drop(['ManDis'], axis =1)\n",
    "US_df_transfer = US_df_transfer.reset_index(drop=True)\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "print(\"Target Set: \", US_df_train.shape)\n",
    "print(\"Source Set: \", US_df_transfer.shape)\n",
    "print(\"Test Set: \", US_df_test.shape)\n",
    "\n",
    "\n",
    "target_column = ['pm25_value']\n",
    "US_df_train_y = US_df_train[target_column]\n",
    "US_df_train_X = US_df_train.drop(target_column, axis = 1)\n",
    "\n",
    "US_df_transfer_y = US_df_transfer[target_column]\n",
    "US_df_transfer_X = US_df_transfer.drop(target_column, axis = 1)\n",
    "\n",
    "US_df_test_y = US_df_test[target_column]\n",
    "US_df_test_X = US_df_test.drop(target_column, axis = 1)\n",
    "\n",
    "TF_train_X = pd.concat([US_df_transfer_X, US_df_train_X], sort= False)\n",
    "TF_train_y = pd.concat([US_df_transfer_y, US_df_train_y], sort= False)\n",
    "\n",
    "np_TF_train_X = TF_train_X.to_numpy()\n",
    "np_TF_train_y = TF_train_y.to_numpy()\n",
    "\n",
    "# np_TF_train_X = US_df_train_X.to_numpy()\n",
    "# np_TF_train_y = US_df_train_y.to_numpy()\n",
    "\n",
    "np_US_df_test_X = US_df_test_X.to_numpy()\n",
    "np_US_df_test_y = US_df_test_y.to_numpy()\n",
    "\n",
    "np_TF_train_y_list = np_TF_train_y.ravel()\n",
    "np_US_df_test_y_list = np_US_df_test_y.ravel()\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STrAdaBoost.R2 AS\n",
      "-------------------------------------------\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "RMSE of StrAdaboost: [5.729734963498598, 5.804636863702339, 5.6699154873885105, 6.025391937562782, 5.80057033331383, 5.6649735569851005, 5.976982997493459, 5.720269574604312, 5.880813960250914, 5.730236637922472]\n",
      "R^2 of StrAdaboost: [0.168297767321497, 0.14940461580334483, 0.1856700294292351, 0.10118219708460188, 0.14500331848798168, 0.1885604574932414, 0.1086757328862196, 0.17342487626334976, 0.12711076570335983, 0.16523277525726074]\n",
      "\n",
      "\n",
      "RMSE of StrAdaboost: 5.800352631272232 0.12471797023674308\n",
      "R^2 of StrAdaboost: 0.15125625357300918 0.030730296305573477\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "####################### STrAdaBoost.R2 #########################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "# sample_size = [len(US_df_transfer_X), len(US_df_train_X)]\n",
    "sample_size = [714, 153]\n",
    "\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "print(\"STrAdaBoost.R2 AS\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_stradaboost_us = []\n",
    "rmselist_stradaboost_us = []\n",
    "\n",
    "for x in range(0, 10):\n",
    "\n",
    "    model_stradaboost_us = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                          n_estimators = n_estimators, sample_size = sample_size,\n",
    "                          steps = steps, fold = fold,\n",
    "                          random_state = random_state)\n",
    "\n",
    "    model_stradaboost_us.fit(np_TF_train_X, np_TF_train_y_list)\n",
    "    y_pred_us = model_stradaboost_us.predict(np_US_df_test_X)\n",
    "\n",
    "    mse_stradaboost_us = sqrt(mean_squared_error(np_US_df_test_y_list, y_pred_us))\n",
    "    rmselist_stradaboost_us.append(mse_stradaboost_us)\n",
    "\n",
    "    r2_score_stradaboost_us = pearsonr(np_US_df_test_y_list, y_pred_us)\n",
    "    r2_score_stradaboost_us = (r2_score_stradaboost_us[0])**2\n",
    "    r2scorelist_stradaboost_us.append(r2_score_stradaboost_us)\n",
    "    \n",
    "print(\"RMSE of StrAdaboost:\", rmselist_stradaboost_us)\n",
    "print(\"R^2 of StrAdaboost:\", r2scorelist_stradaboost_us)\n",
    "\n",
    "print(\"\\n\")\n",
    "    \n",
    "print(\"RMSE of StrAdaboost:\", statistics.mean(rmselist_stradaboost_us), statistics.stdev(rmselist_stradaboost_us))\n",
    "print(\"R^2 of StrAdaboost:\", statistics.mean(r2scorelist_stradaboost_us), statistics.stdev(r2scorelist_stradaboost_us))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression\n",
      "-------------------------------------------\n",
      "RMSE of GBR: [5.340775527679069, 5.426111780305621, 5.471787607907473, 5.427058538518495, 5.387645786279188, 5.650975705744706, 5.466504809368625, 5.405203574316431, 5.328619349366162, 5.378858350707841]\n",
      "R^2 of GBR: [0.2684925416685895, 0.24787417031492454, 0.24535611992198594, 0.2537526063094502, 0.2553581767122477, 0.21340487983645212, 0.24746856029039668, 0.2556984120419787, 0.27171623225328023, 0.26007186993351367]\n",
      "\n",
      "\n",
      "RMSE of GBR: 5.428354103019361 0.09138988620992623\n",
      "R^2 of GBR: 0.25191935692828193 0.01607320712942802\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "####################### GBR Transfer Learning #########################################################\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_us = []\n",
    "rmselist_GBRTL_us = []\n",
    "\n",
    "for x in range(0, 10):\n",
    "\n",
    "    model_GBRTL_us = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100, subsample=0.5)\n",
    "    model_GBRTL_us.fit(np_TF_train_X, np_TF_train_y_list)\n",
    "\n",
    "\n",
    "    y_pred_GBRTL_us = model_GBRTL_us.predict(np_US_df_test_X) \n",
    "\n",
    "    rmse_GBRTL_us = sqrt(mean_squared_error(np_US_df_test_y_list, y_pred_GBRTL_us))\n",
    "    rmselist_GBRTL_us.append(rmse_GBRTL_us)\n",
    "    \n",
    "    r2_score_GBRTL_us = pearsonr(np_US_df_test_y_list, y_pred_GBRTL_us)\n",
    "    r2_score_GBRTL_us = (r2_score_GBRTL_us[0])**2\n",
    "    r2scorelist_GBRTL_us.append(r2_score_GBRTL_us)\n",
    "    \n",
    "print(\"RMSE of GBR:\", rmselist_GBRTL_us)\n",
    "print(\"R^2 of GBR:\", r2scorelist_GBRTL_us)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of GBR:\", statistics.mean(rmselist_GBRTL_us), statistics.stdev(rmselist_GBRTL_us))\n",
    "print(\"R^2 of GBR:\", statistics.mean(r2scorelist_GBRTL_us), statistics.stdev(r2scorelist_GBRTL_us))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Boosting Transfer Regression\n",
      "-------------------------------------------\n",
      "RMSE of Ada TL: [5.747322921182811, 5.8057066183958845, 5.66840828986415, 5.682139649401526, 5.683500710331262, 5.68877378822928, 5.7158050380774625, 5.732669488512051, 5.691906316240544, 5.717902628936855]\n",
      "R^2 of Ada TL: [0.18258223085087244, 0.14697368182965317, 0.19340897563867754, 0.18076452288646003, 0.17899511906268573, 0.18429778023297783, 0.17822771976905247, 0.16589719436897546, 0.18462884865254206, 0.17592551773366158]\n",
      "\n",
      "\n",
      "RMSE of Ada TL: 5.713413544917183 0.04086903932826141\n",
      "R^2 of Ada TL: 0.17717015910255582 0.012724644443972732\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "####################### AdaBoost TL #########################################################\n",
    "print(\"Adaptive Boosting Transfer Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_Ada_us = []\n",
    "rmselist_Ada_us = []\n",
    "\n",
    "for x in range(0, 10):\n",
    "    \n",
    "    model_Ada_us = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_Ada_us.fit(np_TF_train_X, np_TF_train_y_list)\n",
    "\n",
    "    y_pred_Ada_us = model_Ada_us.predict(np_US_df_test_X)\n",
    "    \n",
    "    rmse_Ada_us = sqrt(mean_squared_error(np_US_df_test_y_list, y_pred_Ada_us))\n",
    "    rmselist_Ada_us.append(rmse_Ada_us)\n",
    "    \n",
    "    r2_score_Ada_us = pearsonr(np_US_df_test_y_list, y_pred_Ada_us)\n",
    "    r2_score_Ada_us = (r2_score_Ada_us[0])**2\n",
    "    r2scorelist_Ada_us.append(r2_score_Ada_us)\n",
    "\n",
    "print(\"RMSE of Ada TL:\", rmselist_Ada_us)\n",
    "print(\"R^2 of Ada TL:\", r2scorelist_Ada_us)\n",
    "\n",
    "print(\"\\n\")\n",
    "    \n",
    "print(\"RMSE of Ada TL:\", statistics.mean(rmselist_Ada_us), statistics.stdev(rmselist_Ada_us))\n",
    "print(\"R^2 of Ada TL:\", statistics.mean(r2scorelist_Ada_us), statistics.stdev(r2scorelist_Ada_us))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
