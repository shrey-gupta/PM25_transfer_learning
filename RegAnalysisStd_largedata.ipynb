{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories uploaded!!\n"
     ]
    }
   ],
   "source": [
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2 ##STrAdaBoost.R2\n",
    "# from TwoStageTrAdaBoostR2 import TwoStageTrAdaBoostR2 ##two-stage TrAdaBoost.R2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "import statistics \n",
    "from scipy.stats import *\n",
    "from scipy.spatial import distance\n",
    "\n",
    "######### Instance Transfer repositories ####################\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "print(\"Repositories uploaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ailerons Data\n",
      "Training Set:  (7154, 41)\n",
      "Testing Set:  (6596, 41)\n",
      "-------------------------------------------\n",
      "Target Set:  (358, 41)\n",
      "Source Set:  (6796, 41)\n",
      "Test Set:  (6596, 41)\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################################################################ Ailerons ###############################################\n",
    "target_ailerons = ['goal']\n",
    "colnames_ailerons = ['climbRate', 'Sgz', 'p', 'q', 'curPitch', 'curRoll', 'absRoll', 'diffClb', 'diffRollRate', 'diffDiffClb', 'SeTime1',\n",
    "            'SeTime2', 'SeTime3', 'SeTime4', 'SeTime5', 'SeTime6', 'SeTime7', 'SeTime8', 'SeTime9', 'SeTime10', 'SeTime11', 'SeTime12', \n",
    "            'SeTime13', 'SeTime14', 'diffSeTime1', 'diffSeTime2', 'diffSeTime3', 'diffSeTime4', 'diffSeTime5', 'diffSeTime6', 'diffSeTime7',\n",
    "            'diffSeTime8', 'diffSeTime9', 'diffSeTime10', 'diffSeTime11', 'diffSeTime12', 'diffSeTime13', 'diffSeTime14', 'alpha', 'Se', 'goal']\n",
    "AileronsData_train_df = pd.read_csv('UCI_regression/Ailerons/ailerons.data', header = None, names = colnames_ailerons) \n",
    "print(\"Ailerons Data\")\n",
    "print(\"Training Set: \", AileronsData_train_df.shape)\n",
    "\n",
    "AileronsData_test_df = pd.read_csv('UCI_regression/Ailerons/ailerons.test', header = None, names = colnames_ailerons) \n",
    "print(\"Testing Set: \", AileronsData_test_df.shape)\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "############################################### Standardization ###############################################\n",
    "ailerons_cols = AileronsData_train_df.columns.difference(['goal'])\n",
    "ss = StandardScaler()\n",
    "AileronsData_train_df[ailerons_cols] = ss.fit_transform(AileronsData_train_df[ailerons_cols])\n",
    "AileronsData_test_df[ailerons_cols] = ss.transform(AileronsData_test_df[ailerons_cols]) ## Use the same scale as the training data\n",
    "\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "AileronsData_source_df, AileronsData_tgt_df = train_test_split(AileronsData_train_df, test_size = 0.05) ## test_size = tgt size\n",
    "# print(AileronsData_df_tgt.shape, AileronsData_df_source.shape, AileronsData_df_test.shape)\n",
    "\n",
    "AileronsData_train_df = AileronsData_train_df.reset_index(drop = True)\n",
    "AileronsData_tgt_df = AileronsData_tgt_df.reset_index(drop = True)\n",
    "AileronsData_source_df = AileronsData_source_df.reset_index(drop = True)\n",
    "print(\"Target Set: \", AileronsData_tgt_df.shape)\n",
    "print(\"Source Set: \", AileronsData_source_df.shape)\n",
    "print(\"Test Set: \", AileronsData_test_df.shape)\n",
    "\n",
    "\n",
    "AileronsData_df_test_y = AileronsData_test_df[target_ailerons]\n",
    "AileronsData_df_test_X = AileronsData_test_df.drop(target_ailerons, axis = 1)\n",
    "\n",
    "AileronsData_df_tgt_y = AileronsData_tgt_df[target_ailerons]\n",
    "AileronsData_df_tgt_X = AileronsData_tgt_df.drop(target_ailerons, axis = 1)\n",
    "\n",
    "AileronsData_df_source_y = AileronsData_source_df[target_ailerons]\n",
    "AileronsData_df_source_X = AileronsData_source_df.drop(target_ailerons, axis = 1)\n",
    "\n",
    "\n",
    "############## Merging the datasets #################\n",
    "ailerons_X_df = pd.concat([AileronsData_df_source_X, AileronsData_df_tgt_X], ignore_index=True)\n",
    "ailerons_y_df = pd.concat([AileronsData_df_source_y, AileronsData_df_tgt_y], ignore_index=True)\n",
    "\n",
    "ailerons_np_train_X = ailerons_X_df.to_numpy()\n",
    "ailerons_np_train_y = ailerons_y_df.to_numpy()\n",
    "\n",
    "ailerons_np_test_X = AileronsData_df_test_X.to_numpy()\n",
    "ailerons_np_test_y = AileronsData_df_test_y.to_numpy()\n",
    "\n",
    "ailerons_np_train_y_list = ailerons_np_train_y.ravel()\n",
    "ailerons_np_test_y_list = ailerons_np_test_y.ravel()\n",
    "\n",
    "src_size_ailerons = len(AileronsData_df_source_y)\n",
    "tgt_size_ailerons = len(AileronsData_df_tgt_y)\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Two-Stage TrAdaBoost.R2 Ailerons #######################################\n",
    "\n",
    "src_idx_ailerons = np.arange(start = 0, stop = (src_size_ailerons - 1), step = 1)\n",
    "tgt_idx_ailerons = np.arange(start = src_size_ailerons, stop = ((src_size_ailerons + tgt_size_ailerons)-1), step = 1)\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_TwoTrAda_ailerons = []\n",
    "rmselist_TwoTrAda_ailerons = []\n",
    "\n",
    "for x in range(0, 20):\n",
    "\n",
    "    model_TwoTrAda_ailerons = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv = 10) \n",
    "    model_TwoTrAda_ailerons.fit(ailerons_np_train_X, ailerons_np_train_y_list, src_idx_ailerons, tgt_idx_ailerons)\n",
    "\n",
    "    y_pred_TwoTrAda_ailerons = model_TwoTrAda_ailerons.predict(ailerons_np_test_X)\n",
    "\n",
    "    mse_TwoTrAda_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_TwoTrAda_ailerons))\n",
    "    rmselist_TwoTrAda_ailerons.append(mse_TwoTrAda_ailerons)\n",
    "        \n",
    "    r2_score_TwoTrAda_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_TwoTrAda_ailerons)\n",
    "    r2_score_TwoTrAda_ailerons = (r2_score_TwoTrAda_ailerons[0])**2\n",
    "    r2scorelist_TwoTrAda_ailerons.append(r2_score_TwoTrAda_ailerons)\n",
    "\n",
    "\n",
    "print(\"RMSE of TrAdaboost.R2:\", statistics.mean(rmselist_TwoTrAda_ailerons))\n",
    "print(\"R^2 of TrAdaboost.R2:\", statistics.mean(r2scorelist_TwoTrAda_ailerons))\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of TrAdaboost.R2:\", rmselist_TwoTrAda_ailerons)\n",
    "print(\"R^2 of TrAdaboostR2:\", r2scorelist_TwoTrAda_ailerons)\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### AdaBoostR2 Transfer Learning Ailerons #####################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_AdaTL_ailerons = []\n",
    "rmselist_AdaTL_ailerons = []\n",
    "\n",
    "for x in range(0, 30):\n",
    "\n",
    "    model_AdaTL_ailerons = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_AdaTL_ailerons.fit(ailerons_np_train_X, ailerons_np_train_y_list)\n",
    "\n",
    "    y_pred_AdaTL_ailerons = model_AdaTL_ailerons.predict(ailerons_np_test_X)\n",
    "\n",
    "    mse_AdaTL_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_AdaTL_ailerons))\n",
    "    rmselist_AdaTL_ailerons.append(mse_AdaTL_ailerons)\n",
    "        \n",
    "    r2_score_AdaTL_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_AdaTL_ailerons)\n",
    "    r2_score_AdaTL_ailerons = (r2_score_AdaTL_ailerons[0])**2\n",
    "    r2scorelist_AdaTL_ailerons.append(r2_score_AdaTL_ailerons)\n",
    "\n",
    "print(\"RMSE of Adaboost.R2:\", statistics.mean(rmselist_AdaTL_ailerons))\n",
    "print(\"R^2 of Adaboost.R2:\", statistics.mean(r2scorelist_AdaTL_ailerons))\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of Adaboost.R2:\", rmselist_AdaTL_ailerons)\n",
    "print(\"R^2 of Adaboost.R2:\", r2scorelist_AdaTL_ailerons)\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning Ailerons #######################################\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_ailerons = []\n",
    "rmselist_GBRTL_ailerons = []\n",
    "\n",
    "for x in range(0, 20):\n",
    "\n",
    "    model_GBRTL_ailerons = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100)\n",
    "    model_GBRTL_ailerons.fit(ailerons_np_train_X, ailerons_np_train_y_list)\n",
    "\n",
    "    y_pred_GBRTL_ailerons = model_GBRTL_ailerons.predict(AileronsData_df_test_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBRTL_ailerons = sqrt(mean_squared_error(ailerons_np_test_y, y_pred_GBRTL_ailerons))\n",
    "    rmselist_GBRTL_ailerons.append(mse_GBRTL_ailerons)\n",
    "        \n",
    "    r2_score_GBRTL_ailerons = pearsonr(ailerons_np_test_y_list, y_pred_GBRTL_ailerons)\n",
    "    r2_score_GBRTL_ailerons = (r2_score_GBRTL_ailerons[0])**2\n",
    "    r2scorelist_GBRTL_ailerons.append(r2_score_GBRTL_ailerons)\n",
    "\n",
    "    \n",
    "print(\"RMSE of GBRTL:\", statistics.mean(rmselist_GBRTL_ailerons))\n",
    "print(\"R^2 of GBRTL:\", statistics.mean(r2scorelist_GBRTL_ailerons))\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of GBRTL:\", rmselist_GBRTL_ailerons)\n",
    "print(\"R^2 of GBRTL:\", r2scorelist_GBRTL_ailerons)\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevators Data\n",
      "(8752, 19)\n",
      "(7847, 19)\n",
      "Target Set:  (438, 19)\n",
      "Source Set:  (8314, 19)\n",
      "Test Set:  (7847, 19)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "####################################### Elevators #########################################################\n",
    "target_elevators = ['Goal']\n",
    "colnames_elevators = ['climbRate', 'Sgz', 'p', 'q', 'curRoll', 'absRoll', 'diffClb', 'diffRollRate', 'diffDiffClb', 'SaTime1', 'SaTime2', \n",
    "                      'SaTime3', 'SaTime4', 'diffSaTime1', 'diffSaTime2', 'diffSaTime3', 'diffSaTime4', 'Sa', 'Goal']\n",
    "Elevators_train_df = pd.read_csv('UCI_regression/Elevators/elevators.data', header = None, names = colnames_elevators)\n",
    "print(\"Elevators Data\")\n",
    "print(Elevators_train_df.shape)\n",
    "\n",
    "Elevators_test_df = pd.read_csv('UCI_regression/Elevators/elevators.test', header = None, names = colnames_elevators)\n",
    "print(Elevators_test_df.shape)\n",
    "\n",
    "############################################### Standardization ###############################################\n",
    "elevators_cols = Elevators_train_df.columns.difference(['Goal'])\n",
    "ss = StandardScaler()\n",
    "Elevators_train_df[elevators_cols] = ss.fit_transform(Elevators_train_df[elevators_cols])\n",
    "Elevators_test_df[elevators_cols] = ss.transform(Elevators_test_df[elevators_cols]) ## Use the same scale as the training data\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "Elevators_source_df, Elevators_tgt_df = train_test_split(Elevators_train_df, test_size = 0.05) ## test_size = tgt size\n",
    "# print(Elevators_df_tgt.shape, Elevators_df_source.shape, Elevators_df_test.shape)\n",
    "\n",
    "Elevators_tgt_df = Elevators_tgt_df.reset_index(drop = True)\n",
    "Elevators_source_df = Elevators_source_df.reset_index(drop = True)\n",
    "print(\"Target Set: \", Elevators_tgt_df.shape)\n",
    "print(\"Source Set: \", Elevators_source_df.shape)\n",
    "print(\"Test Set: \", Elevators_test_df.shape)\n",
    "\n",
    "\n",
    "Elevators_test_df_y = Elevators_test_df[target_elevators]\n",
    "Elevators_test_df_X = Elevators_test_df.drop(target_elevators, axis = 1)\n",
    "\n",
    "Elevators_tgt_df_y = Elevators_tgt_df[target_elevators]\n",
    "Elevators_tgt_df_X = Elevators_tgt_df.drop(target_elevators, axis = 1)\n",
    "\n",
    "Elevators_source_df_y = Elevators_source_df[target_elevators]\n",
    "Elevators_source_df_X = Elevators_source_df.drop(target_elevators, axis = 1)\n",
    "\n",
    "\n",
    "############## Merging the datasets #################\n",
    "elevators_X_df = pd.concat([Elevators_source_df_X, Elevators_tgt_df_X], ignore_index=True)\n",
    "elevators_y_df = pd.concat([Elevators_source_df_y, Elevators_tgt_df_y], ignore_index=True)\n",
    "\n",
    "elevators_np_train_X = elevators_X_df.to_numpy()\n",
    "elevators_np_train_y = elevators_y_df.to_numpy()\n",
    "\n",
    "elevators_np_test_X = Elevators_test_df_X.to_numpy()\n",
    "elevators_np_test_y = Elevators_test_df_y.to_numpy()\n",
    "\n",
    "elevators_np_train_y_list = elevators_np_train_y.ravel()\n",
    "elevators_np_test_y_list = elevators_np_test_y.ravel()\n",
    "\n",
    "src_size_elevators = len(Elevators_source_df_y)\n",
    "tgt_size_elevators = len(Elevators_tgt_df_y)\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Elevators #######################################\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "\n",
    "############# Transfer Learning specifications #########################\n",
    "src_idx_elevators = np.arange(start=0, stop=(src_size_elevators - 1), step=1)\n",
    "tgt_idx_elevators = np.arange(start=src_size_elevators, stop=((src_size_elevators + tgt_size_elevators)-1), step=1)\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_TwoTrAda_elevators = []\n",
    "rmselist_TwoTrAda_elevators = []\n",
    "\n",
    "for x in range(0, 10):\n",
    "\n",
    "    model_TwoTrAda_elevators = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100, cv = 10) \n",
    "    model_TwoTrAda_elevators.fit(elevators_np_train_X, elevators_np_train_y_list, src_idx_elevators, tgt_idx_elevators)\n",
    "\n",
    "    y_pred_TwoTrAda_elevators = model_TwoTrAda_elevators.predict(elevators_np_test_X)\n",
    "\n",
    "    mse_TwoTrAda_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_TwoTrAda_elevators))\n",
    "    rmselist_TwoTrAda_elevators.append(mse_TwoTrAda_elevators)\n",
    "        \n",
    "    r2_score_TwoTrAda_elevators = pearsonr(elevators_np_test_y_list, y_pred_TwoTrAda_elevators)\n",
    "    r2_score_TwoTrAda_elevators = (r2_score_TwoTrAda_elevators[0])**2\n",
    "\n",
    "    r2scorelist_TwoTrAda_elevators.append(r2_score_TwoTrAda_elevators)\n",
    "\n",
    "\n",
    "print(\"RMSE of TrAdaboost.R2:\", statistics.mean(rmselist_TwoTrAda_elevators))\n",
    "print(\"R^2 of TrAdaboostR2:\", statistics.mean(r2scorelist_TwoTrAda_elevators))\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of TrAdaboost.R2:\", rmselist_TwoTrAda_elevators)\n",
    "print(\"R^2 of TrAdaboostR2:\", r2scorelist_TwoTrAda_elevators)\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning Elevators #######################################\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_elevators = []\n",
    "rmselist_GBRTL_elevators = []\n",
    "\n",
    "for x in range(0, 10):\n",
    "\n",
    "    model_GBRTL_elevators = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100)\n",
    "    model_GBRTL_elevators.fit(elevators_np_train_X, elevators_np_train_y_list)\n",
    "\n",
    "    y_pred_GBRTL_elevators = model_GBRTL_elevators.predict(elevators_np_test_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBRTL_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_GBRTL_elevators))\n",
    "    rmselist_GBRTL_elevators.append(mse_GBRTL_elevators)\n",
    "        \n",
    "    r2_score_GBRTL_elevators = pearsonr(elevators_np_test_y_list, y_pred_GBRTL_elevators)\n",
    "    r2_score_GBRTL_elevators = (r2_score_GBRTL_elevators[0])**2\n",
    "    r2scorelist_GBRTL_elevators.append(r2_score_GBRTL_elevators)\n",
    "\n",
    "\n",
    "print(\"RMSE of GBRTL:\", statistics.mean(rmselist_GBRTL_elevators))\n",
    "print(\"R^2 of GBRTL:\", statistics.mean(r2scorelist_GBRTL_elevators))\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of GBRTL:\", rmselist_GBRTL_elevators)\n",
    "print(\"R^2 of GBRTL:\", r2scorelist_GBRTL_elevators)\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abalone Data\n",
      "(4177, 9)\n",
      "Target Set:  (1241, 8)\n",
      "Source Set 1:  (1465, 8)\n",
      "Source Set 2:  (1471, 8)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################### Abalone ###########################################\n",
    "#### range: [0.0 - 1.130]\n",
    "#### Mid of correlation variable: Whole_weight\n",
    "#### [0, 0.12] [0.12, 0.15], [0.15, 1.130]\n",
    "#### Target variable: Rings\n",
    "#######################################################################################\n",
    "target_var_abalone = ['Rings']\n",
    "colnames_abalone = ['Sex', 'Length', 'Diameter', 'Height', 'Whole_weight', 'Shucked_weight', 'Viscera_weight', 'Shell_weight', 'Rings']\n",
    "AbaloneData_df = pd.read_csv('UCI_regression/Abalone/abalone.data', header = None, names = colnames_abalone)\n",
    "\n",
    "gender = {'M': 1,'F': 2, 'I': 3} \n",
    "AbaloneData_df.Sex = [gender[item] for item in AbaloneData_df.Sex] \n",
    "\n",
    "print(\"Abalone Data\")\n",
    "print(AbaloneData_df.shape)\n",
    "\n",
    "########## Corr Abalone ################\n",
    "# print(\"The correlation matrix is: \")\n",
    "# print(AbaloneData_df.corr()['Rings'])\n",
    "\n",
    "##################### Splitting in 3 equal parts #######################################\n",
    "# print(AbaloneData_df.sort_values('Whole_weight')['Whole_weight'])\n",
    "# print(len(AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] <= 0.5)]))\n",
    "# print(len(AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] > 0.5) & (AbaloneData_df['Whole_weight'] <= 1.0)]))\n",
    "# print(len(AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] > 1.0)]))\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "# AbaloneData_df_remain, AbaloneData_df_tgt = train_test_split(AbaloneData_df, test_size = 0.05) ## test_size = tgt size\n",
    "# AbaloneData_df_source, AbaloneData_df_test = train_test_split(AbaloneData_df_remain, test_size = 0.3) ## test_size = tgt size\n",
    "# print(AbaloneData_df_tgt.shape, AbaloneData_df_source.shape, AbaloneData_df_test.shape)\n",
    "\n",
    "\n",
    "drop_col_abalone = ['Whole_weight']\n",
    "\n",
    "abalone_tgt_df = AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] <= 0.5)]\n",
    "abalone_tgt_df = abalone_tgt_df.drop(drop_col_abalone, axis = 1)\n",
    "abalone_tgt_df = abalone_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",abalone_tgt_df.shape)\n",
    "\n",
    "abalone_source1_df = AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] > 0.5) & (AbaloneData_df['Whole_weight'] <= 1.0)]\n",
    "abalone_source1_df = abalone_source1_df.drop(drop_col_abalone, axis = 1)\n",
    "abalone_source1_df = abalone_source1_df.reset_index(drop=True)\n",
    "print(\"Source Set 1: \",abalone_source1_df.shape)\n",
    "\n",
    "abalone_source2_df = AbaloneData_df.loc[(AbaloneData_df['Whole_weight'] > 1.0)]\n",
    "abalone_source2_df = abalone_source2_df.drop(drop_col_abalone, axis = 1)\n",
    "abalone_source2_df = abalone_source2_df.reset_index(drop=True)\n",
    "print(\"Source Set 2: \",abalone_source2_df.shape)\n",
    "\n",
    "## Concatenating the source datasets\n",
    "abalone_source_df = pd.concat([abalone_source1_df, abalone_source2_df], ignore_index = True)\n",
    "abalone_source_df = abalone_source_df.reset_index(drop = True)\n",
    "\n",
    "\n",
    "print(\"---------------------------\")\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Set:  (1241, 8)\n",
      "Source Set:  (600, 8)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################## Finding best instances from the source dataset (Abalone) ######################################################\n",
    "\n",
    "abalone_source_df[\"ManDis\"] = \"\"\n",
    "\n",
    "abalone_tgt_df_mean = []\n",
    "prow = abalone_tgt_df.mean()\n",
    "abalone_tgt_df_mean = [prow.Sex, prow.Length, prow.Diameter, prow.Height, prow.Shucked_weight,\n",
    "       prow.Viscera_weight, prow.Shell_weight, prow.Rings]\n",
    "\n",
    "rowidx = 0\n",
    "\n",
    "for row in abalone_source_df.itertuples():\n",
    "    row_list =[row.Sex, row.Length, row.Diameter, row.Height, row.Shucked_weight,\n",
    "       row.Viscera_weight, row.Shell_weight, row.Rings]\n",
    "\n",
    "    man_dis = 0\n",
    "    for i in range(0, len(row_list)):\n",
    "        tempval = abalone_tgt_df_mean[i] - row_list[i]\n",
    "        man_dis = man_dis + abs(tempval)\n",
    "\n",
    "    abalone_source_df.loc[rowidx,\"ManDis\"] = man_dis\n",
    "    rowidx = rowidx + 1\n",
    "\n",
    "abalone_source_df = abalone_source_df.sort_values(by =['ManDis'])\n",
    "abalone_source_df = abalone_source_df.head(600) \n",
    "abalone_source_df = abalone_source_df.drop(['ManDis'], axis =1)\n",
    "abalone_source_df = abalone_source_df.reset_index(drop=True)\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "print(\"Target Set: \", abalone_tgt_df.shape)\n",
    "print(\"Source Set: \", abalone_source_df.shape)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_abalone = ['Rings']\n",
    "\n",
    "abalone_source_df_y = abalone_source_df[target_abalone]\n",
    "abalone_source_df_X = abalone_source_df.drop(target_abalone, axis = 1)\n",
    "\n",
    "features_abalone = abalone_source_df_X.columns\n",
    "\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "RMSE List of STrAdaboostR2: [1.2942680728626348, 1.8184918441218962, 1.8604795528456102, 3.253979220202562, 1.4154678343778357, 1.5344002482507897, 1.3124300225116543, 1.5205324768706319, 1.3735002537330483, 1.2547090476659521, 1.5200887670278884, 2.024785227732052, 2.313493699985706, 1.2528317076556974, 1.247709128306791, 1.5667480822174094, 1.9420634130488332, 1.4017035306055552, 1.8705258620386729, 1.1274923424922312]\n",
      "R^2 List of STrAdaboostR2: [0.5778137794272499, 0.510127385406228, 0.5549397369952896, 0.22024182881169582, 0.6989282951457836, 0.21131810025933265, 0.5886390651560783, 0.294777884110548, 0.28844857675282215, 0.4411470651551269, 0.48524284950854074, 0.3420756513632278, 0.49247174085244855, 0.5254159317328093, 0.5528106270508392, 0.49401225401124227, 0.562798051910745, 0.515117778556663, 0.4076035165134958, 0.4404878231452198]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 1.6452850167276727 0.49182829841805537\n",
      "Mean, STDev of R^2: 0.4602208970932693 0.13014762485864617\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Abalone ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "r2scorelist_stradaboost_abalone = []\n",
    "rmselist_stradaboost_abalone = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(abalone_tgt_df):\n",
    "        \n",
    "    abalone_train_df_X = abalone_tgt_df.iloc[train_idx].loc[:, features_abalone]\n",
    "    abalone_test_df_X = abalone_tgt_df.iloc[test_idx][features_abalone]\n",
    "    abalone_train_df_y = abalone_tgt_df.iloc[train_idx].loc[:,target_abalone]\n",
    "    abalone_test_df_y = abalone_tgt_df.loc[test_idx][target_abalone] \n",
    "    \n",
    "    abalone_X_df = pd.concat([abalone_source_df_X, abalone_train_df_X], ignore_index=True)\n",
    "    abalone_y_df = pd.concat([abalone_source_df_y, abalone_train_df_y], ignore_index=True)\n",
    "\n",
    "    abalone_np_train_X = abalone_X_df.to_numpy()\n",
    "    abalone_np_train_y = abalone_y_df.to_numpy()\n",
    "\n",
    "    abalone_np_test_X = abalone_test_df_X.to_numpy()\n",
    "    abalone_np_test_y = abalone_test_df_y.to_numpy()\n",
    "\n",
    "    abalone_np_train_y_list = abalone_np_train_y.ravel()\n",
    "    abalone_np_test_y_list = abalone_np_test_y.ravel()\n",
    "    \n",
    "    sample_size = [len(abalone_source_df_X), len(abalone_train_df_X)]\n",
    "\n",
    "    model_stradaboost_abalone = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                        n_estimators = n_estimators, sample_size = sample_size,\n",
    "                        steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "    model_stradaboost_abalone.fit(abalone_np_train_X, abalone_np_train_y_list)\n",
    "    y_pred_stradaboost_abalone = model_stradaboost_abalone.predict(abalone_np_test_X)\n",
    "\n",
    "    mse_stradaboost_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_stradaboost_abalone))\n",
    "    rmselist_stradaboost_abalone.append(mse_stradaboost_abalone)\n",
    "        \n",
    "    r2_score_stradaboost_abalone = pearsonr(abalone_np_test_y_list, y_pred_stradaboost_abalone)\n",
    "    r2_score_stradaboost_abalone = (r2_score_stradaboost_abalone[0])**2\n",
    "    r2scorelist_stradaboost_abalone.append(r2_score_stradaboost_abalone)\n",
    "\n",
    "print(\"RMSE List of STrAdaboostR2:\", rmselist_stradaboost_abalone)\n",
    "print(\"R^2 List of STrAdaboostR2:\", r2scorelist_stradaboost_abalone)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_stradaboost_abalone), statistics.stdev(rmselist_stradaboost_abalone))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_stradaboost_abalone), statistics.stdev(r2scorelist_stradaboost_abalone))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE List of TrAdaboost.R2: [2.3358154162536287, 2.6661149965277686, 2.9700755341610456, 3.2989531191802075, 2.2826498024306305, 2.0970523775620404, 2.0177380256371706, 1.8891152313622421, 2.752497388381207, 2.0542435141488022, 2.439907047558311, 2.835558420174797, 2.025763138898031, 1.9647481501725805, 2.344466033777315, 2.5560365813518255, 2.3600544608585694, 1.978096310462208, 2.646185453086457, 2.025808493314089]\n",
      "R^2 List of TrAdaboost.R2: [0.49319968046465007, 0.5379373907098207, 0.46260967123422536, 0.4867972870526036, 0.6080447463524427, 0.3023703738787406, 0.42381633136776686, 0.4574925001043787, 0.3289007157474186, 0.4268819720280001, 0.5229254826839679, 0.3240890792733061, 0.6913370705969084, 0.4550277813086461, 0.4128672587159948, 0.4264490187979004, 0.5020003908303805, 0.5097270723177003, 0.4088837015973851, 0.4647667318364844]\n",
      "\n",
      "\n",
      "Mean, Stdev of RMSE: 2.3770439747649466 0.3894959849588865\n",
      "Mean, Stdev of R^2: 0.46230621284493606 0.09186696319077892\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Abalone #######################################\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_TwoTrAda_abalone = []\n",
    "rmselist_TwoTrAda_abalone = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(abalone_tgt_df):\n",
    "        \n",
    "    abalone_train_df_X = abalone_tgt_df.iloc[train_idx].loc[:, features_abalone]\n",
    "    abalone_test_df_X = abalone_tgt_df.iloc[test_idx][features_abalone]\n",
    "    abalone_train_df_y = abalone_tgt_df.iloc[train_idx].loc[:,target_abalone]\n",
    "    abalone_test_df_y = abalone_tgt_df.loc[test_idx][target_abalone] \n",
    "    \n",
    "    abalone_X_df = pd.concat([abalone_source_df_X, abalone_train_df_X], ignore_index=True)\n",
    "    abalone_y_df = pd.concat([abalone_source_df_y, abalone_train_df_y], ignore_index=True)\n",
    "\n",
    "    abalone_np_train_X = abalone_X_df.to_numpy()\n",
    "    abalone_np_train_y = abalone_y_df.to_numpy()\n",
    "\n",
    "    abalone_np_test_X = abalone_test_df_X.to_numpy()\n",
    "    abalone_np_test_y = abalone_test_df_y.to_numpy()\n",
    "\n",
    "    abalone_np_train_y_list = abalone_np_train_y.ravel()\n",
    "    abalone_np_test_y_list = abalone_np_test_y.ravel()\n",
    "\n",
    "    src_size_abalone = len(abalone_source_df_y)\n",
    "    tgt_size_abalone = len(abalone_train_df_y)\n",
    "    \n",
    "    src_idx_abalone = np.arange(start = 0, stop = (src_size_abalone - 1), step = 1)\n",
    "    tgt_idx_abalone = np.arange(start = src_size_abalone, stop = ((src_size_abalone + tgt_size_abalone)-1), step=1)\n",
    "\n",
    "\n",
    "    model_TwoTrAda_abalone = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100) \n",
    "    model_TwoTrAda_abalone.fit(abalone_np_train_X, abalone_np_train_y_list, src_idx_abalone, tgt_idx_abalone)\n",
    "\n",
    "    y_pred_TwoTrAda_abalone = model_TwoTrAda_abalone.predict(abalone_np_test_X)\n",
    "\n",
    "    mse_TwoTrAda_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_TwoTrAda_abalone))\n",
    "    rmselist_TwoTrAda_abalone.append(mse_TwoTrAda_abalone)\n",
    "        \n",
    "    r2_score_TwoTrAda_abalone = pearsonr(abalone_np_test_y_list, y_pred_TwoTrAda_abalone)\n",
    "    r2_score_TwoTrAda_abalone = (r2_score_TwoTrAda_abalone[0])**2\n",
    "    r2scorelist_TwoTrAda_abalone.append(r2_score_TwoTrAda_abalone)\n",
    "\n",
    "print(\"RMSE List of TrAdaboost.R2:\", rmselist_TwoTrAda_abalone)\n",
    "print(\"R^2 List of TrAdaboost.R2:\", r2scorelist_TwoTrAda_abalone)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Mean, Stdev of RMSE:\", statistics.mean(rmselist_TwoTrAda_abalone), statistics.stdev(rmselist_TwoTrAda_abalone))\n",
    "print(\"Mean, Stdev of R^2:\", statistics.mean(r2scorelist_TwoTrAda_abalone), statistics.stdev(r2scorelist_TwoTrAda_abalone))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE List of Adaboost.R2 TL: [1.2504247494019327, 1.7657249668037305, 1.89569903377933, 3.2532755632102206, 1.4936185898283525, 1.4070485067715626, 1.2780691126409347, 1.2952120111369823, 1.2185132569760504, 1.1664952928318673, 1.4431519085733768, 1.9500910194428454, 2.363560140825891, 1.1378988286910905, 1.1343452679535926, 1.511106599638056, 1.8988885837677354, 1.1572423882973184, 1.8723490916485794, 1.0998007831649441]\n",
      "R^2 List of Adaboost.R2 TL: [0.5901314864496952, 0.5232221797175364, 0.5437723857569366, 0.23756770243906197, 0.6683812336475996, 0.23301984026064682, 0.6077878100647153, 0.352826224818253, 0.2830390415370179, 0.4396294459296463, 0.4683668644342236, 0.3649472972652102, 0.49633198407516443, 0.4752250341956109, 0.5698057437152155, 0.5273507252768682, 0.635721124383488, 0.5860177748898414, 0.3893848276174636, 0.4454354917910456]\n",
      "\n",
      "\n",
      "Mean, Stdev of RMSE: 1.5796257847692197 0.5290940312036921\n",
      "Mean, Stdev of R^2: 0.471898210913262 0.12851406705226057\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning Abalone #####################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_AdaTr_abalone = []\n",
    "rmselist_AdaTr_abalone = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(abalone_tgt_df):\n",
    "        \n",
    "    abalone_train_df_X = abalone_tgt_df.iloc[train_idx].loc[:, features_abalone]\n",
    "    abalone_test_df_X = abalone_tgt_df.iloc[test_idx][features_abalone]\n",
    "    abalone_train_df_y = abalone_tgt_df.iloc[train_idx].loc[:,target_abalone]\n",
    "    abalone_test_df_y = abalone_tgt_df.loc[test_idx][target_abalone] \n",
    "    \n",
    "    abalone_X_df = pd.concat([abalone_source_df_X, abalone_train_df_X], ignore_index=True)\n",
    "    abalone_y_df = pd.concat([abalone_source_df_y, abalone_train_df_y], ignore_index=True)\n",
    "\n",
    "    abalone_np_train_X = abalone_X_df.to_numpy()\n",
    "    abalone_np_train_y = abalone_y_df.to_numpy()\n",
    "\n",
    "    abalone_np_test_X = abalone_test_df_X.to_numpy()\n",
    "    abalone_np_test_y = abalone_test_df_y.to_numpy()\n",
    "\n",
    "    abalone_np_train_y_list = abalone_np_train_y.ravel()\n",
    "    abalone_np_test_y_list = abalone_np_test_y.ravel()\n",
    "\n",
    "\n",
    "    model_AdaTr_abalone = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_AdaTr_abalone.fit(abalone_np_train_X, abalone_np_train_y_list)\n",
    "\n",
    "    y_pred_AdaTr_abalone = model_AdaTr_abalone.predict(abalone_np_test_X)\n",
    "\n",
    "    mse_AdaTr_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_AdaTr_abalone))\n",
    "    rmselist_AdaTr_abalone.append(mse_AdaTr_abalone)\n",
    "        \n",
    "    r2_score_AdaTr_abalone = pearsonr(abalone_np_test_y_list, y_pred_AdaTr_abalone)\n",
    "    r2_score_AdaTr_abalone = (r2_score_AdaTr_abalone[0])**2\n",
    "    r2scorelist_AdaTr_abalone.append(r2_score_AdaTr_abalone)\n",
    "\n",
    "print(\"RMSE List of Adaboost.R2 TL:\", rmselist_AdaTr_abalone)\n",
    "print(\"R^2 List of Adaboost.R2 TL:\", r2scorelist_AdaTr_abalone)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Mean, Stdev of RMSE:\", statistics.mean(rmselist_AdaTr_abalone), statistics.stdev(rmselist_AdaTr_abalone))\n",
    "print(\"Mean, Stdev of R^2:\", statistics.mean(r2scorelist_AdaTr_abalone), statistics.stdev(r2scorelist_AdaTr_abalone))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of GBRTL: [1.396411605443678, 1.8378740199429298, 1.8271455594905333, 3.217428256994164, 1.6290472225941706, 1.2236063526759622, 1.2521234275778645, 1.373137309203999, 1.2843716646082113, 1.1118247260560632, 1.7826594807914964, 2.1438672848544416, 2.5464002094554448, 1.0332827703883227, 1.2116685836503465, 1.702678607615944, 2.0976420610431763, 1.1799921225691246, 1.8788661360109653, 1.1039443919080707]\n",
      "R^2 List of GBRTL: [0.5202927821512104, 0.5122182227076909, 0.5847241682437399, 0.23466672497860805, 0.6101592506920963, 0.22992309360030042, 0.49042684746186666, 0.21661178249367366, 0.23724000592729488, 0.4362241199348688, 0.34327071306640217, 0.30017811889421864, 0.37974289243959686, 0.47304264315281974, 0.5077155240416839, 0.4240262550703565, 0.5280310657185362, 0.469579216830239, 0.3863755039169853, 0.42588065671715275]\n",
      "\n",
      "\n",
      "Mean, Stdev of RMSE of GBRTL: 1.6416985896437455 0.554365305975001\n",
      "Mean, Stdev of R^2 of GBRTL: 0.41551647940196706 0.12131022441344184\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning Abalone #######################################\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_abalone = []\n",
    "rmselist_GBRTL_abalone = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(abalone_tgt_df):\n",
    "        \n",
    "    abalone_train_df_X = abalone_tgt_df.iloc[train_idx].loc[:, features_abalone]\n",
    "    abalone_test_df_X = abalone_tgt_df.iloc[test_idx][features_abalone]\n",
    "    abalone_train_df_y = abalone_tgt_df.iloc[train_idx].loc[:,target_abalone]\n",
    "    abalone_test_df_y = abalone_tgt_df.loc[test_idx][target_abalone] \n",
    "    \n",
    "    abalone_X_df = pd.concat([abalone_source_df_X, abalone_train_df_X], ignore_index=True)\n",
    "    abalone_y_df = pd.concat([abalone_source_df_y, abalone_train_df_y], ignore_index=True)\n",
    "\n",
    "    abalone_np_train_X = abalone_X_df.to_numpy()\n",
    "    abalone_np_train_y = abalone_y_df.to_numpy()\n",
    "\n",
    "    abalone_np_test_X = abalone_test_df_X.to_numpy()\n",
    "    abalone_np_test_y = abalone_test_df_y.to_numpy()\n",
    "\n",
    "    abalone_np_train_y_list = abalone_np_train_y.ravel()\n",
    "    abalone_np_test_y_list = abalone_np_test_y.ravel()\n",
    "\n",
    "\n",
    "    model_GBRTL_abalone = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100)\n",
    "    model_GBRTL_abalone.fit(abalone_np_train_X, abalone_np_train_y_list)\n",
    "\n",
    "    y_pred_GBRTL_abalone = model_GBRTL_abalone.predict(abalone_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBRTL_abalone = sqrt(mean_squared_error(abalone_np_test_y, y_pred_GBRTL_abalone))\n",
    "    rmselist_GBRTL_abalone.append(mse_GBRTL_abalone)\n",
    "        \n",
    "    r2_score_GBRTL_abalone = pearsonr(abalone_np_test_y_list, y_pred_GBRTL_abalone)\n",
    "    r2_score_GBRTL_abalone = (r2_score_GBRTL_abalone[0])**2\n",
    "    r2scorelist_GBRTL_abalone.append(r2_score_GBRTL_abalone)\n",
    "\n",
    "\n",
    "print(\"RMSE List of GBRTL:\", rmselist_GBRTL_abalone)\n",
    "print(\"R^2 List of GBRTL:\", r2scorelist_GBRTL_abalone)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Mean, Stdev of RMSE of GBRTL:\", statistics.mean(rmselist_GBRTL_abalone), statistics.stdev(rmselist_GBRTL_abalone))\n",
    "print(\"Mean, Stdev of R^2 of GBRTL:\", statistics.mean(r2scorelist_GBRTL_abalone), statistics.stdev(r2scorelist_GBRTL_abalone))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4774158366799477 0.1778150997140501\n",
      "1.4702303687021976 0.17970051016641017\n",
      "0.180939186766893 0.8609152412759344\n",
      "\n",
      "\n",
      "-0.5852548329307646 0.5745091033401768\n",
      "-0.36585924469666253 0.7239555216280504\n",
      "0.9064702983841878 0.3911716398994435\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats_StAd_rmse, pval_StAd_rmse = stats.ttest_ind(rmselist_stradaboost_abalone, rmselist_AdaTr_abalone)\n",
    "print(stats_StAd_rmse, pval_StAd_rmse)\n",
    "\n",
    "stats_StGb_rmse, pval_StGb_rmse = stats.ttest_ind(rmselist_stradaboost_abalone, rmselist_GBRTL_abalone)\n",
    "print(stats_StGb_rmse, pval_StGb_rmse)\n",
    "\n",
    "stats_StTr_rmse, pval_StTr_rmse = stats.ttest_ind(rmselist_stradaboost_abalone, rmselist_TwoTrAda_abalone)\n",
    "print(stats_StTr_rmse, pval_StTr_rmse)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "stats_StAd_r2, pval_StAd_r2 = stats.ttest_ind(r2scorelist_stradaboost_abalone, r2scorelist_AdaTr_abalone)\n",
    "print(stats_StAd_r2, pval_StAd_r2)\n",
    "\n",
    "stats_StGb_r2, pval_StGb_r2 = stats.ttest_ind(r2scorelist_stradaboost_abalone, r2scorelist_GBRTL_abalone)\n",
    "print(stats_StGb_r2, pval_StGb_r2)\n",
    "\n",
    "stats_StTr_r2, pval_StTr_r2 = stats.ttest_ind(r2scorelist_stradaboost_abalone, r2scorelist_TwoTrAda_abalone)\n",
    "print(stats_StTr_r2, pval_StTr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3950437583222772 0.07475725214402565\n",
      "2.1242400051017136 0.10085945561990267\n",
      "0.32488683877032 0.7615486615910663\n",
      "\n",
      "\n",
      "-1.881842769362401 0.1329977130272984\n",
      "-1.2603856460659317 0.2760438976285486\n",
      "2.293616600098016 0.0835237480871644\n"
     ]
    }
   ],
   "source": [
    "#### Dependent(paired) t-test\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "stats_StAd_rmse, pval_StAd_rmse = stats.ttest_rel(rmselist_stradaboost_abalone, rmselist_AdaTr_abalone)\n",
    "print(stats_StAd_rmse, pval_StAd_rmse)\n",
    "\n",
    "stats_StGb_rmse, pval_StGb_rmse = stats.ttest_rel(rmselist_stradaboost_abalone, rmselist_GBRTL_abalone)\n",
    "print(stats_StGb_rmse, pval_StGb_rmse)\n",
    "\n",
    "stats_StTr_rmse, pval_StTr_rmse = stats.ttest_rel(rmselist_stradaboost_abalone, rmselist_TwoTrAda_abalone)\n",
    "print(stats_StTr_rmse, pval_StTr_rmse)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "stats_StAd_r2, pval_StAd_r2 = stats.ttest_rel(r2scorelist_stradaboost_abalone, r2scorelist_AdaTr_abalone)\n",
    "print(stats_StAd_r2, pval_StAd_r2)\n",
    "\n",
    "stats_StGb_r2, pval_StGb_r2 = stats.ttest_rel(r2scorelist_stradaboost_abalone, r2scorelist_GBRTL_abalone)\n",
    "print(stats_StGb_r2, pval_StGb_r2)\n",
    "\n",
    "stats_StTr_r2, pval_StTr_r2 = stats.ttest_rel(r2scorelist_stradaboost_abalone, r2scorelist_TwoTrAda_abalone)\n",
    "print(stats_StTr_r2, pval_StTr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinematics Data\n",
      "(8192, 9)\n",
      "Target Set:  (2878, 8)\n",
      "Source Set 1:  (2396, 8)\n",
      "Source Set 2:  (2918, 8)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################################## Kinematics ######################################################################\n",
    "#### range: [0.04 - 1.45]\n",
    "#### Mid of correlation variable: theta7\n",
    "#### [0, 0.6] [0.6, 0.85], [0.6, 0.85]\n",
    "####################################################################################################################################\n",
    "target_var_Kinematics = ['y']\n",
    "colnames_Kinematics = ['theta1', 'theta2', 'theta3', 'theta4', 'theta5', 'theta6', 'theta7', 'theta8', 'y']\n",
    "KinematicsData_df = pd.read_csv('UCI_regression/Kinematics/kin8nm.data', header = None,  names = colnames_Kinematics)\n",
    "\n",
    "print(\"Kinematics Data\")\n",
    "print(KinematicsData_df.shape)\n",
    "\n",
    "############################################### Standardization ###############################################\n",
    "kinematics_cols = KinematicsData_df.columns.difference(['y'])\n",
    "\n",
    "ss = StandardScaler()\n",
    "KinematicsData_df[kinematics_cols] = ss.fit_transform(KinematicsData_df[kinematics_cols])\n",
    "\n",
    "\n",
    "########## Corr Kinematics ################\n",
    "# print(\"The correlation matrix is: \")\n",
    "# print(KinematicsData_df.corr().sort_values('y')['y'])\n",
    "\n",
    "##################### Splitting in 3 equal parts #######################################\n",
    "# print(KinematicsData_df.sort_values('theta7')['theta7'])\n",
    "\n",
    "drop_col_kinematics = ['theta7']\n",
    "\n",
    "kinematics_tgt_df = KinematicsData_df.loc[(KinematicsData_df['theta7'] <= -0.5)]\n",
    "kinematics_tgt_df = kinematics_tgt_df.drop(drop_col_kinematics, axis = 1)\n",
    "kinematics_tgt_df = kinematics_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",kinematics_tgt_df.shape)\n",
    "\n",
    "\n",
    "kinematics_source1_df = KinematicsData_df.loc[(KinematicsData_df['theta7'] > -0.5) & (KinematicsData_df['theta7'] <= 0.5)]\n",
    "kinematics_source1_df = kinematics_source1_df.drop(drop_col_kinematics, axis = 1)\n",
    "kinematics_source1_df = kinematics_source1_df.reset_index(drop=True)\n",
    "print(\"Source Set 1: \",kinematics_source1_df.shape)\n",
    "\n",
    "\n",
    "kinematics_source2_df = KinematicsData_df.loc[(KinematicsData_df['theta7'] > 0.5)]\n",
    "kinematics_source2_df = kinematics_source2_df.drop(drop_col_kinematics, axis = 1)\n",
    "kinematics_source2_df = kinematics_source2_df.reset_index(drop=True)\n",
    "print(\"Source Set 2: \",kinematics_source2_df.shape)\n",
    "\n",
    "\n",
    "## Concatenating the source datasets\n",
    "kinematics_source_df = pd.concat([kinematics_source1_df, kinematics_source2_df], ignore_index = True)\n",
    "kinematics_source_df = kinematics_source_df.reset_index(drop = True)\n",
    "\n",
    "# #################### Splitting into features and target (Hide in STrAdaBoost.R2)####################\n",
    "# target_kinematics = ['y']\n",
    "\n",
    "# kinematics_source_df_y = kinematics_source_df[target_kinematics]\n",
    "# kinematics_source_df_X = kinematics_source_df.drop(target_kinematics, axis = 1)\n",
    "\n",
    "# features_kinematics = kinematics_source_df_X.columns\n",
    "\n",
    "\n",
    "\n",
    "print(\"---------------------------\")\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Set:  (2878, 8)\n",
      "Source Set:  (800, 8)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################## Finding best instances from the source dataset (Kinematics) ######################################################\n",
    "\n",
    "kinematics_source_df[\"ManDis\"] = \"\"\n",
    "\n",
    "kinematics_tgt_df_mean = []\n",
    "prow = kinematics_tgt_df.mean()\n",
    "kinematics_tgt_df_mean = [prow.theta1, prow.theta2, prow.theta3, prow.theta4, prow.theta5, prow.theta6, prow.theta8, prow.y]\n",
    "\n",
    "rowidx = 0\n",
    "\n",
    "for row in kinematics_source_df.itertuples():\n",
    "    row_list =[row.theta1, row.theta2, row.theta3, row.theta4, row.theta5, row.theta6, row.theta8, row.y]\n",
    "\n",
    "    man_dis = 0\n",
    "    for i in range(0, len(row_list)):\n",
    "        tempval = kinematics_tgt_df_mean[i] - row_list[i]\n",
    "        man_dis = man_dis + abs(tempval)\n",
    "\n",
    "    kinematics_source_df.loc[rowidx,\"ManDis\"] = man_dis\n",
    "    rowidx = rowidx + 1\n",
    "\n",
    "kinematics_source_df = kinematics_source_df.sort_values(by =['ManDis'])\n",
    "kinematics_source_df = kinematics_source_df.head(800) \n",
    "kinematics_source_df = kinematics_source_df.drop(['ManDis'], axis =1)\n",
    "kinematics_source_df = kinematics_source_df.reset_index(drop=True)\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "print(\"Target Set: \", kinematics_tgt_df.shape)\n",
    "print(\"Source Set: \", kinematics_source_df.shape)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_kinematics = ['y']\n",
    "\n",
    "kinematics_source_df_y = kinematics_source_df[target_kinematics]\n",
    "kinematics_source_df_X = kinematics_source_df.drop(target_kinematics, axis = 1)\n",
    "\n",
    "features_kinematics = kinematics_source_df_X.columns\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "RMSE List of STrAdaboostR2: 0.1586831321186387\n",
      "R^2 List of STrAdaboostR2: 0.6280751630315328\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 0.1586831321186387 0.0076641723542312246\n",
      "Mean, STDev of R^2: 0.6280751630315328 0.08357579198726406\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Active Learning Kinematics ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "r2scorelist_stradaboost_kinematics = []\n",
    "rmselist_stradaboost_kinematics = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(kinematics_tgt_df):\n",
    "        \n",
    "    kinematics_train_df_X = kinematics_tgt_df.iloc[train_idx].loc[:, features_kinematics]\n",
    "    kinematics_test_df_X = kinematics_tgt_df.iloc[test_idx][features_kinematics]\n",
    "    kinematics_train_df_y = kinematics_tgt_df.iloc[train_idx].loc[:,target_kinematics]\n",
    "    kinematics_test_df_y = kinematics_tgt_df.loc[test_idx][target_kinematics] \n",
    "    \n",
    "    kinematics_X_df = pd.concat([kinematics_source_df_X, kinematics_train_df_X], ignore_index=True)\n",
    "    kinematics_y_df = pd.concat([kinematics_source_df_y, kinematics_train_df_y], ignore_index=True)\n",
    "\n",
    "    kinematics_np_train_X = kinematics_X_df.to_numpy()\n",
    "    kinematics_np_train_y = kinematics_y_df.to_numpy()\n",
    "\n",
    "    kinematics_np_test_X = kinematics_test_df_X.to_numpy()\n",
    "    kinematics_np_test_y = kinematics_test_df_y.to_numpy()\n",
    "\n",
    "    kinematics_np_train_y_list = kinematics_np_train_y.ravel()\n",
    "    kinematics_np_test_y_list = kinematics_np_test_y.ravel()\n",
    "    \n",
    "    \n",
    "    sample_size = [len(kinematics_source_df_X), len(kinematics_train_df_X)]\n",
    "\n",
    "    model_stradaboost_kinematics = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                        n_estimators = n_estimators, sample_size = sample_size,\n",
    "                        steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "    model_stradaboost_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list)\n",
    "    y_pred_stradaboost_kinematics = model_stradaboost_kinematics.predict(kinematics_np_test_X)\n",
    "\n",
    "\n",
    "    mse_stradaboost_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_stradaboost_kinematics))\n",
    "\n",
    "    rmselist_stradaboost_kinematics.append(mse_stradaboost_kinematics)\n",
    "        \n",
    "    r2_score_stradaboost_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_stradaboost_kinematics)\n",
    "    r2_score_stradaboost_kinematics = (r2_score_stradaboost_kinematics[0])**2\n",
    "\n",
    "    r2scorelist_stradaboost_kinematics.append(r2_score_stradaboost_kinematics)\n",
    "\n",
    "    \n",
    "print(\"RMSE List of STrAdaboostR2:\", statistics.mean(rmselist_stradaboost_kinematics))\n",
    "print(\"R^2 List of STrAdaboostR2:\", statistics.mean(r2scorelist_stradaboost_kinematics))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_stradaboost_kinematics), statistics.stdev(rmselist_stradaboost_kinematics))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_stradaboost_kinematics), statistics.stdev(r2scorelist_stradaboost_kinematics))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "RMSE List of TrAdaboost.R2: [0.17127393955694623, 0.1669823459829515, 0.17217512838058419, 0.16807116672007408, 0.17662436844893892, 0.18322992269756577, 0.17708671995261255, 0.16720243538533466, 0.16972185591652802, 0.1794764312051885, 0.14985630557445656, 0.16337513788734326, 0.1650656035957635, 0.15649602793526374, 0.17227748084038497, 0.1602992884583097, 0.17564152304814457, 0.18968403888876234, 0.16677897526799754, 0.16003597223323784]\n",
      "R^2 List of TrAdaboostR2: [0.5535063206087691, 0.6632203635108883, 0.5754247900707788, 0.5655199718691947, 0.5288552633967446, 0.5771643746114014, 0.44668476227349024, 0.5324714539671573, 0.5390098563208533, 0.49612229355516463, 0.6296784300489926, 0.5750741847693349, 0.36045144880565116, 0.6585029517807146, 0.4473901173060256, 0.5280390341581853, 0.5584162072512125, 0.46412984004885527, 0.6133847371223513, 0.552189676932758]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 0.16956773339881942 0.0093664668885901\n",
      "Mean, STDev of R^2: 0.5432618039204262 0.07439481092959442\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Kinematics #######################################\n",
    "\n",
    "############# Transfer Learning specifications #########################\n",
    "\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_TwoTrAda_kinematics = []\n",
    "rmselist_TwoTrAda_kinematics = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(kinematics_tgt_df):\n",
    "        \n",
    "    kinematics_train_df_X = kinematics_tgt_df.iloc[train_idx].loc[:, features_kinematics]\n",
    "    kinematics_test_df_X = kinematics_tgt_df.iloc[test_idx][features_kinematics]\n",
    "    kinematics_train_df_y = kinematics_tgt_df.iloc[train_idx].loc[:,target_kinematics]\n",
    "    kinematics_test_df_y = kinematics_tgt_df.loc[test_idx][target_kinematics] \n",
    "    \n",
    "    kinematics_X_df = pd.concat([kinematics_source_df_X, kinematics_train_df_X], ignore_index=True)\n",
    "    kinematics_y_df = pd.concat([kinematics_source_df_y, kinematics_train_df_y], ignore_index=True)\n",
    "\n",
    "    kinematics_np_train_X = kinematics_X_df.to_numpy()\n",
    "    kinematics_np_train_y = kinematics_y_df.to_numpy()\n",
    "\n",
    "    kinematics_np_test_X = kinematics_test_df_X.to_numpy()\n",
    "    kinematics_np_test_y = kinematics_test_df_y.to_numpy()\n",
    "\n",
    "    kinematics_np_train_y_list = kinematics_np_train_y.ravel()\n",
    "    kinematics_np_test_y_list = kinematics_np_test_y.ravel()\n",
    "\n",
    "    src_size_kinematics = len(kinematics_source_df_y)\n",
    "    tgt_size_kinematics = len(kinematics_train_df_y)\n",
    "\n",
    "    src_idx_kinematics = np.arange(start = 0, stop = (src_size_kinematics - 1), step = 1)\n",
    "    tgt_idx_kinematics = np.arange(start = src_size_kinematics, stop = ((src_size_kinematics + tgt_size_kinematics)-1), step = 1)\n",
    "\n",
    "\n",
    "    model_TwoTrAda_kinematics = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100)\n",
    "    model_TwoTrAda_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list, src_idx_kinematics, tgt_idx_kinematics)\n",
    "\n",
    "    y_pred_TwoTrAda_kinematics = model_TwoTrAda_kinematics.predict(kinematics_np_test_X)\n",
    "\n",
    "    mse_TwoTrAda_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_TwoTrAda_kinematics))\n",
    "    rmselist_TwoTrAda_kinematics.append(mse_TwoTrAda_kinematics)\n",
    "        \n",
    "    r2_score_TwoTrAda_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_TwoTrAda_kinematics)\n",
    "    r2_score_TwoTrAda_kinematics = (r2_score_TwoTrAda_kinematics[0])**2\n",
    "    r2scorelist_TwoTrAda_kinematics.append(r2_score_TwoTrAda_kinematics)\n",
    "\n",
    "print(\"RMSE List of TrAdaboost.R2:\", rmselist_TwoTrAda_kinematics)\n",
    "print(\"R^2 List of TrAdaboostR2:\", r2scorelist_TwoTrAda_kinematics)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_TwoTrAda_kinematics), statistics.stdev(rmselist_TwoTrAda_kinematics))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_TwoTrAda_kinematics), statistics.stdev(r2scorelist_TwoTrAda_kinematics))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE List of Adaboost.R2: [0.2154752685103698, 0.1985844838892281, 0.21146872987552065, 0.20143870658282897, 0.2084368802569673, 0.20509098740625809, 0.19590132265779048, 0.1984767295462005, 0.20066657556787076, 0.1940639339583811, 0.19573528041609659, 0.21254076626704194, 0.19260275381954683, 0.20024603801490737, 0.2127625151625833, 0.1946791338774877, 0.19844330806078467, 0.2246199493720246, 0.2070223979495842, 0.19051378455805573]\n",
      "R^2 List of Adaboost.R2: [0.36537822322200547, 0.515427104077821, 0.38411375147009996, 0.40826702567999223, 0.4074368190778562, 0.5766234982070354, 0.37387393704525607, 0.3875088393617786, 0.38634178126663865, 0.48767932699211114, 0.4059204909356948, 0.3471076650608209, 0.20297093095566596, 0.4439041165518097, 0.22565914366021045, 0.34539953611115465, 0.515785387970833, 0.25395486208595136, 0.4109043013447319, 0.4318167360165548]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 0.20293847728747644 0.008954844325299674\n",
      "Mean, STDev of R^2: 0.3938036738547011 0.09371349330463755\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning Kinematics #####################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_AdaTL_kinematics = []\n",
    "rmselist_AdaTL_kinematics = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(kinematics_tgt_df):\n",
    "        \n",
    "    kinematics_train_df_X = kinematics_tgt_df.iloc[train_idx].loc[:, features_kinematics]\n",
    "    kinematics_test_df_X = kinematics_tgt_df.iloc[test_idx][features_kinematics]\n",
    "    kinematics_train_df_y = kinematics_tgt_df.iloc[train_idx].loc[:,target_kinematics]\n",
    "    kinematics_test_df_y = kinematics_tgt_df.loc[test_idx][target_kinematics] \n",
    "    \n",
    "    kinematics_X_df = pd.concat([kinematics_source_df_X, kinematics_train_df_X], ignore_index=True)\n",
    "    kinematics_y_df = pd.concat([kinematics_source_df_y, kinematics_train_df_y], ignore_index=True)\n",
    "\n",
    "    kinematics_np_train_X = kinematics_X_df.to_numpy()\n",
    "    kinematics_np_train_y = kinematics_y_df.to_numpy()\n",
    "\n",
    "    kinematics_np_test_X = kinematics_test_df_X.to_numpy()\n",
    "    kinematics_np_test_y = kinematics_test_df_y.to_numpy()\n",
    "\n",
    "    kinematics_np_train_y_list = kinematics_np_train_y.ravel()\n",
    "    kinematics_np_test_y_list = kinematics_np_test_y.ravel()\n",
    "\n",
    "    model_AdaTL_kinematics = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_AdaTL_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list)\n",
    "\n",
    "    y_pred_AdaTL_kinematics = model_AdaTL_kinematics.predict(kinematics_np_test_X)\n",
    "\n",
    "    mse_AdaTL_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_AdaTL_kinematics))\n",
    "    rmselist_AdaTL_kinematics.append(mse_AdaTL_kinematics)\n",
    "        \n",
    "    r2_score_AdaTL_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_AdaTL_kinematics)\n",
    "    r2_score_AdaTL_kinematics = (r2_score_AdaTL_kinematics[0])**2\n",
    "    r2scorelist_AdaTL_kinematics.append(r2_score_AdaTL_kinematics)\n",
    "\n",
    "print(\"RMSE List of Adaboost.R2:\", rmselist_AdaTL_kinematics)\n",
    "print(\"R^2 List of Adaboost.R2:\", r2scorelist_AdaTL_kinematics)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_AdaTL_kinematics), statistics.stdev(rmselist_AdaTL_kinematics))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_AdaTL_kinematics), statistics.stdev(r2scorelist_AdaTL_kinematics))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of GBRTL: [0.20297238222001085, 0.1848060082047616, 0.20224217250963997, 0.18303929398079735, 0.2011556891615623, 0.19600130297585558, 0.19089314700841448, 0.19118682989768113, 0.195100757148304, 0.1730455086776183, 0.18937014323012513, 0.20898403152231088, 0.19671983116526634, 0.18648861736533234, 0.2032060476394821, 0.20387651982213575, 0.18700255898624019, 0.21573602371523867, 0.19667278803892851, 0.17198487208884486]\n",
      "R^2 List of GBRTL: [0.42467335025841574, 0.5648310321277084, 0.4229502742183758, 0.5042618696742892, 0.43054532168848236, 0.5429624837449435, 0.4088604238947674, 0.41530272672772856, 0.4104448645674725, 0.5500647787274874, 0.43958039663440185, 0.3666075916568952, 0.2442738102916208, 0.4949905916318364, 0.28992421680533204, 0.3281466615119518, 0.5293114951324919, 0.3242815636959829, 0.4648046415782203, 0.5053667617084855]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 0.1940242262679275 0.011172029103735728\n",
      "Mean, STDev of R^2: 0.4331092428138445 0.08960586177710513\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning Kinematics #######################################\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_kinematics = []\n",
    "rmselist_GBRTL_kinematics = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(kinematics_tgt_df):\n",
    "        \n",
    "    kinematics_train_df_X = kinematics_tgt_df.iloc[train_idx].loc[:, features_kinematics]\n",
    "    kinematics_test_df_X = kinematics_tgt_df.iloc[test_idx][features_kinematics]\n",
    "    kinematics_train_df_y = kinematics_tgt_df.iloc[train_idx].loc[:,target_kinematics]\n",
    "    kinematics_test_df_y = kinematics_tgt_df.loc[test_idx][target_kinematics] \n",
    "    \n",
    "    kinematics_X_df = pd.concat([kinematics_source_df_X, kinematics_train_df_X], ignore_index=True)\n",
    "    kinematics_y_df = pd.concat([kinematics_source_df_y, kinematics_train_df_y], ignore_index=True)\n",
    "\n",
    "    kinematics_np_train_X = kinematics_X_df.to_numpy()\n",
    "    kinematics_np_train_y = kinematics_y_df.to_numpy()\n",
    "\n",
    "    kinematics_np_test_X = kinematics_test_df_X.to_numpy()\n",
    "    kinematics_np_test_y = kinematics_test_df_y.to_numpy()\n",
    "\n",
    "    kinematics_np_train_y_list = kinematics_np_train_y.ravel()\n",
    "    kinematics_np_test_y_list = kinematics_np_test_y.ravel()\n",
    "\n",
    "\n",
    "    model_GBRTL_kinematics = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100)\n",
    "    model_GBRTL_kinematics.fit(kinematics_np_train_X, kinematics_np_train_y_list)\n",
    "\n",
    "    y_pred_GBRTL_kinematics = model_GBRTL_kinematics.predict(kinematics_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBRTL_kinematics = sqrt(mean_squared_error(kinematics_np_test_y, y_pred_GBRTL_kinematics))\n",
    "    rmselist_GBRTL_kinematics.append(mse_GBRTL_kinematics)\n",
    "        \n",
    "    r2_score_GBRTL_kinematics = pearsonr(kinematics_np_test_y_list, y_pred_GBRTL_kinematics)\n",
    "    r2_score_GBRTL_kinematics = (r2_score_GBRTL_kinematics[0])**2\n",
    "\n",
    "    r2scorelist_GBRTL_kinematics.append(r2_score_GBRTL_kinematics)\n",
    "\n",
    "\n",
    "print(\"RMSE List of GBRTL:\", rmselist_GBRTL_kinematics)\n",
    "print(\"R^2 List of GBRTL:\", r2scorelist_GBRTL_kinematics)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "    \n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_GBRTL_kinematics), statistics.stdev(rmselist_GBRTL_kinematics))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_GBRTL_kinematics), statistics.stdev(r2scorelist_GBRTL_kinematics))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.239211166142098 0.05549370834515708\n",
      "5.710744979214197 0.00044878897195905153\n",
      "12.933901052446585 1.2086974283329565e-06\n",
      "\n",
      "\n",
      "0.15020428465586927 0.8843214418707841\n",
      "-0.580453091569201 0.5775889224254931\n",
      "-5.759859685898271 0.0004241772800097817\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats_StAd_rmse, pval_StAd_rmse = stats.ttest_ind(rmselist_stradaboost_kinematics, rmselist_AdaTL_kinematics)\n",
    "print(stats_StAd_rmse, pval_StAd_rmse)\n",
    "\n",
    "stats_StGb_rmse, pval_StGb_rmse = stats.ttest_ind(rmselist_stradaboost_kinematics, rmselist_GBRTL_kinematics)\n",
    "print(stats_StGb_rmse, pval_StGb_rmse)\n",
    "\n",
    "stats_StTr_rmse, pval_StTr_rmse = stats.ttest_ind(rmselist_stradaboost_kinematics, rmselist_TwoTrAda_kinematics)\n",
    "print(stats_StTr_rmse, pval_StTr_rmse)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "stats_StAd_r2, pval_StAd_r2 = stats.ttest_ind(r2scorelist_stradaboost_kinematics, r2scorelist_AdaTL_kinematics)\n",
    "print(stats_StAd_r2, pval_StAd_r2)\n",
    "\n",
    "stats_StGb_r2, pval_StGb_r2 = stats.ttest_ind(r2scorelist_stradaboost_kinematics, r2scorelist_GBRTL_kinematics)\n",
    "print(stats_StGb_r2, pval_StGb_r2)\n",
    "\n",
    "stats_StTr_r2, pval_StTr_r2 = stats.ttest_ind(r2scorelist_stradaboost_kinematics, r2scorelist_TwoTrAda_kinematics)\n",
    "print(stats_StTr_r2, pval_StTr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6296148561965667 0.02216745053260249\n",
      "6.519298221944031 0.0028583835971875094\n",
      "13.492049030039581 0.0001746222481559807\n",
      "\n",
      "\n",
      "0.7297095707949993 0.5060026819401974\n",
      "-4.064041932226505 0.015297728196215526\n",
      "-9.89590741109181 0.0005852307476539434\n"
     ]
    }
   ],
   "source": [
    "#### Dependent(paired) t-test\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "\n",
    "stats_StAd_rmse, pval_StAd_rmse = stats.ttest_rel(rmselist_stradaboost_kinematics, rmselist_AdaTL_kinematics)\n",
    "print(stats_StAd_rmse, pval_StAd_rmse)\n",
    "\n",
    "stats_StGb_rmse, pval_StGb_rmse = stats.ttest_rel(rmselist_stradaboost_kinematics, rmselist_GBRTL_kinematics)\n",
    "print(stats_StGb_rmse, pval_StGb_rmse)\n",
    "\n",
    "stats_StTr_rmse, pval_StTr_rmse = stats.ttest_rel(rmselist_stradaboost_kinematics, rmselist_TwoTrAda_kinematics)\n",
    "print(stats_StTr_rmse, pval_StTr_rmse)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "stats_StAd_r2, pval_StAd_r2 = stats.ttest_rel(r2scorelist_stradaboost_kinematics, r2scorelist_AdaTL_kinematics)\n",
    "print(stats_StAd_r2, pval_StAd_r2)\n",
    "\n",
    "stats_StGb_r2, pval_StGb_r2 = stats.ttest_rel(r2scorelist_stradaboost_kinematics, r2scorelist_GBRTL_kinematics)\n",
    "print(stats_StGb_r2, pval_StGb_r2)\n",
    "\n",
    "stats_StTr_r2, pval_StTr_r2 = stats.ttest_rel(r2scorelist_stradaboost_kinematics, r2scorelist_TwoTrAda_kinematics)\n",
    "print(stats_StTr_r2, pval_StTr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer Activity Data\n",
      "(8192, 22)\n",
      "Target Set:  (2766, 21)\n",
      "Source Set 1:  (2539, 21)\n",
      "Source Set 2:  (2887, 21)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################### Computer Activity ###########################################\n",
    "colnames_CompAct = ['lread', 'lwrite', 'scall', 'sread', 'swrite', 'fork', 'exec', 'rchar', 'wchar', 'pgout', 'ppgout', \n",
    "                    'pgfree', 'pgscan', 'atch', 'pgin', 'ppgin', 'pflt', 'vflt', 'runqsz', 'freemem', 'freeswap', 'usr' ]\n",
    "CompActData_df = pd.read_csv('UCI_regression/ComputerActivity/cpu_act.data', header = None, names = colnames_CompAct)\n",
    "print(\"Computer Activity Data\")\n",
    "print(CompActData_df.shape)\n",
    "\n",
    "########## Corr Computer Activity ################\n",
    "# print(\"The correlation matrix is: \")\n",
    "# print(CompActData_df.corr().sort_values('usr')['usr'])\n",
    "\n",
    "##################### Splitting in 3 equal parts #######################################\n",
    "# print(CompActData_df.sort_values('pgin')['pgin'])\n",
    "\n",
    "drop_col_compact = ['pgin']\n",
    "\n",
    "compact_tgt_df = CompActData_df.loc[(CompActData_df['pgin'] <= 1.0)]\n",
    "compact_tgt_df = compact_tgt_df.drop(drop_col_compact, axis = 1)\n",
    "compact_tgt_df = compact_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",compact_tgt_df.shape)\n",
    "\n",
    "\n",
    "compact_source1_df = CompActData_df.loc[(CompActData_df['pgin'] > 1.0) & (CompActData_df['pgin'] <= 6.0)]\n",
    "compact_source1_df = compact_source1_df.drop(drop_col_compact, axis = 1)\n",
    "compact_source1_df = compact_source1_df.reset_index(drop = True)\n",
    "print(\"Source Set 1: \",compact_source1_df.shape)\n",
    "\n",
    "\n",
    "compact_source2_df = CompActData_df.loc[(CompActData_df['pgin'] > 6.0)]\n",
    "compact_source2_df = compact_source2_df.drop(drop_col_compact, axis = 1)\n",
    "compact_source2_df = compact_source2_df.reset_index(drop = True)\n",
    "print(\"Source Set 2: \",compact_source2_df.shape)\n",
    "\n",
    "\n",
    "## Concatenating the source datasets\n",
    "compact_source_df = pd.concat([compact_source1_df, compact_source2_df], ignore_index = True)\n",
    "compact_source_df = compact_source_df.reset_index(drop = True)\n",
    "\n",
    "# #################### Splitting into features and target (Hide for STrAdaBoost.R2)####################\n",
    "# target_compact = ['usr']\n",
    "\n",
    "# compact_source_df_y = compact_source_df[target_compact]\n",
    "# compact_source_df_X = compact_source_df.drop(target_compact, axis = 1)\n",
    "\n",
    "# features_compact = compact_source_df_X.columns\n",
    "\n",
    "print(\"---------------------------\")\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Set:  (3416, 21)\n",
      "Source Set:  (4776, 21)\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "################################## Finding best instances from the source dataset (Conputer Activity) ######################################################\n",
    "compact_source_df[\"ManDis\"] = \"\"\n",
    "\n",
    "compact_tgt_df_mean = []\n",
    "prow = compact_tgt_df.mean()\n",
    "compact_tgt_df_mean = [prow.lread, prow.lwrite, prow.scall, prow.sread, prow.swrite, prow.fork, prow.exec, prow.rchar,\n",
    "       prow.wchar, prow.pgout, prow.ppgout, prow.pgfree, prow.pgscan, prow.atch, prow.ppgin, prow.pflt, prow.vflt, prow.runqsz,\n",
    "        prow.freemem, prow.freeswap, prow.usr]\n",
    "\n",
    "rowidx = 0\n",
    "\n",
    "for row in compact_source_df.itertuples():\n",
    "    row_list =[row.lread, row.lwrite, row.scall, row.sread, row.swrite, row.fork, row.exec, row.rchar,\n",
    "       row.wchar, row.pgout, row.ppgout, row.pgfree, row.pgscan, row.atch, row.ppgin, row.pflt, row.vflt, row.runqsz,\n",
    "        row.freemem, row.freeswap, row.usr]\n",
    "\n",
    "    man_dis = 0\n",
    "    for i in range(0, len(row_list)):\n",
    "        tempval = compact_tgt_df_mean[i] - row_list[i]\n",
    "        man_dis = man_dis + abs(tempval)\n",
    "\n",
    "    compact_source_df.loc[rowidx,\"ManDis\"] = man_dis\n",
    "    rowidx = rowidx + 1\n",
    "\n",
    "\n",
    "compact_source_df = compact_source_df.sort_values(by =['ManDis'])\n",
    "compact_tgt_source_df = compact_source_df.head(650) ## For Computer Activity 650 instances\n",
    "compact_source_df = compact_source_df.iloc[650:]\n",
    "compact_source_df = compact_source_df.drop(['ManDis'], axis =1)\n",
    "compact_tgt_source_df = compact_tgt_source_df.drop(['ManDis'], axis =1)\n",
    "\n",
    "compact_tgt_df = pd.concat([compact_tgt_df, compact_tgt_source_df], ignore_index=True) ### This line is used only for STrAdaBoost.R2 and not for TrAdaBoost.R2\n",
    "compact_source_df = compact_source_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#################### Splitting with small target set and large source and test set #############\n",
    "print(\"Target Set: \", compact_tgt_df.shape)\n",
    "print(\"Source Set: \", compact_source_df.shape)\n",
    "\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_compact = ['usr']\n",
    "\n",
    "compact_source_df_y = compact_source_df[target_compact]\n",
    "compact_source_df_X = compact_source_df.drop(target_compact, axis = 1)\n",
    "\n",
    "features_compact = compact_source_df_X.columns\n",
    "\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STrAdaboost.R2 (50 iter)\n",
      "-------------------------------------------\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "RMSE List of STrAdaboost.R2: [3.3545093240911683, 3.0891528549493126, 3.2412523085504126, 2.9897035821695823, 3.1325674919209914, 3.1489640104026297, 3.1194970864961866, 3.1864482067783886, 3.223319369107611, 3.3554983708815325, 2.9089271694374714, 3.013370684226342, 3.077996765386855, 3.2915831048161084, 3.3679253364931494, 3.330165961639412, 3.495010524931279, 4.0925494624904974, 3.185928665961804, 3.471715029987155]\n",
      "R^2 List of STrAdaboost.R2: [0.9611637239867228, 0.9451063617158112, 0.9698625821749568, 0.9801255141939725, 0.9837663329774095, 0.8873529963788677, 0.9818547300345639, 0.9766448256140556, 0.8878943891815784, 0.9536916722426512, 0.9666256765389541, 0.84523911323256, 0.9847912170810543, 0.9582663917471265, 0.8480734306024682, 0.974953079829458, 0.8983675137544195, 0.6919155958462786, 0.7513792402162124, 0.7473879236353359]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 3.2538042655358943 0.25219033713278066\n",
      "Mean, STDev of R^2: 0.9097231155492228 0.08973157288396204\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 compAct ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "r2scorelist_stradaboost_compact = []\n",
    "rmselist_stradaboost_compact = []\n",
    "\n",
    "print(\"STrAdaboost.R2 (50 iter)\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(compact_tgt_df):\n",
    "        \n",
    "    compact_train_df_X = compact_tgt_df.iloc[train_idx].loc[:, features_compact]\n",
    "    compact_test_df_X = compact_tgt_df.iloc[test_idx][features_compact]\n",
    "    compact_train_df_y = compact_tgt_df.iloc[train_idx].loc[:,target_compact]\n",
    "    compact_test_df_y = compact_tgt_df.loc[test_idx][target_compact] \n",
    "    \n",
    "    compact_X_df = pd.concat([compact_source_df_X, compact_train_df_X], ignore_index=True)\n",
    "    compact_y_df = pd.concat([compact_source_df_y, compact_train_df_y], ignore_index=True)\n",
    "\n",
    "    compact_np_train_X = compact_X_df.to_numpy()\n",
    "    compact_np_train_y = compact_y_df.to_numpy()\n",
    "\n",
    "    compact_np_test_X = compact_test_df_X.to_numpy()\n",
    "    compact_np_test_y = compact_test_df_y.to_numpy()\n",
    "\n",
    "    compact_np_train_y_list = compact_np_train_y.ravel()\n",
    "    compact_np_test_y_list = compact_np_test_y.ravel()\n",
    "    \n",
    "    sample_size = [len(compact_source_df_X), len(compact_train_df_X)]\n",
    "\n",
    "    model_stradaboost_compact = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth=6),\n",
    "                        n_estimators = n_estimators, sample_size = sample_size,\n",
    "                        steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "    model_stradaboost_compact.fit(compact_np_train_X, compact_np_train_y_list)\n",
    "    y_pred_stradaboost_compact = model_stradaboost_compact.predict(compact_np_test_X)\n",
    "    \n",
    "    mse_stradaboost_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_stradaboost_compact))\n",
    "    rmselist_stradaboost_compact.append(mse_stradaboost_compact)\n",
    "        \n",
    "    r2_score_stradaboost_compact = pearsonr(compact_np_test_y_list, y_pred_stradaboost_compact)\n",
    "    r2_score_stradaboost_compact = (r2_score_stradaboost_compact[0])**2\n",
    "    r2scorelist_stradaboost_compact.append(r2_score_stradaboost_compact)\n",
    "        \n",
    "\n",
    "print(\"RMSE List of STrAdaboost.R2:\", rmselist_stradaboost_compact)\n",
    "print(\"R^2 List of STrAdaboost.R2:\", r2scorelist_stradaboost_compact)\n",
    "\n",
    "print(\"\\n\")\n",
    "        \n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_stradaboost_compact), statistics.stdev(rmselist_stradaboost_compact))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_stradaboost_compact), statistics.stdev(r2scorelist_stradaboost_compact))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of TrAdaboost.R2: [2.850245727000064, 2.7005677832721795, 2.423316286110016, 2.3887951407597274, 2.4424424368999618, 2.712540816344094, 2.6922048694063783, 2.4355915511440815, 2.273891051582728, 2.455530672645627, 2.791109298242016, 3.0911190772016943, 2.452726097045739, 2.4119787667080628, 2.7179839042457594, 2.7054580881290557, 2.6361848259425584, 2.715932861277004, 2.646284569087001, 2.320419939336392]\n",
      "R^2 List of TrAdaboost.R2: [0.9558602992700392, 0.931005062205565, 0.9444198699483178, 0.9767082601341441, 0.9821184016071886, 0.9787744231494595, 0.8357842797316652, 0.9680639432406996, 0.9724770595594833, 0.9748248196263483, 0.8432705081475351, 0.9211716882582086, 0.9661358344788633, 0.9474209043007024, 0.7855117137776909, 0.9814564031631141, 0.9710649039181786, 0.8450924978885074, 0.9341749920943405, 0.9798138826886302]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 2.593216188119007 0.20554703753186954\n",
      "Mean, STDev of R^2: 0.9347574873594341 0.058924264017501\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 compAct #######################################\n",
    "\n",
    "############# Transfer Learning specifications #########################\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_TwoTrAda_compact = []\n",
    "rmselist_TwoTrAda_compact = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(compact_tgt_df):\n",
    "        \n",
    "    compact_train_df_X = compact_tgt_df.iloc[train_idx].loc[:, features_compact]\n",
    "    compact_test_df_X = compact_tgt_df.iloc[test_idx][features_compact]\n",
    "    compact_train_df_y = compact_tgt_df.iloc[train_idx].loc[:,target_compact]\n",
    "    compact_test_df_y = compact_tgt_df.loc[test_idx][target_compact] \n",
    "    \n",
    "    compact_X_df = pd.concat([compact_source_df_X, compact_train_df_X], ignore_index=True)\n",
    "    compact_y_df = pd.concat([compact_source_df_y, compact_train_df_y], ignore_index=True)\n",
    "\n",
    "    compact_np_train_X = compact_X_df.to_numpy()\n",
    "    compact_np_train_y = compact_y_df.to_numpy()\n",
    "\n",
    "    compact_np_test_X = compact_test_df_X.to_numpy()\n",
    "    compact_np_test_y = compact_test_df_y.to_numpy()\n",
    "\n",
    "    compact_np_train_y_list = compact_np_train_y.ravel()\n",
    "    compact_np_test_y_list = compact_np_test_y.ravel()\n",
    "\n",
    "    src_size_compact = len(compact_source_df_y)\n",
    "    tgt_size_compact = len(compact_train_df_y)\n",
    "    \n",
    "    src_idx_compact = np.arange(start=0, stop=(src_size_compact - 1), step=1)\n",
    "    tgt_idx_compact = np.arange(start=src_size_compact, stop=((src_size_compact + tgt_size_compact)-1), step=1)\n",
    "\n",
    "    model_TwoTrAda_compact = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100)\n",
    "    model_TwoTrAda_compact.fit(compact_np_train_X, compact_np_train_y_list, src_idx_compact, tgt_idx_compact)\n",
    "\n",
    "    y_pred_TwoTrAda_compact = model_TwoTrAda_compact.predict(compact_np_test_X)\n",
    "\n",
    "    mse_TwoTrAda_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_TwoTrAda_compact))\n",
    "\n",
    "    rmselist_TwoTrAda_compact.append(mse_TwoTrAda_compact)\n",
    "        \n",
    "    r2_score_TwoTrAda_compact = pearsonr(compact_np_test_y_list, y_pred_TwoTrAda_compact)\n",
    "    r2_score_TwoTrAda_compact = (r2_score_TwoTrAda_compact[0])**2\n",
    "\n",
    "    r2scorelist_TwoTrAda_compact.append(r2_score_TwoTrAda_compact)\n",
    "\n",
    "\n",
    "print(\"RMSE List of TrAdaboost.R2:\", rmselist_TwoTrAda_compact)\n",
    "print(\"R^2 List of TrAdaboost.R2:\", r2scorelist_TwoTrAda_compact)\n",
    "\n",
    "print(\"\\n\")\n",
    "        \n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_TwoTrAda_compact), statistics.stdev(rmselist_TwoTrAda_compact))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_TwoTrAda_compact), statistics.stdev(r2scorelist_TwoTrAda_compact))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE List of Adaboost.R2: [2.7497607287843904, 2.5208526259990593, 2.4948268134683627, 2.577512548409647, 2.32702382173679, 2.3216455841878125, 2.4181591995786937, 2.334494866576656, 2.3519531779585354, 2.60371142986263, 2.631725106318242, 2.8575501136246153, 2.54642011764177, 2.305717861419587, 2.722873833819519, 2.6456650763593865, 2.6419954948055775, 2.7446544956999404, 2.7618707632104353, 2.6573848223593988]\n",
      "R^2 List of Adaboost.R2: [0.9628507856331731, 0.9476199758914179, 0.9444863522653001, 0.9739300893739561, 0.9862879199834731, 0.9853015927797946, 0.8881935735983749, 0.9726899441917263, 0.9752572746248802, 0.9735256726643179, 0.8733316440291593, 0.9347874453456327, 0.9669435715720194, 0.9524811342596715, 0.8268690783935556, 0.9833335382643411, 0.9725179154073612, 0.8344019712614956, 0.9428754162773287, 0.9786248389406393]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 2.5607899240910523 0.17056972694345388\n",
      "Mean, STDev of R^2: 0.943815486737881 0.04894320718774135\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning compAct #####################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#earlystopping = EarlyStopping(monitor=\"mean_squared_error\", patience=40, verbose=1, mode='auto')\n",
    "#epochs = 100, batch_size = 5, callbacks=[earlystopping])\n",
    "\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_AdaTL_compact = []\n",
    "rmselist_AdaTL_compact = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(compact_tgt_df):\n",
    "        \n",
    "    compact_train_df_X = compact_tgt_df.iloc[train_idx].loc[:, features_compact]\n",
    "    compact_test_df_X = compact_tgt_df.iloc[test_idx][features_compact]\n",
    "    compact_train_df_y = compact_tgt_df.iloc[train_idx].loc[:,target_compact]\n",
    "    compact_test_df_y = compact_tgt_df.loc[test_idx][target_compact] \n",
    "    \n",
    "    compact_X_df = pd.concat([compact_source_df_X, compact_train_df_X], ignore_index=True)\n",
    "    compact_y_df = pd.concat([compact_source_df_y, compact_train_df_y], ignore_index=True)\n",
    "\n",
    "    compact_np_train_X = compact_X_df.to_numpy()\n",
    "    compact_np_train_y = compact_y_df.to_numpy()\n",
    "\n",
    "    compact_np_test_X = compact_test_df_X.to_numpy()\n",
    "    compact_np_test_y = compact_test_df_y.to_numpy()\n",
    "\n",
    "    compact_np_train_y_list = compact_np_train_y.ravel()\n",
    "    compact_np_test_y_list = compact_np_test_y.ravel()\n",
    "\n",
    "    model_AdaTL_compact = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_AdaTL_compact.fit(compact_np_train_X, compact_np_train_y_list) \n",
    "\n",
    "    y_pred_AdaTL_compact = model_AdaTL_compact.predict(compact_np_test_X)\n",
    "\n",
    "    mse_AdaTL_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_AdaTL_compact))\n",
    "    rmselist_AdaTL_compact.append(mse_AdaTL_compact)\n",
    "        \n",
    "    r2_score_AdaTL_compact = pearsonr(compact_np_test_y_list, y_pred_AdaTL_compact)\n",
    "    r2_score_AdaTL_compact = (r2_score_AdaTL_compact[0])**2\n",
    "    r2scorelist_AdaTL_compact.append(r2_score_AdaTL_compact)\n",
    "\n",
    "\n",
    "print(\"RMSE List of Adaboost.R2:\", rmselist_AdaTL_compact)\n",
    "print(\"R^2 List of Adaboost.R2:\", r2scorelist_AdaTL_compact)\n",
    "\n",
    "print(\"\\n\")\n",
    "        \n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_AdaTL_compact), statistics.stdev(rmselist_AdaTL_compact))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_AdaTL_compact), statistics.stdev(r2scorelist_AdaTL_compact))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning compAct #######################################\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_compact = []\n",
    "rmselist_GBRTL_compact = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(compact_tgt_df):\n",
    "        \n",
    "    compact_train_df_X = compact_tgt_df.iloc[train_idx].loc[:, features_compact]\n",
    "    compact_test_df_X = compact_tgt_df.iloc[test_idx][features_compact]\n",
    "    compact_train_df_y = compact_tgt_df.iloc[train_idx].loc[:,target_compact]\n",
    "    compact_test_df_y = compact_tgt_df.loc[test_idx][target_compact] \n",
    "    \n",
    "    compact_X_df = pd.concat([compact_source_df_X, compact_train_df_X], ignore_index=True)\n",
    "    compact_y_df = pd.concat([compact_source_df_y, compact_train_df_y], ignore_index=True)\n",
    "\n",
    "    compact_np_train_X = compact_X_df.to_numpy()\n",
    "    compact_np_train_y = compact_y_df.to_numpy()\n",
    "\n",
    "    compact_np_test_X = compact_test_df_X.to_numpy()\n",
    "    compact_np_test_y = compact_test_df_y.to_numpy()\n",
    "\n",
    "    compact_np_train_y_list = compact_np_train_y.ravel()\n",
    "    compact_np_test_y_list = compact_np_test_y.ravel()\n",
    "\n",
    "\n",
    "    model_GBRTL_compact = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100, subsample=0.5)\n",
    "    model_GBRTL_compact.fit(compact_np_train_X, compact_np_train_y_list)\n",
    "\n",
    "    y_pred_GBRTL_compact = model_GBRTL_compact.predict(compact_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBRTL_compact = sqrt(mean_squared_error(compact_np_test_y, y_pred_GBRTL_compact))\n",
    "    rmselist_GBRTL_compact.append(mse_GBRTL_compact)\n",
    "        \n",
    "    r2_score_GBRTL_compact = pearsonr(compact_np_test_y_list, y_pred_GBRTL_compact)\n",
    "    r2_score_GBRTL_compact = (r2_score_GBRTL_compact[0])**2\n",
    "    r2scorelist_GBRTL_compact.append(r2_score_GBRTL_compact)\n",
    "\n",
    "\n",
    "print(\"RMSE List of GBRTL:\", rmselist_GBRTL_compact)\n",
    "print(\"R^2 List of GBRTL:\", r2scorelist_GBRTL_compact)\n",
    "\n",
    "print(\"\\n\")\n",
    "        \n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_GBRTL_compact), statistics.stdev(rmselist_GBRTL_compact))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_GBRTL_compact), statistics.stdev(r2scorelist_GBRTL_compact))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
