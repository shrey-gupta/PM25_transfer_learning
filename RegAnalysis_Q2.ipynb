{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done uploading repositories\n",
      "Second Upload Completed!!\n",
      "Dataset after pre-processing: \n",
      "(9357, 10)\n",
      "Target:  (45, 7)\n",
      "Test:  (2202, 7)\n",
      "Source:  (1778, 7)\n",
      "Transfer Learning (M + H, L)\n",
      "-------------------------------------------\n",
      "STrAdaBoost\n",
      "Inside STrAdaBoost.R2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STrAdaBoost\n",
      "Inside STrAdaBoost.R2\n",
      "STrAdaBoost\n",
      "Inside STrAdaBoost.R2\n",
      "STrAdaBoost\n",
      "Inside STrAdaBoost.R2\n",
      "STrAdaBoost\n",
      "Inside STrAdaBoost.R2\n",
      "STrAdaBoost\n",
      "Inside STrAdaBoost.R2\n",
      "STrAdaBoost\n",
      "Inside STrAdaBoost.R2\n",
      "STrAdaBoost\n",
      "Inside STrAdaBoost.R2\n",
      "STrAdaBoost\n",
      "Inside STrAdaBoost.R2\n",
      "STrAdaBoost\n",
      "Inside STrAdaBoost.R2\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################## Header files ################################################\n",
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2 ##For STrAdaBoost.R2\n",
    "# from TwoStageTrAdaBoostR2 import TwoStageTrAdaBoostR2 ## For two-stage TrAdaBoost.R2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Dropout, Flatten\n",
    "from keras import optimizers, utils, initializers, regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler #Importing the StandardScaler\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "#Geo plotting libraries\n",
    "#import geopandas as gdp\n",
    "#from matplotlib.colors import ListedColormap\n",
    "#import geoplot as glpt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "import folium\n",
    "import glob\n",
    "\n",
    "import statistics\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from adapt.instance_based import (TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2)\n",
    "\n",
    "\n",
    "print(\"Done uploading repositories\")\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "print(\"Second Upload Completed!!\")\n",
    "\n",
    "############################## UCI Italian dataset #######################################################\n",
    "#################### Dataset Information: 2 years and single terrain #####################################\n",
    "## Predictors: T, Ah, Rh, NMHC_GT, NOx_GT, CO_GT, C6H6_GT ,Target: O3\n",
    "###########################################################################################################\n",
    "#AQI_datasets/UCI_AQI\n",
    "aqi_df = pd.read_csv('AQI_datasets/UCI_AQI/AirQualityUCI.csv', sep=',', delimiter=\";\", decimal=\",\", index_col = None, header=0)\n",
    "\n",
    "def remove_outlier(col):\n",
    "    aqi_df[col] = aqi_df.groupby('Date')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "################ Pre-processing ############################################\n",
    "aqi_df.dropna(how = 'all', inplace = True) ## drop end rows with NaN values\n",
    "drop_unamed = ['Unnamed: 15', 'Unnamed: 16']\n",
    "aqi_df = aqi_df.drop(drop_unamed, axis = 1) ## drop unamed columns\n",
    "\n",
    "drop_uw = ['Time', 'PT08_S1_CO', 'PT08_S2_NMHC', 'PT08_S3_NOx', 'NO2_GT', 'PT08_S4_NO2']\n",
    "aqi_df = aqi_df.drop(drop_uw, axis = 1) ## Drop unwanted columns\n",
    "\n",
    "aqi_df.replace(to_replace = -200, value = np.NaN, inplace = True) ## Replace the -200 values seen in the dataset with NaN\n",
    "\n",
    "## Replace the NaN values with the column mean\n",
    "col_list = aqi_df.columns[1:]\n",
    "for i in col_list:\n",
    "    remove_outlier(i)\n",
    "\n",
    "aqi_df.fillna(method ='ffill', inplace= True)\n",
    "aqi_df.dropna(axis = 0)\n",
    "\n",
    "## Convert 'Date' column to datetime and then seperate out year and month into different columns.\n",
    "aqi_df.Date = pd.to_datetime(aqi_df.Date)\n",
    "aqi_df['Year'] = aqi_df['Date'].dt.year\n",
    "aqi_df['Month'] = aqi_df['Date'].dt.month\n",
    "drop_date = ['Date']\n",
    "aqi_df = aqi_df.drop(drop_date, axis = 1)\n",
    "aqi_df = aqi_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset after pre-processing: \")\n",
    "print(aqi_df.shape)\n",
    "\n",
    "################ Observing data statistics ################################\n",
    "# print(aqi_df.describe())\n",
    "\n",
    "#Split the dataset according to the year.\n",
    "drop_cols = ['Year', 'Month']\n",
    "aqi_df_2004 = aqi_df[aqi_df['Year'] == 2004]\n",
    "aqi_df_2004 = aqi_df_2004.drop(drop_cols, axis = 1)\n",
    "\n",
    "aqi_df_2005 = aqi_df[aqi_df['Year'] == 2005]\n",
    "aqi_df_2005 = aqi_df_2005.drop(drop_cols, axis = 1)\n",
    "\n",
    "aqi_df_2004 = aqi_df_2004.reset_index(drop=True)\n",
    "aqi_df_2005 = aqi_df_2005.reset_index(drop=True)\n",
    "\n",
    "################ Divide the dataframe into target and the predictors. ################\n",
    "target_uci_col = ['PT08_S5_O3']\n",
    "aqi_df_2004_target = aqi_df_2004[target_uci_col]\n",
    "aqi_df_2004_target.columns = ['O3']\n",
    "aqi_df_2004_predictors = aqi_df_2004.drop(target_uci_col, axis = 1)\n",
    "aqi_df_2004_predictors = aqi_df_2004_predictors.reset_index(drop=True)\n",
    "\n",
    "aqi_df_2005_target = aqi_df_2005[target_uci_col]\n",
    "aqi_df_2005_target.columns = ['O3']\n",
    "aqi_df_2005_predictors = aqi_df_2005.drop(target_uci_col, axis = 1)\n",
    "aqi_df_2005_predictors = aqi_df_2005_predictors.reset_index(drop=True)\n",
    "\n",
    "################### 2004: Source Dataset, 2005: Training Set [Training and Testing Set] ###################\n",
    "################ Standardize the dataset ################\n",
    "ss = StandardScaler()\n",
    "\n",
    "# columns_uci = aqi_df_2004_predictors.columns\n",
    "# aqi_df_2004_predictors[columns_uci] = ss.fit_transform(aqi_df_2004_predictors[columns_uci])\n",
    "# aqi_df_2005_predictors[columns_uci] = ss.fit_transform(aqi_df_2005_predictors[columns_uci])\n",
    "\n",
    "#################### Renaming features and target ####################\n",
    "\n",
    "italianAQ_train_df_y = aqi_df_2005_target\n",
    "italianAQ_train_df_X = aqi_df_2005_predictors\n",
    "\n",
    "italianAQ_source_df_y = aqi_df_2004_target\n",
    "italianAQ_source_df_X = aqi_df_2004_predictors\n",
    "\n",
    "################## Split into target and test dataset ###################\n",
    "def TimeSeriesTrainTestSplit(X, y, test_size):\n",
    "\n",
    "        test_index = int(len(X)*(1-test_size))\n",
    "\n",
    "        X_train = X.iloc[:test_index]\n",
    "        y_train = y.iloc[:test_index]\n",
    "        X_test = X.iloc[test_index:]\n",
    "        y_test = y.iloc[test_index:]\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "italianAQ_test_df_X, italianAQ_test_df_y, italianAQ_tgt_df_X, italianAQ_tgt_df_y = TimeSeriesTrainTestSplit(italianAQ_train_df_X,italianAQ_train_df_y, 0.02)\n",
    "\n",
    "# italianAQ_tgt_df = italianAQ_tgt_df_X\n",
    "# italianAQ_tgt_df = italianAQ_tgt_df.reset_index(drop=True)\n",
    "\n",
    "italianAQ_tgt_df = pd.concat([italianAQ_tgt_df_X, italianAQ_tgt_df_y], axis=1, sort= False)\n",
    "italianAQ_tgt_df = italianAQ_tgt_df.reset_index(drop=True)\n",
    "# italianAQ_tgt_df.index = italianAQ_tgt_df.index + 1\n",
    "\n",
    "italianAQ_test_df = pd.concat([italianAQ_test_df_X, italianAQ_test_df_y], axis=1, sort= False)\n",
    "italianAQ_test_df = italianAQ_test_df.reset_index(drop=True)\n",
    "\n",
    "italianAQ_source_df = pd.concat([italianAQ_source_df_X, italianAQ_source_df_y], axis=1, sort= False)\n",
    "italianAQ_source_df = italianAQ_source_df.reset_index(drop=True)\n",
    "\n",
    "################################## Importance Sampling ######################################################\n",
    "italianAQ_source_df[\"ManDis\"] = \"\"\n",
    "\n",
    "\n",
    "italianAQ_tgt_df_mean = []\n",
    "# prow = italianAQ_tgt_df.mean().tolist()\n",
    "italianAQ_tgt_df_mean = italianAQ_tgt_df.mean().tolist()\n",
    "# italianAQ_tgt_df_mean = [prow.CO_GT, prow.NMHC_GT, prow.C6H6_GT, prow.NOx_GT, prow.T, prow.RH, prow.AH, prow.O3]\n",
    "\n",
    "rowidx = 0\n",
    "\n",
    "for row in italianAQ_source_df.itertuples():\n",
    "    row_list =[row.CO_GT, row.NMHC_GT, row.C6H6_GT, row.NOx_GT, row.T, row.RH, row.AH, row.O3]\n",
    "    \n",
    "    man_dis = 0\n",
    "    for i in range(0, len(row_list)):\n",
    "        tempval = italianAQ_tgt_df_mean[i] - row_list[i]\n",
    "        man_dis = man_dis + abs(tempval)\n",
    "    \n",
    "#     print(\"Mandis Value:\", man_dis)\n",
    "    italianAQ_source_df.loc[rowidx,\"ManDis\"] = man_dis\n",
    "    rowidx = rowidx + 1\n",
    "\n",
    "italianAQ_source_df = italianAQ_source_df.sort_values(by =['ManDis'])\n",
    "italianAQ_source_df = italianAQ_source_df.head(1778) \n",
    "italianAQ_source_df = italianAQ_source_df.drop(['ManDis'], axis =1)\n",
    "italianAQ_source_df = italianAQ_source_df.reset_index(drop=True)\n",
    "\n",
    "############################ Split again into target and features ############################\n",
    "\n",
    "target_column_italianAQ = ['O3']\n",
    "\n",
    "italianAQ_tgt_df_y = italianAQ_tgt_df[target_column_italianAQ]\n",
    "italianAQ_tgt_df_X = italianAQ_tgt_df.drop(target_column_italianAQ, axis = 1)\n",
    "\n",
    "italianAQ_test_df_y = italianAQ_test_df[target_column_italianAQ]\n",
    "italianAQ_test_df_X = italianAQ_test_df.drop(target_column_italianAQ, axis = 1)\n",
    "\n",
    "italianAQ_source_df_y = italianAQ_source_df[target_column_italianAQ]\n",
    "italianAQ_source_df_X = italianAQ_source_df.drop(target_column_italianAQ, axis = 1)\n",
    "\n",
    "\n",
    "columns_italianAQ = italianAQ_tgt_df_X.columns\n",
    "italianAQ_tgt_df_X[columns_italianAQ] = ss.fit_transform(italianAQ_tgt_df_X[columns_italianAQ])\n",
    "italianAQ_test_df_X[columns_italianAQ] = ss.fit_transform(italianAQ_test_df_X[columns_italianAQ])\n",
    "italianAQ_source_df_X[columns_italianAQ] = ss.fit_transform(italianAQ_source_df_X[columns_italianAQ])\n",
    "\n",
    "# italianAQ_source_df_X = italianAQ_source_df\n",
    "\n",
    "print(\"Target: \",italianAQ_tgt_df_X.shape)\n",
    "print(\"Test: \",italianAQ_test_df_X.shape)\n",
    "print(\"Source: \",italianAQ_source_df_X.shape)\n",
    "\n",
    "############### Merging the datasets ##########################################\n",
    "italianAQ_X_df = pd.concat([italianAQ_tgt_df_X, italianAQ_source_df_X], ignore_index=True)\n",
    "italianAQ_y_df = pd.concat([italianAQ_tgt_df_y, italianAQ_source_df_y], ignore_index=True)\n",
    "\n",
    "italianAQ_np_train_X = italianAQ_X_df.to_numpy()\n",
    "italianAQ_np_train_y = italianAQ_y_df.to_numpy()\n",
    "\n",
    "italianAQ_np_test_X = italianAQ_test_df_X.to_numpy()\n",
    "italianAQ_np_test_y = italianAQ_test_df_y.to_numpy()\n",
    "\n",
    "italianAQ_np_train_y_list = italianAQ_np_train_y.ravel()\n",
    "italianAQ_np_test_y_list = italianAQ_np_test_y.ravel()\n",
    "\n",
    "src_size_italianAQ = len(italianAQ_source_df_y)\n",
    "tgt_size_italianAQ = len(italianAQ_tgt_df_y)\n",
    "\n",
    "src_idx = np.arange(start=0, stop=(src_size_italianAQ - 1), step=1)\n",
    "tgt_idx = np.arange(start=src_size_italianAQ, stop=((src_size_italianAQ + tgt_size_italianAQ) - 1), step=1)\n",
    "\n",
    "########################### Transfer Learning Italian AQ #####################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "\n",
    "\n",
    "print(\"Transfer Learning (M + H, L)\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_AdaTL_italianAQ = []\n",
    "rmselist_AdaTL_italianAQ = []\n",
    "\n",
    "r2scorelist_Ada_italianAQ = []\n",
    "rmselist_Ada_italianAQ = []\n",
    "\n",
    "r2scorelist_KMM_italianAQ = []\n",
    "rmselist_KMM_italianAQ = []\n",
    "\n",
    "r2scorelist_GBRTL_italianAQ = []\n",
    "rmselist_GBRTL_italianAQ = []\n",
    "\n",
    "r2scorelist_GBR_italianAQ = []\n",
    "rmselist_GBR_italianAQ = []\n",
    "\n",
    "r2scorelist_TwoTrAda_italianAQ = []\n",
    "rmselist_TwoTrAda_italianAQ = []\n",
    "\n",
    "r2scorelist_stradaboost_italianAQ = []\n",
    "rmselist_stradaboost_italianAQ = []\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 42, shuffle=False)\n",
    "\n",
    "for x in range(0, 10):\n",
    "\n",
    "    ################### STrAdaBoost ###################\n",
    "    print(\"STrAdaBoost\")\n",
    "    from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "#     sample_size = [len(italianAQ_tgt_df_X), len(italianAQ_source_df_X)]\n",
    "    sample_size = [45, 1778]\n",
    "    n_estimators = 100\n",
    "    steps = 30\n",
    "    fold = 10\n",
    "    random_state = np.random.RandomState(1)\n",
    "\n",
    "\n",
    "    model_stradaboost_italianAQ = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth = 6),\n",
    "                        n_estimators = n_estimators, sample_size = sample_size,\n",
    "                        steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "    model_stradaboost_italianAQ.fit(italianAQ_np_train_X, italianAQ_np_train_y_list)\n",
    "    y_pred_stradaboost_italianAQ = model_stradaboost_italianAQ.predict(italianAQ_np_test_X)\n",
    "\n",
    "\n",
    "    mse_stradaboost_italianAQ = sqrt(mean_squared_error(italianAQ_np_test_y, y_pred_stradaboost_italianAQ))\n",
    "    rmselist_stradaboost_italianAQ.append(mse_stradaboost_italianAQ)\n",
    "\n",
    "    r2_score_stradaboost_italianAQ = pearsonr(italianAQ_np_test_y_list, y_pred_stradaboost_italianAQ)\n",
    "    r2_score_stradaboost_italianAQ = (r2_score_stradaboost_italianAQ[0])**2\n",
    "    r2scorelist_stradaboost_italianAQ.append(r2_score_stradaboost_italianAQ)\n",
    "\n",
    "\n",
    "\n",
    "with open('italianAQ_rmse_stradaboost.txt', 'w') as italianAQ_handle_rmse:\n",
    "    italianAQ_handle_rmse.write(\"\\n\\nSTrAdaBoost Active Sampling:\\n \")\n",
    "    italianAQ_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_stradaboost_italianAQ)\n",
    "\n",
    "\n",
    "with open('italianAQ_r2_stradaboost.txt', 'w') as italianAQ_handle_r2:\n",
    "    italianAQ_handle_r2.write(\"\\n\\nSTrAdaBoost Active Sampling:\\n \")\n",
    "    italianAQ_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_stradaboost_italianAQ)\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "print(\"-------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories uploaded!!\n",
      "Second Upload Completed!!\n",
      "(1994, 123)\n",
      "Min:  0.0\n",
      "Max:  1.0\n",
      "Training Set:  (107, 122)\n",
      "Source Set 1:  (136, 122)\n",
      "Source Set 2:  (76, 122)\n",
      "Final Source Set:  (212, 122)\n",
      "Adaboost.R2 Transfer Learning (L + M, H)\n",
      "-------------------------------------------\n",
      "(11, 121) (96, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "(11, 121) (96, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "(11, 121) (96, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "(11, 121) (96, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "(11, 121) (96, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "(11, 121) (96, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "(11, 121) (96, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "(10, 121) (97, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "(10, 121) (97, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "(10, 121) (97, 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside STrAdaBoost.R2\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2 ##STrAdaBoost.R2\n",
    "# from TwoStageTrAdaBoostR2 import TwoStageTrAdaBoostR2 ##two-stage TrAdaBoost.R2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Dropout, Flatten\n",
    "from keras import optimizers, utils, initializers, regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler #Importing the StandardScaler\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "#Geo plotting libraries\n",
    "import geopandas as gdp\n",
    "from matplotlib.colors import ListedColormap\n",
    "# import geoplot as glpt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import statistics\n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import *\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "######################## Instance Transfer repositories ###################################\n",
    "from adapt.instance_based import TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Repositories uploaded!!\")\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "print(\"Second Upload Completed!!\")\n",
    "\n",
    "##########################################################################################\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame) #\"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "attrib = pd.read_csv('Scientific_data/Communities/attributes.csv', delim_whitespace = True)\n",
    "communities_df = pd.read_csv(\"Scientific_data/Communities/communities.data\", names = attrib['attributes'])\n",
    "\n",
    "communities_df = communities_df.drop(columns=['state','county',\n",
    "                          'community','communityname',\n",
    "                          'fold'], axis=1)\n",
    "\n",
    "################## All missing columns were dropped ##################\n",
    "communities_df = communities_df.replace('?', np.nan)\n",
    "feat_miss = communities_df.columns[communities_df.isnull().any()]\n",
    "\n",
    "communities_df.drop(feat_miss, axis = 1)\n",
    "print(communities_df.shape)\n",
    "\n",
    "################## Correlation ==> Column: PctEmploy ##################\n",
    "# print(\"The correlation matrix is: \")\n",
    "# communities_df_corr = communities_df.corr()['ViolentCrimesPerPop'].abs().sort_values()\n",
    "# print(communities_df_corr.to_string()) ### Helps to print the entire series\n",
    "\n",
    "################## To find where to split the data ##################\n",
    "print('Min: ', communities_df['PctEmploy'].min())\n",
    "print('Max: ', communities_df['PctEmploy'].max())\n",
    "\n",
    "\n",
    "################### Processing ######################################\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "drop_col_communities = ['PctEmploy']\n",
    "\n",
    "communities_train_df = communities_df.loc[(communities_df['PctEmploy'] <= 0.42)]\n",
    "communities_train_df = communities_train_df.drop(drop_col_communities, axis = 1)\n",
    "communities_train_df = communities_train_df.reset_index(drop=True)\n",
    "communities_train_df = clean_dataset(communities_train_df)\n",
    "communities_train_df = communities_train_df.reset_index(drop=True)\n",
    "print(\"Training Set: \",communities_train_df.shape)\n",
    "\n",
    "communities_source1_df = communities_df.loc[(communities_df['PctEmploy'] > 0.42) & (communities_df['PctEmploy'] <= 0.58)]\n",
    "communities_source1_df = communities_source1_df.drop(drop_col_communities, axis = 1)\n",
    "communities_source1_df = communities_source1_df.reset_index(drop=True)\n",
    "communities_source1_df = clean_dataset(communities_source1_df)\n",
    "communities_source1_df = communities_source1_df.reset_index(drop=True)\n",
    "print(\"Source Set 1: \",communities_source1_df.shape)\n",
    "\n",
    "communities_source2_df = communities_df.loc[(communities_df['PctEmploy'] > 0.58)]\n",
    "communities_source2_df = communities_source2_df.drop(drop_col_communities, axis = 1)\n",
    "communities_source2_df = communities_source2_df.reset_index(drop=True)\n",
    "communities_source2_df = clean_dataset(communities_source2_df)\n",
    "communities_source2_df = communities_source2_df.reset_index(drop=True)\n",
    "print(\"Source Set 2: \",communities_source2_df.shape)\n",
    "\n",
    "communities_source_df = pd.concat([communities_source1_df, communities_source2_df], ignore_index=True)\n",
    "print(\"Final Source Set: \",communities_source_df.shape)\n",
    "\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_column_communities = ['ViolentCrimesPerPop']\n",
    "\n",
    "communities_train_df_y = communities_train_df[target_column_communities]\n",
    "communities_train_df_X = communities_train_df.drop(target_column_communities, axis = 1)\n",
    "communities_cols = communities_train_df_X.columns\n",
    "communities_train_df_X[communities_cols] = ss.fit_transform(communities_train_df_X[communities_cols])\n",
    "\n",
    "\n",
    "communities_source_df_y = communities_source_df[target_column_communities]\n",
    "communities_source_df_X = communities_source_df.drop(target_column_communities, axis = 1)\n",
    "communities_cols = communities_source_df_X.columns\n",
    "communities_source_df_X[communities_cols] = ss.fit_transform(communities_source_df_X[communities_cols])\n",
    "\n",
    "\n",
    "########################### Transfer Learning communities #####################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "\n",
    "\n",
    "print(\"Adaboost.R2 Transfer Learning (L + M, H)\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_AdaTL_communities = []\n",
    "rmselist_AdaTL_communities = []\n",
    "\n",
    "r2scorelist_Ada_communities = []\n",
    "rmselist_Ada_communities = []\n",
    "\n",
    "r2scorelist_KMM_communities = []\n",
    "rmselist_KMM_communities = []\n",
    "\n",
    "r2scorelist_GBRTL_communities = []\n",
    "rmselist_GBRTL_communities = []\n",
    "\n",
    "r2scorelist_GBR_communities = []\n",
    "rmselist_GBR_communities = []\n",
    "\n",
    "r2scorelist_TwoTrAda_communities = []\n",
    "rmselist_TwoTrAda_communities = []\n",
    "\n",
    "r2scorelist_stradaboost_communities = []\n",
    "rmselist_stradaboost_communities = []\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits = 10, random_state = 42, shuffle=False)\n",
    "\n",
    "for train_ix, test_ix in kfold.split(communities_train_df_X):\n",
    "    ############### get data ###############\n",
    "    communities_test_df_X, communities_tgt_df_X  = communities_train_df_X.iloc[train_ix], communities_train_df_X.iloc[test_ix] #### Make it opposite, so target size is small.\n",
    "    communities_test_df_y, communities_tgt_df_y  = communities_train_df_y.iloc[train_ix], communities_train_df_y.iloc[test_ix] #### Make it opposite, so target size is small.\n",
    "\n",
    "    print(communities_tgt_df_X.shape, communities_test_df_X.shape)\n",
    "\n",
    "    ############### Merging the datasets ##########################################\n",
    "    communities_X_df = pd.concat([communities_tgt_df_X, communities_source_df_X], ignore_index=True)\n",
    "    communities_y_df = pd.concat([communities_tgt_df_y, communities_source_df_y], ignore_index=True)\n",
    "\n",
    "    communities_np_train_X = communities_X_df.to_numpy()\n",
    "    communities_np_train_y = communities_y_df.to_numpy()\n",
    "\n",
    "    communities_np_test_X = communities_test_df_X.to_numpy()\n",
    "    communities_np_test_y = communities_test_df_y.to_numpy()\n",
    "\n",
    "    communities_np_train_y_list = communities_np_train_y.ravel()\n",
    "    communities_np_test_y_list = communities_np_test_y.ravel()\n",
    "\n",
    "    src_size_communities = len(communities_source_df_y)\n",
    "    tgt_size_communities = len(communities_tgt_df_y)\n",
    "\n",
    "    src_idx = np.arange(start = 0, stop = (src_size_communities - 1), step = 1)\n",
    "    tgt_idx = np.arange(start = src_size_communities, stop = ((src_size_communities + tgt_size_communities) - 1), step=1)\n",
    "\n",
    "\n",
    "    ################### AdaBoost Tl ###################\n",
    "    model_AdaTL_communities = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100)\n",
    "    model_AdaTL_communities.fit(communities_np_train_X, communities_np_train_y_list)\n",
    "\n",
    "    y_pred_AdaTL_communities = model_AdaTL_communities.predict(communities_np_test_X)\n",
    "\n",
    "    mse_AdaTL_communities = sqrt(mean_squared_error(communities_np_test_y, y_pred_AdaTL_communities))\n",
    "    rmselist_AdaTL_communities.append(mse_AdaTL_communities)\n",
    "\n",
    "    r2_score_AdaTL_communities = pearsonr(communities_np_test_y_list, y_pred_AdaTL_communities)\n",
    "    r2_score_AdaTL_communities = (r2_score_AdaTL_communities[0])**2\n",
    "    r2scorelist_AdaTL_communities.append(r2_score_AdaTL_communities)\n",
    "\n",
    "\n",
    "    ################### AdaBoost ###################\n",
    "    model_Ada_communities = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100)\n",
    "    model_Ada_communities.fit(communities_tgt_df_X, communities_tgt_df_y)\n",
    "\n",
    "    y_pred_ada_communities = model_Ada_communities.predict(communities_np_test_X)\n",
    "\n",
    "    mse_Ada_communities = sqrt(mean_squared_error(communities_np_test_y, y_pred_ada_communities))\n",
    "    rmselist_Ada_communities.append(mse_Ada_communities)\n",
    "\n",
    "    r2_score_Ada_communities = pearsonr(communities_np_test_y_list, y_pred_ada_communities)\n",
    "    r2_score_Ada_communities = (r2_score_Ada_communities[0])**2\n",
    "    r2scorelist_Ada_communities.append(r2_score_Ada_communities)\n",
    "\n",
    "\n",
    "    ################### GBRTL ###################\n",
    "    model_GBRTL_communities = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100, subsample = 0.5)\n",
    "    model_GBRTL_communities.fit(communities_np_train_X, communities_np_train_y_list)\n",
    "\n",
    "    y_pred_GBRTL_communities = model_GBRTL_communities.predict(communities_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBRTL_communities = sqrt(mean_squared_error(communities_np_test_y, y_pred_GBRTL_communities))\n",
    "    rmselist_GBRTL_communities.append(mse_GBRTL_communities)\n",
    "\n",
    "    r2_score_GBRTL_communities = pearsonr(communities_np_test_y_list, y_pred_GBRTL_communities)\n",
    "    r2_score_GBRTL_communities = (r2_score_GBRTL_communities[0])**2\n",
    "    r2scorelist_GBRTL_communities.append(r2_score_GBRTL_communities)\n",
    "\n",
    "\n",
    "    ################### GBR ###################\n",
    "    model_GBR_communities = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100, subsample=0.5)\n",
    "    model_GBR_communities.fit(communities_tgt_df_X, communities_tgt_df_y)\n",
    "\n",
    "    y_pred_GBR_communities = model_GBR_communities.predict(communities_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBR_communities = sqrt(mean_squared_error(communities_np_test_y, y_pred_GBR_communities))\n",
    "    rmselist_GBR_communities.append(mse_GBR_communities)\n",
    "\n",
    "    r2_score_GBR_communities = pearsonr(communities_np_test_y_list, y_pred_GBR_communities)\n",
    "    r2_score_GBR_communities = (r2_score_GBR_communities[0])**2\n",
    "    r2scorelist_GBR_communities.append(r2_score_GBR_communities)\n",
    "\n",
    "\n",
    "    ################### STrAdaBoost ###################\n",
    "    from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "    sample_size = [len(communities_tgt_df_X), len(communities_source_df_X)]\n",
    "    n_estimators = 100\n",
    "    steps = 30\n",
    "    fold = 10\n",
    "    random_state = np.random.RandomState(1)\n",
    "\n",
    "\n",
    "    model_stradaboost_communities = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth = 6),\n",
    "                        n_estimators = n_estimators, sample_size = sample_size,\n",
    "                        steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "    model_stradaboost_communities.fit(communities_np_train_X, communities_np_train_y_list)\n",
    "    y_pred_stradaboost_communities = model_stradaboost_communities.predict(communities_np_test_X)\n",
    "\n",
    "\n",
    "    mse_stradaboost_communities = sqrt(mean_squared_error(communities_np_test_y, y_pred_stradaboost_communities))\n",
    "    rmselist_stradaboost_communities.append(mse_stradaboost_communities)\n",
    "\n",
    "    r2_score_stradaboost_communities = pearsonr(communities_np_test_y_list, y_pred_stradaboost_communities)\n",
    "    r2_score_stradaboost_communities = (r2_score_stradaboost_communities[0])**2\n",
    "    r2scorelist_stradaboost_communities.append(r2_score_stradaboost_communities)\n",
    "\n",
    "\n",
    "\n",
    "with open('communities_rmse.txt', 'w') as communities_handle_rmse:\n",
    "    communities_handle_rmse.write(\"AdaBoost TL:\\n \")\n",
    "    communities_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_AdaTL_communities)\n",
    "\n",
    "    communities_handle_rmse.write(\"\\n\\nAdaBoost:\\n \")\n",
    "    communities_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_Ada_communities)\n",
    "\n",
    "    communities_handle_rmse.write(\"\\n\\nGBRT:\\n \")\n",
    "    communities_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_GBRTL_communities)\n",
    "\n",
    "    communities_handle_rmse.write(\"\\n\\nGBR:\\n \")\n",
    "    communities_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_GBR_communities)\n",
    "\n",
    "    communities_handle_rmse.write(\"\\n\\nSTrAdaBoost:\\n \")\n",
    "    communities_handle_rmse.writelines(\"%s\\n\" % ele for ele in rmselist_stradaboost_communities)\n",
    "\n",
    "\n",
    "with open('communities_r2.txt', 'w') as communities_handle_r2:\n",
    "    communities_handle_r2.write(\"AdaBoost TL:\\n \")\n",
    "    communities_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_AdaTL_communities)\n",
    "\n",
    "    communities_handle_r2.write(\"\\n\\nAdaBoost:\\n \")\n",
    "    communities_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_Ada_communities)\n",
    "\n",
    "    communities_handle_r2.write(\"\\n\\nGBR:\\n \")\n",
    "    communities_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_GBR_communities)\n",
    "\n",
    "    communities_handle_r2.write(\"\\n\\nSTrAdaBoost:\\n \")\n",
    "    communities_handle_r2.writelines(\"%s\\n\" % ele for ele in r2scorelist_stradaboost_communities)\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "print(\"-------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
