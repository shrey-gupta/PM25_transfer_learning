{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The heat extension is already loaded. To reload it, use:\n",
      "  %reload_ext heat\n"
     ]
    }
   ],
   "source": [
    "import pyheat\n",
    "%load_ext heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats, io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories uploaded!!\n",
      "Second Upload Completed!!\n",
      "The shape of the Input data is:  (392, 8)\n",
      "Target Set:  (119, 7)\n",
      "Source Set:  (157, 7)\n",
      "Test Set:  (116, 7)\n",
      "---------------------------\n",
      "Inside STrAdaBoost.R2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-62891d396ca5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0mprofiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcProfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m \u001b[0mtransfer_boost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tottime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-62891d396ca5>\u001b[0m in \u001b[0;36mtransfer_boost\u001b[0;34m()\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mmodel_stradaboost_auto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_np_train_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_np_train_y_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0my_pred_stradaboost_auto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stradaboost_auto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_np_test_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-62891d396ca5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;31m## Make this model learn.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;31m## source_weight remains the same over all the CV iterations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_weight_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;31m## Get the predictions for the model fitted on the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m         \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             trees = [self._make_estimator(append=False,\n\u001b[0m\u001b[1;32m    377\u001b[0m                                           random_state=random_state)\n\u001b[1;32m    378\u001b[0m                      for i in range(n_more_estimators)]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    374\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             trees = [self._make_estimator(append=False,\n\u001b[0m\u001b[1;32m    377\u001b[0m                                           random_state=random_state)\n\u001b[1;32m    378\u001b[0m                      for i in range(n_more_estimators)]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m    151\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         estimator.set_params(**{p: getattr(self, p)\n\u001b[0m\u001b[1;32m    153\u001b[0m                                 for p in self.estimator_params})\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mvalid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# grouped by prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \"\"\"\n\u001b[1;32m    204\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3091\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3092\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3093\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2840\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2841\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2842\u001b[0;31m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[1;32m   2843\u001b[0m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[1;32m   2844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m         return _signature_from_function(sigcls, obj,\n\u001b[0m\u001b[1;32m   2293\u001b[0m                                         skip_bound_arg=skip_bound_arg)\n\u001b[1;32m   2294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m         \u001b[0mannotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2185\u001b[0;31m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0m\u001b[1;32m   2186\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_KEYWORD_ONLY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2187\u001b[0m                                     default=default))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2510\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'implicit{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2512\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misidentifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2513\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{!r} is not a valid parameter name'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env pypy\n",
    "\n",
    "# %%heat\n",
    "\n",
    "### So using DecisionTreeRegressor Vs RandomForestRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Dropout, Flatten\n",
    "from keras import optimizers, utils, initializers, regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler #Importing the StandardScaler\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "#Geo plotting libraries\n",
    "import geopandas as gdp\n",
    "from matplotlib.colors import ListedColormap\n",
    "# import geoplot as glpt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import statistics \n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import *\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "######### Instance Transfer repositories ####################\n",
    "from adapt.instance_based import TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Repositories uploaded!!\")\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "print(\"Second Upload Completed!!\")\n",
    "\n",
    "#################################################################################################################################\n",
    "#################################################################################################################################\n",
    "#################################################################################################################################\n",
    "\n",
    "############This is the code for STrAdaboost.R2#################################\n",
    "############It has been taken from the following github repository: https://github.com/jay15summer/Two-stage-TrAdaboost.R2 ###############################\n",
    "############It has then been modified for STrAdaBoost.R2#######################\n",
    "\"\"\"\n",
    "STrAdaBoost.R2 algorithm\n",
    "\n",
    "based on algorithm 3 in paper \"Boosting for Regression Transfer\".\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "################################################################################\n",
    "## the second stage\n",
    "################################################################################\n",
    "##DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "class Stage2_TrAdaBoostR2:\n",
    "    def __init__(self,\n",
    "                 base_estimator = RandomForestRegressor(max_depth = 4, n_jobs = 5),\n",
    "                 sample_size = None,\n",
    "                 n_estimators = 100,\n",
    "                 learning_rate = 0.1,\n",
    "                 loss = 'square', #'linear'\n",
    "                 random_state = np.random.mtrand._rand):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.sample_size = sample_size\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = loss\n",
    "        self.random_state = random_state\n",
    "\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        ## Check parameters\n",
    "        if self.learning_rate <= 0:\n",
    "            raise ValueError(\"learning_rate must be greater than zero\")\n",
    "\n",
    "        if sample_weight is None:\n",
    "            ## Initialize weights to 1 / n_samples.\n",
    "            sample_weight = np.empty(X.shape[0], dtype=np.float64) ##???\n",
    "            sample_weight[:] = 1. / X.shape[0] ## Note: 1. means 1.0 .... Hence the expression is 1.0/ X.shape[0]\n",
    "        else:\n",
    "            ## Normalize existing weights. Don't need to normalize before.\n",
    "            sample_weight = sample_weight / sample_weight.sum(dtype=np.float64)\n",
    "\n",
    "            ## Check that the sample weights sum is positive\n",
    "            if sample_weight.sum() <= 0:\n",
    "                raise ValueError(\n",
    "                      \"Attempting to fit with a non-positive \"\n",
    "                      \"weighted number of samples.\")\n",
    "\n",
    "        if self.sample_size is None:\n",
    "            raise ValueError(\"Additional input required: sample size of source and target is missing\")\n",
    "        elif np.array(self.sample_size).sum() != X.shape[0]:\n",
    "            raise ValueError(\"Input error: the specified sample size does not equal to the input size\")\n",
    "\n",
    "        ## Clear any previous fit results\n",
    "        self.estimators_ = []\n",
    "        self.estimator_weights_ = np.zeros(self.n_estimators, dtype=np.float64)\n",
    "        self.estimator_errors_ = np.ones(self.n_estimators, dtype=np.float64)\n",
    "\n",
    "        ## this for loop is sequential and does not support parallel(revison is needed for making parallel)\n",
    "        for iboost in range(self.n_estimators):\n",
    "            ## AdaBoostR2' step\n",
    "            sample_weight, estimator_weight, estimator_error = self._stage2_adaboostR2(iboost, X, y, sample_weight)\n",
    "\n",
    "            ## Early termination. Hence, if it is returned None by the previous step, we would break out of this.\n",
    "            if sample_weight is None:\n",
    "                break\n",
    "\n",
    "            self.estimator_weights_[iboost] = estimator_weight\n",
    "            self.estimator_errors_[iboost] = estimator_error\n",
    "\n",
    "            ## Stop if error is zero. You got the best estimaator.\n",
    "            if estimator_error == 0:\n",
    "                break\n",
    "\n",
    "            sample_weight_sum = np.sum(sample_weight)\n",
    "\n",
    "            ## Stop if the sum of sample weights has become non-positive\n",
    "            if sample_weight_sum <= 0:\n",
    "                break\n",
    "\n",
    "            if iboost < self.n_estimators - 1:\n",
    "            ## Normalize before moving towards the next step.\n",
    "                sample_weight = sample_weight /sample_weight_sum\n",
    "        return self\n",
    "\n",
    "\n",
    "    def _stage2_adaboostR2(self, iboost, X, y, sample_weight):\n",
    "\n",
    "        estimator = copy.deepcopy(self.base_estimator) ## some estimators allow for specifying random_state estimator = base_estimator(random_state=random_state)\n",
    "        ## deepcopy() allows to make a copy and execute changes into the copy without altering the original.\n",
    "\n",
    "        ## using sampling method to account for sample_weight as discussed in Drucker's paper\n",
    "        ## Weighted sampling of the training set with replacement\n",
    "        cdf = np.cumsum(sample_weight)\n",
    "        cdf /= cdf[-1]\n",
    "        # print(\"The cdf is: \", cdf)\n",
    "        uniform_samples = self.random_state.random_sample(X.shape[0])\n",
    "        bootstrap_idx = cdf.searchsorted(uniform_samples, side='right')\n",
    "        # searchsorted returns a scalar\n",
    "        bootstrap_idx = np.array(bootstrap_idx, copy=False)\n",
    "        # print(\"the bootstrap_idx is: \", bootstrap_idx)\n",
    "\n",
    "        # Fit on the bootstrapped sample and obtain a prediction\n",
    "        # for all samples in the training set\n",
    "        estimator.fit(X[bootstrap_idx], y[bootstrap_idx])\n",
    "        y_predict = estimator.predict(X)\n",
    "\n",
    "        ## add the fitted estimator to the list of estimators.\n",
    "        self.estimators_.append(estimator)\n",
    "\n",
    "        error_vect = np.abs(np.subtract(y_predict, y))\n",
    "        error_max = error_vect.max()\n",
    "\n",
    "        if error_max != 0.:\n",
    "            error_vect = error_vect/error_max\n",
    "\n",
    "        if self.loss == 'square':\n",
    "            error_vect **= 2\n",
    "        elif self.loss == 'exponential':\n",
    "            error_vect = 1. - np.exp(- error_vect)\n",
    "\n",
    "        ## Calculate the average loss or the adjusted error is calculated.\n",
    "        estimator_error = (sample_weight * error_vect).sum()\n",
    "\n",
    "        if estimator_error <= 0:\n",
    "            ## Stop if fit is perfect\n",
    "            return sample_weight, 1., 0.\n",
    "\n",
    "        elif estimator_error >= 0.5:\n",
    "            ## Discard current estimator only if it isn't the only one\n",
    "            if len(self.estimators_) > 1:\n",
    "                self.estimators_.pop(-1)\n",
    "            return None, None, None\n",
    "\n",
    "        beta = estimator_error / (1. - estimator_error)\n",
    "\n",
    "        ## avoid overflow of np.log(1. / beta). This step is basically for overflow.\n",
    "        if beta < 1e-308:\n",
    "            beta = 1e-308\n",
    "        estimator_weight = self.learning_rate * np.log(1. / beta)\n",
    "\n",
    "        ## Boost weight using AdaBoost.R2 alg except the weight of the source data remains the same\n",
    "        ## the weight of the source data are remained\n",
    "        # source_weight_sum= np.sum(sample_weight[:-self.sample_size[-1]]) / np.sum(sample_weight)\n",
    "        # target_weight_sum = np.sum(sample_weight[-self.sample_size[-1]:]) / np.sum(sample_weight)\n",
    "\n",
    "        if not iboost == self.n_estimators - 1:\n",
    "            sample_weight[-self.sample_size[-1]:] *= np.power(beta,(1. - error_vect[-self.sample_size[-1]:]) * self.learning_rate)\n",
    "\n",
    "            ## make the sum weight of the source data not changing\n",
    "            # source_weight_sum_new = np.sum(sample_weight[:-self.sample_size[-1]]) / np.sum(sample_weight)\n",
    "            # target_weight_sum_new = np.sum(sample_weight[-self.sample_size[-1]:]) / np.sum(sample_weight)\n",
    "            #\n",
    "            # if source_weight_sum_new != 0. and target_weight_sum_new != 0.:\n",
    "            #     sample_weight[:-self.sample_size[-1]] = sample_weight[:-self.sample_size[-1]]*source_weight_sum/source_weight_sum_new\n",
    "            #     sample_weight[-self.sample_size[-1]:] = sample_weight[-self.sample_size[-1]:]*target_weight_sum/target_weight_sum_new\n",
    "\n",
    "        return sample_weight, estimator_weight, estimator_error\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Evaluate predictions of all estimators\n",
    "        predictions = np.array([\n",
    "                est.predict(X) for est in self.estimators_[:len(self.estimators_)]]).T\n",
    "\n",
    "        # Sort the predictions\n",
    "        sorted_idx = np.argsort(predictions, axis=1)\n",
    "\n",
    "        # Find index of median prediction for each sample\n",
    "        weight_cdf = np.cumsum(self.estimator_weights_[sorted_idx], axis=1)\n",
    "        median_or_above = weight_cdf >= 0.5 * weight_cdf[:, -1][:, np.newaxis]\n",
    "        median_idx = median_or_above.argmax(axis=1)\n",
    "\n",
    "        median_estimators = sorted_idx[np.arange(X.shape[0]), median_idx]\n",
    "\n",
    "        # Return median predictions\n",
    "        return predictions[np.arange(X.shape[0]), median_estimators]\n",
    "\n",
    "\n",
    "################################################################################\n",
    "## the whole two stages\n",
    "################################################################################\n",
    "\n",
    "##DecisionTreeRegressor(max_depth = 6)\n",
    "class TwoStageTrAdaBoostR2:\n",
    "    def __init__(self,\n",
    "                 base_estimator = RandomForestRegressor(max_depth = 4, n_jobs = 5),\n",
    "                 sample_size = None,\n",
    "                 n_estimators = 100,\n",
    "                 steps = 30,\n",
    "                 fold = 10,\n",
    "                 learning_rate = 0.1,\n",
    "                 loss = 'square', #'linear',\n",
    "                 random_state = np.random.mtrand._rand):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.sample_size = sample_size\n",
    "        self.n_estimators = n_estimators\n",
    "        self.steps = steps\n",
    "        self.fold = fold\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = loss\n",
    "        self.random_state = random_state\n",
    "\n",
    "\n",
    "    def fit(self, X, y, sample_weight = None):\n",
    "        # Check parameters\n",
    "        if self.learning_rate <= 0:\n",
    "            raise ValueError(\"learning_rate must be greater than zero\")\n",
    "\n",
    "        if sample_weight is None:\n",
    "            # Initialize weights to 1 / n_samples\n",
    "            sample_weight = np.empty(X.shape[0], dtype=np.float64)\n",
    "            sample_weight[:] = 1. / X.shape[0]\n",
    "        else:\n",
    "            # Normalize existing weights\n",
    "            sample_weight = sample_weight / sample_weight.sum(dtype=np.float64)\n",
    "\n",
    "            # Check that the sample weights sum is positive\n",
    "            if sample_weight.sum() <= 0:\n",
    "                raise ValueError(\n",
    "                      \"Attempting to fit with a non-positive \"\n",
    "                      \"weighted number of samples.\")\n",
    "\n",
    "        ## Checking if correct sample size has been input.\n",
    "        ## If 'no' sample size is provided, raise this error.\n",
    "        if self.sample_size is None:\n",
    "            raise ValueError(\"Additional input required: sample size of source and target is missing\")\n",
    "        ## If sample size provided does not equal to the size of the input then raise this error.\n",
    "        elif np.array(self.sample_size).sum() != X.shape[0]:\n",
    "            raise ValueError(\"Input error: the specified sample size does not equal to the input size\")\n",
    "\n",
    "\n",
    "        ## Dissociates the source and target dataset from X and y provided using sample_size.\n",
    "        X_source = X[:-self.sample_size[-1]]\n",
    "        y_source = y[:-self.sample_size[-1]]\n",
    "        X_target = X[-self.sample_size[-1]:]\n",
    "        y_target = y[-self.sample_size[-1]:]\n",
    "\n",
    "        print(\"Inside STrAdaBoost.R2\")\n",
    "\n",
    "        self.models_ = []\n",
    "        self.errors_ = []\n",
    "\n",
    "        ## This loop accounts for the number of steps 'S' in TrAdaBoost algorithm.\n",
    "        for istep in range(self.steps):\n",
    "            model = AdaBoostRegressor(self.base_estimator,\n",
    "                                      n_estimators = self.n_estimators)\n",
    "\n",
    "            ## The sample weights were calculate above. They are 1/n+m. Where n: no. of source instances, m: no. of target instances.\n",
    "            ## Fitting the model means making it learn. This basically means for 'Boosting', to provide weights to the instances.\n",
    "            model.fit(X, y, sample_weight = sample_weight)\n",
    "            ## Add this models to the list of models\n",
    "            self.models_.append(model)\n",
    "\n",
    "            ## Cross Validation training\n",
    "            kf = KFold(n_splits = self.fold) ## Create no. of CV Folds\n",
    "            error = []\n",
    "            ## Seperate the source and the target weights from the sample_weight\n",
    "            target_weight = sample_weight[-self.sample_size[-1]:]\n",
    "            source_weight = sample_weight[:-self.sample_size[-1]]\n",
    "\n",
    "            ## Find the mean error on the model using CV\n",
    "            for train, test in kf.split(X_target):\n",
    "                sample_size = [self.sample_size[0], len(train)]\n",
    "                ## This initialization always remains constant; so it basically has no effect. We do this for the change in sample_size.\n",
    "                model = AdaBoostRegressor(self.base_estimator,\n",
    "                                          n_estimators = self.n_estimators)\n",
    "\n",
    "                ## Divide the dataset into source and target data.\n",
    "                X_train = np.concatenate((X_source, X_target[train]))\n",
    "                y_train = np.concatenate((y_source, y_target[train]))\n",
    "                X_test = X_target[test]\n",
    "                y_test = y_target[test]\n",
    "\n",
    "                ## make sure the sum weight of the target data do not change with CV's split sampling i.e. Normalizing them by multiplying them with a factor.\n",
    "                ## target_weight_train remians the same over all the CV iterations.\n",
    "                target_weight_train = target_weight[train]*np.sum(target_weight)/np.sum(target_weight[train])\n",
    "                ## Make this model learn.\n",
    "                ## source_weight remains the same over all the CV iterations.\n",
    "                model.fit(X_train, y_train, sample_weight = np.concatenate((source_weight, target_weight_train)))\n",
    "                ## Get the predictions for the model fitted on the test set.\n",
    "                y_predict = model.predict(X_test)\n",
    "                ## Append the error into a list and then we would take mean of this list.\n",
    "                error.append(mean_squared_error(y_predict, y_test))\n",
    "\n",
    "            ## Add the mean of all the errors obtained using KFold CV in the errors list.\n",
    "            ## Each value in 'errors' list corresponds to the model in the 'models' list.\n",
    "            self.errors_.append(np.array(error).mean())\n",
    "            ## Find the updated sample_weights\n",
    "            # sample_weight = self._twostage_adaboostR2(istep, X, y, sample_weight)\n",
    "\n",
    "            ## Updating the sample weights by finding adjusted error first.\n",
    "            y_predict = model.predict(X)\n",
    "            error_vect = np.abs(np.subtract(y_predict, y)) #(y_predict - y)\n",
    "            error_max = error_vect.max()\n",
    "\n",
    "            if error_max != 0.:\n",
    "                error_vect = error_vect/error_max ## error_vect now has the adjusted error.\n",
    "\n",
    "            if self.loss == 'square':\n",
    "                error_vect **= 2\n",
    "            elif self.loss == 'exponential':\n",
    "                error_vect = 1. - np.exp(- error_vect)\n",
    "\n",
    "            estimator_error = (sample_weight * error_vect).sum()\n",
    "\n",
    "            # beta = self._beta_binary_search(istep, sample_weight, error_vect, stp = 1e-30)\n",
    "            # beta = self.get_beta(eta, wt, i, n, m)\n",
    "            n = len(y_source) ## Length of source dataset\n",
    "            m = len(y_target) ## length of target dataset\n",
    "            beta = (m/(n+m) + istep*(1-m/(n+m))/(self.steps-1))\n",
    "            beta2 = estimator_error / (1. - estimator_error)\n",
    "\n",
    "\n",
    "            if not beta:\n",
    "                print(\"can't find beta, break\")\n",
    "                break\n",
    "\n",
    "            # if not istep == self.steps - 1:\n",
    "            ## Updating source instances weight using the equation.\n",
    "            ## Original Equation\n",
    "            sample_weight[:-self.sample_size[-1]] = (sample_weight[:-self.sample_size[-1]]* np.power(beta,error_vect[:-self.sample_size[-1]]))* (self.learning_rate/sample_weight.sum())\n",
    "#             sample_weight[-self.sample_size[-1]:] = sample_weight[-self.sample_size[-1]:]*(self.learning_rate/sample_weight.sum())\n",
    "            sample_weight[-self.sample_size[-1]:] = (sample_weight[-self.sample_size[-1]:]* np.power(beta2,1 - error_vect[-self.sample_size[-1]:]))* (self.learning_rate/sample_weight.sum())\n",
    "\n",
    "\n",
    "            ## If the sample_weights do not exist then break out.\n",
    "            if sample_weight is None:\n",
    "                break\n",
    "            ## If the mean error comes out to be 0 then we have found the perfect model.\n",
    "            if np.array(error).mean() == 0:\n",
    "                break\n",
    "\n",
    "            ## Stop if the sum of sample weights has become non-positive\n",
    "            sample_weight_sum = np.sum(sample_weight)\n",
    "            if sample_weight_sum <= 0:\n",
    "                break\n",
    "\n",
    "            # if istep < self.steps - 1:\n",
    "            #     ## When we reach the end of the no. of steps then normalize the sample_weights\n",
    "            #     sample_weight = sample_weight/sample_weight_sum\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def _twostage_adaboostR2(self, istep, X, y, sample_weight):\n",
    "\n",
    "        ## some estimators allow for specifying random_state estimator = base_estimator(random_state=random_state)\n",
    "        ## Creating a deepcopy of the estimator, so that changes to it does not change the original.\n",
    "        estimator = copy.deepcopy(self.base_estimator)\n",
    "\n",
    "        ## using sampling method to account for sample_weight as discussed in Drucker's paper\n",
    "        ## Weighted sampling of the training set with replacement\n",
    "        cdf = np.cumsum(sample_weight)\n",
    "        cdf /= cdf[-1]\n",
    "        uniform_samples = self.random_state.random_sample(X.shape[0])\n",
    "        bootstrap_idx = cdf.searchsorted(uniform_samples, side='right')\n",
    "        ## searchsorted returns a scalar\n",
    "        bootstrap_idx = np.array(bootstrap_idx, copy=False)\n",
    "        ## Fit on the bootstrapped sample and obtain a prediction for all samples in the training set.\n",
    "        ## Fit on the same model used for deepcopy and using the same sample weights and then make predictions on them.\n",
    "        estimator.fit(X[bootstrap_idx], y[bootstrap_idx])\n",
    "        ##################################################################################################################\n",
    "\n",
    "        ## Updating the sample weights.\n",
    "        y_predict = estimator.predict(X)\n",
    "        ## Calculate error.\n",
    "        error_vect = np.abs(np.subtract(y_predict, y)) #(y_predict - y)\n",
    "        error_max = error_vect.max()\n",
    "\n",
    "        if error_max != 0.:\n",
    "            error_vect /= error_max\n",
    "\n",
    "        if self.loss == 'square':\n",
    "            error_vect = np.square(error_vect) #error_vect **= 2\n",
    "        elif self.loss == 'exponential':\n",
    "            error_vect = 1. - np.exp(- error_vect)\n",
    "\n",
    "        beta = self._beta_binary_search(istep, sample_weight, error_vect, stp = 1e-30)\n",
    "\n",
    "        if not istep == self.steps - 1:\n",
    "            ## Updating source instances weight using the equation.\n",
    "            sample_weight[:-self.sample_size[-1]] *= np.power(beta,(error_vect[:-self.sample_size[-1]]) * self.learning_rate)\n",
    "        return sample_weight\n",
    "\n",
    "\n",
    "    def _beta_binary_search(self, istep, sample_weight, error_vect, stp):\n",
    "        # calculate the specified sum of weight for the target data\n",
    "        n_target = self.sample_size[-1]\n",
    "        n_source = np.array(self.sample_size).sum() - n_target\n",
    "        theoretical_sum = n_target/(n_source+n_target) + istep/(self.steps-1)*(1-n_target/(n_source+n_target))\n",
    "        # for the last iteration step, beta is 0.\n",
    "        if istep == self.steps - 1:\n",
    "            beta = 0.\n",
    "            return beta\n",
    "        # binary search for beta\n",
    "        L = 0.\n",
    "        R = 1.\n",
    "        beta = (L+R)/2\n",
    "        sample_weight_ = copy.deepcopy(sample_weight)\n",
    "        sample_weight_[:-n_target] *= np.power(\n",
    "                    beta,\n",
    "                    (error_vect[:-n_target]) * self.learning_rate)\n",
    "        sample_weight_ /= np.sum(sample_weight_, dtype=np.float64)\n",
    "        updated_weight_sum = np.sum(sample_weight_[-n_target:], dtype=np.float64)\n",
    "\n",
    "        while np.abs(updated_weight_sum - theoretical_sum) > 0.01:\n",
    "            if updated_weight_sum < theoretical_sum:\n",
    "                R = beta - stp\n",
    "                if R > L:\n",
    "                    beta = (L+R)/2\n",
    "                    sample_weight_ = copy.deepcopy(sample_weight)\n",
    "                    sample_weight_[:-n_target] *= np.power(\n",
    "                                beta,\n",
    "                                (error_vect[:-n_target]) * self.learning_rate)\n",
    "                    sample_weight_ /= np.sum(sample_weight_, dtype=np.float64)\n",
    "                    updated_weight_sum = np.sum(sample_weight_[-n_target:], dtype=np.float64)\n",
    "                else:\n",
    "                    print(\"At step:\", istep+1)\n",
    "                    print(\"Binary search's goal not meeted! Value is set to be the available best!\")\n",
    "                    print(\"Try reducing the search interval. Current stp interval:\", stp)\n",
    "                    break\n",
    "\n",
    "            elif updated_weight_sum > theoretical_sum:\n",
    "                L = beta + stp\n",
    "                if L < R:\n",
    "                    beta = (L+R)/2\n",
    "                    sample_weight_ = copy.deepcopy(sample_weight)\n",
    "                    sample_weight_[:-n_target] *= np.power(\n",
    "                                beta,\n",
    "                                (error_vect[:-n_target]) * self.learning_rate)\n",
    "                    sample_weight_ /= np.sum(sample_weight_, dtype=np.float64)\n",
    "                    updated_weight_sum = np.sum(sample_weight_[-n_target:], dtype=np.float64)\n",
    "                else:\n",
    "                    print(\"At step:\", istep+1)\n",
    "                    print(\"Binary search's goal not meeted! Value is set to be the available best!\")\n",
    "                    print(\"Try reducing the search interval. Current stp interval:\", stp)\n",
    "                    break\n",
    "        return beta\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        # select the model with the least CV error\n",
    "        fmodel = self.models_[np.array(self.errors_).argmin()]\n",
    "        predictions = fmodel.predict(X)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "\n",
    "######################################################## Automobile ################################################################\n",
    "## horsepower column has correlation 0.4 :: [46 - 230] :: 30\n",
    "#################################################################################################################################\n",
    "\n",
    "def transfer_boost():\n",
    "    dropcol_initial_auto = ['name']\n",
    "    AutoData_df = pd.read_csv('UCI_regression/MPG/Auto.csv') ## horsepower column has correlation 0.4 :: [46 - 230] :: 30\n",
    "    AutoData_df = AutoData_df.drop(dropcol_initial_auto, axis = 1)\n",
    "    print(\"The shape of the Input data is: \", AutoData_df.shape)\n",
    "\n",
    "    drop_col_auto = ['horsepower']\n",
    "\n",
    "    auto_tgt_df = AutoData_df.loc[(AutoData_df['horsepower'] <= 80)]\n",
    "    auto_tgt_df = auto_tgt_df.drop(drop_col_auto, axis = 1)\n",
    "    auto_tgt_df = auto_tgt_df.reset_index(drop=True)\n",
    "    print(\"Target Set: \",auto_tgt_df.shape)\n",
    "\n",
    "    auto_source_df = AutoData_df.loc[(AutoData_df['horsepower'] > 80) & (AutoData_df['horsepower'] <= 110)]\n",
    "    auto_source_df = auto_source_df.drop(drop_col_auto, axis = 1)\n",
    "    auto_source_df = auto_source_df.reset_index(drop=True)\n",
    "    print(\"Source Set: \",auto_source_df.shape)\n",
    "\n",
    "    auto_test_df = AutoData_df.loc[(AutoData_df['horsepower'] > 110)]\n",
    "    auto_test_df = auto_test_df.drop(drop_col_auto, axis = 1)\n",
    "    auto_test_df = auto_test_df.reset_index(drop=True)\n",
    "    print(\"Test Set: \",auto_test_df.shape)\n",
    "\n",
    "    #################### Splitting into features and target ####################\n",
    "    target_column_auto = ['mpg']\n",
    "\n",
    "    auto_tgt_df_y = auto_tgt_df[target_column_auto]\n",
    "    auto_tgt_df_X = auto_tgt_df.drop(target_column_auto, axis = 1)\n",
    "\n",
    "    auto_source_df_y = auto_source_df[target_column_auto]\n",
    "    auto_source_df_X = auto_source_df.drop(target_column_auto, axis = 1)\n",
    "\n",
    "    auto_test_df_y = auto_test_df[target_column_auto]\n",
    "    auto_test_df_X = auto_test_df.drop(target_column_auto, axis = 1)\n",
    "\n",
    "    ############## Merging the datasets ##########################################\n",
    "    auto_X_df = pd.concat([auto_tgt_df_X, auto_source_df_X], ignore_index=True)\n",
    "    auto_y_df = pd.concat([auto_tgt_df_y, auto_source_df_y], ignore_index=True)\n",
    "\n",
    "    auto_np_train_X = auto_X_df.to_numpy()\n",
    "    auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "    auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "    auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "    auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "    auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "\n",
    "    src_size_auto = len(auto_source_df_y)\n",
    "    tgt_size_auto = len(auto_tgt_df_y)\n",
    "\n",
    "    print(\"---------------------------\")\n",
    "\n",
    "\n",
    "    #################################### STrAdaBoost.R2 Auto ################################################################\n",
    "    # from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "    sample_size = [len(auto_tgt_df_X), len(auto_source_df_X)]\n",
    "    n_estimators = 50\n",
    "    steps = 30\n",
    "    fold = 10\n",
    "    random_state = np.random.RandomState(1)\n",
    "\n",
    "    r2scorelist_stradaboost_auto = []\n",
    "    rmselist_stradaboost_auto = []\n",
    "\n",
    "    for x in range(0, 1):\n",
    "\n",
    "        model_stradaboost_auto = TwoStageTrAdaBoostR2(RandomForestRegressor(max_depth = 4, n_jobs = 5),\n",
    "                            n_estimators = n_estimators, sample_size = sample_size,\n",
    "                            steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "        model_stradaboost_auto.fit(auto_np_train_X, auto_np_train_y_list)\n",
    "        y_pred_stradaboost_auto = model_stradaboost_auto.predict(auto_np_test_X)\n",
    "\n",
    "\n",
    "        mse_stradaboost_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_stradaboost_auto))\n",
    "        rmselist_stradaboost_auto.append(mse_stradaboost_auto)\n",
    "\n",
    "        r2_score_stradaboost_auto = pearsonr(auto_np_test_y_list, y_pred_stradaboost_auto)\n",
    "        r2_score_stradaboost_auto = (r2_score_stradaboost_auto[0])**2\n",
    "        r2scorelist_stradaboost_auto.append(r2_score_stradaboost_auto)\n",
    "\n",
    "\n",
    "    print(\"RMSE of STrAdaboostR2:\", statistics.mean(rmselist_stradaboost_auto))\n",
    "    print(\"R^2 of STrAdaboostR2:\", statistics.mean(r2scorelist_stradaboost_auto))\n",
    "    print(\"\\n\")\n",
    "    print(\"RMSE of STrAdaboostR2:\", rmselist_stradaboost_auto)\n",
    "    print(\"R^2 of STrAdaboostR2:\", r2scorelist_stradaboost_auto)\n",
    "\n",
    "\n",
    "    print(\"-------------------------------------------\")\n",
    "    \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     cProfile.run('main()')\n",
    "\n",
    "# Initialize profile class and call regression() function\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "transfer_boost()\n",
    "profiler.disable()\n",
    "stats = pstats.Stats(profiler).sort_stats('tottime')\n",
    "\n",
    "# Print the stats report\n",
    "stats.print_stats()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2208125537 function calls (2169198043 primitive calls) in 2062.664 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      993    0.001    0.000    0.007    0.000 <__array_function__ internals>:2(all)\n",
      "      330    0.000    0.000    0.003    0.000 <__array_function__ internals>:2(any)\n",
      "      333    0.001    0.000    0.016    0.000 <__array_function__ internals>:2(argsort)\n",
      "    13701    0.013    0.000    0.060    0.000 <__array_function__ internals>:2(atleast_1d)\n",
      "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(atleast_2d)\n",
      "      602    0.001    0.000    0.012    0.000 <__array_function__ internals>:2(average)\n",
      "       27    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(can_cast)\n",
      "    14621    0.016    0.000    0.057    0.000 <__array_function__ internals>:2(concatenate)\n",
      "    28012    0.028    0.000    0.102    0.000 <__array_function__ internals>:2(copyto)\n",
      "    27976    0.028    0.000    0.225    0.000 <__array_function__ internals>:2(cumsum)\n",
      "        7    0.000    0.000    0.001    0.000 <__array_function__ internals>:2(delete)\n",
      "        1    0.000    0.000    0.006    0.006 <__array_function__ internals>:2(dot)\n",
      "      331    0.001    0.000    0.020    0.000 <__array_function__ internals>:2(isclose)\n",
      "        7    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(min_scalar_type)\n",
      "    13701    0.019    0.000    0.188    0.000 <__array_function__ internals>:2(prod)\n",
      "      330    0.000    0.000    0.002    0.000 <__array_function__ internals>:2(ravel)\n",
      "    13701    0.012    0.000    0.072    0.000 <__array_function__ internals>:2(reshape)\n",
      "      331    0.000    0.000    0.001    0.000 <__array_function__ internals>:2(result_type)\n",
      "      330    0.000    0.000    0.001    0.000 <__array_function__ internals>:2(shape)\n",
      "    71510    0.075    0.000    1.037    0.000 <__array_function__ internals>:2(sum)\n",
      "    14693    0.015    0.000    0.335    0.000 <__array_function__ internals>:2(unique)\n",
      "        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(vstack)\n",
      "   206808    0.187    0.000    0.259    0.000 <frozen importlib._bootstrap>:1017(_handle_fromlist)\n",
      "   553122    0.395    0.000    0.555    0.000 <frozen importlib._bootstrap>:389(parent)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-22-02bc7ff63c4e>:269(__init__)\n",
      "        1    0.820    0.820 2062.031 2062.031 <ipython-input-22-02bc7ff63c4e>:288(fit)\n",
      "        1    0.000    0.000    0.425    0.425 <ipython-input-22-02bc7ff63c4e>:525(predict)\n",
      "        1    0.006    0.006 2062.517 2062.517 <ipython-input-22-02bc7ff63c4e>:538(transfer_boost)\n",
      "        1    0.164    0.164 2062.681 2062.681 <ipython-input-22-02bc7ff63c4e>:639(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-22-02bc7ff63c4e>:640(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 <string>:1(__new__)\n",
      "        5    0.000    0.000    0.000    0.000 __init__.py:101(get_op_result_name)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:124(_maybe_match_name)\n",
      "    27402    0.162    0.000    0.176    0.000 __init__.py:172(_array_indexing)\n",
      "    27402    0.087    0.000    0.113    0.000 __init__.py:210(_determine_key_type)\n",
      "    27402    0.052    0.000    0.352    0.000 __init__.py:322(_safe_indexing)\n",
      "   206730    0.432    0.000    3.407    0.000 __init__.py:36(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:427(_align_method_SERIES)\n",
      "   206730    0.378    0.000   10.258    0.000 __init__.py:43(start)\n",
      "        5    0.000    0.000    0.001    0.000 __init__.py:448(_construct_result)\n",
      "        4    0.000    0.000    0.001    0.000 __init__.py:518(wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:544(wrapper)\n",
      "    82692    0.160    0.000    1.705    0.000 __init__.py:8(_make_name)\n",
      "57199/57193    0.032    0.000    0.216    0.000 _asarray.py:16(asarray)\n",
      "       19    0.000    0.000    0.000    0.000 _asarray.py:223(require)\n",
      "       19    0.000    0.000    0.000    0.000 _asarray.py:300(<setcomp>)\n",
      "   102336    0.042    0.000    0.127    0.000 _asarray.py:88(asanyarray)\n",
      "    14032    0.011    0.000    0.011    0.000 _base.py:112(__init__)\n",
      "    14031    0.022    0.000    0.052    0.000 _base.py:124(_validate_estimator)\n",
      "  1383801    5.288    0.000  756.610    0.001 _base.py:145(_make_estimator)\n",
      "  1383801    2.621    0.000    3.891    0.000 _base.py:152(<dictcomp>)\n",
      "    27645    0.255    0.000    1.157    0.000 _base.py:176(_partition_estimators)\n",
      "  1383801    9.602    0.000  274.339    0.000 _base.py:44(_set_random_states)\n",
      "  1384132    2.784    0.000    8.247    0.000 _classes.py:1175(__init__)\n",
      "    27645    0.066    0.000    2.245    0.000 _classes.py:385(_validate_X_predict)\n",
      "  1384132    1.575    0.000    1.575    0.000 _classes.py:85(__init__)\n",
      "    56970    0.027    0.000    0.043    0.000 _config.py:14(get_config)\n",
      "        7    0.000    0.000    0.005    0.001 _decorators.py:225(wrapper)\n",
      "      230    0.000    0.000    0.001    0.000 _dtype.py:319(_name_includes_bit_suffix)\n",
      "      230    0.000    0.000    0.001    0.000 _dtype.py:333(_name_get)\n",
      "      230    0.000    0.000    0.000    0.000 _dtype.py:36(_kind_name)\n",
      "       43    0.000    0.000    0.000    0.000 _dtype.py:46(__str__)\n",
      "    13702    0.046    0.000    0.264    0.000 _forest.py:1443(__init__)\n",
      "    13702    0.028    0.000    0.039    0.000 _forest.py:183(__init__)\n",
      "    13701    0.337    0.000 1788.733    0.131 _forest.py:272(fit)\n",
      "    13701    1.176    0.000  748.814    0.055 _forest.py:376(<listcomp>)\n",
      "   137010    0.177    0.000    0.943    0.000 _forest.py:387(<genexpr>)\n",
      "    13701    0.003    0.000    0.003    0.000 _forest.py:412(_validate_y_class_weight)\n",
      "    27645    0.057    0.000    2.696    0.000 _forest.py:416(_validate_X_predict)\n",
      "    13702    0.025    0.000    0.064    0.000 _forest.py:738(__init__)\n",
      "    27645    0.575    0.000  260.577    0.009 _forest.py:762(predict)\n",
      "    13701    0.004    0.000    0.004    0.000 _forest.py:77(_get_n_samples_bootstrap)\n",
      "   276450    0.318    0.000    1.828    0.000 _forest.py:797(<genexpr>)\n",
      "       42    0.000    0.000    0.000    0.000 _internal.py:830(npy_ctypes_check)\n",
      "      664    0.004    0.000    0.009    0.000 _methods.py:134(_mean)\n",
      "    13731    0.014    0.000    0.120    0.000 _methods.py:28(_amax)\n",
      "    14125    0.009    0.000    0.063    0.000 _methods.py:36(_sum)\n",
      "       66    0.000    0.000    0.000    0.000 _methods.py:44(_any)\n",
      "       26    0.000    0.000    0.000    0.000 _methods.py:47(_all)\n",
      "      664    0.001    0.000    0.001    0.000 _methods.py:50(_count_reduce_items)\n",
      "   413460    0.362    0.000    0.676    0.000 _parallel_backends.py:124(get_nested_backend)\n",
      "    82692    0.016    0.000    0.016    0.000 _parallel_backends.py:137(retrieval_context)\n",
      "    27645    0.024    0.000    0.050    0.000 _parallel_backends.py:185(in_main_thread)\n",
      "    41346    0.018    0.000    0.018    0.000 _parallel_backends.py:227(effective_n_jobs)\n",
      "    41346    1.418    0.000   24.889    0.001 _parallel_backends.py:239(terminate)\n",
      "   413460    0.488    0.000   34.267    0.000 _parallel_backends.py:250(apply_async)\n",
      "    68991    0.133    0.000    0.212    0.000 _parallel_backends.py:280(__init__)\n",
      "   523797    0.361    0.000    0.361    0.000 _parallel_backends.py:34(__init__)\n",
      "    41346    0.036    0.000    0.054    0.000 _parallel_backends.py:389(configure)\n",
      "   413460    0.139    0.000   31.015    0.000 _parallel_backends.py:400(_get_pool)\n",
      "    27645    0.077    0.000    0.164    0.000 _parallel_backends.py:501(effective_n_jobs)\n",
      "   413460    0.092    0.000    0.092    0.000 _parallel_backends.py:590(__init__)\n",
      "    41346    0.007    0.000    0.007    0.000 _parallel_backends.py:80(start_call)\n",
      "    41346    0.008    0.000    0.008    0.000 _parallel_backends.py:83(stop_call)\n",
      "   454806    0.058    0.000    0.058    0.000 _parallel_backends.py:89(compute_batch_size)\n",
      "      301    0.002    0.000    0.070    0.000 _regression.py:193(mean_squared_error)\n",
      "      301    0.002    0.000    0.047    0.000 _regression.py:50(_check_reg_targets)\n",
      "       30    0.000    0.000    0.000    0.000 _split.py:272(__init__)\n",
      "      330    0.000    0.000    0.010    0.000 _split.py:304(split)\n",
      "       30    0.000    0.000    0.000    0.000 _split.py:430(__init__)\n",
      "      330    0.001    0.000    0.001    0.000 _split.py:436(_iter_test_indices)\n",
      "      330    0.002    0.000    0.008    0.000 _split.py:54(split)\n",
      "      330    0.001    0.000    0.005    0.000 _split.py:87(_iter_test_masks)\n",
      "    28076    0.045    0.000    0.049    0.000 _ufunc_config.py:139(geterr)\n",
      "    28076    0.059    0.000    0.139    0.000 _ufunc_config.py:39(seterr)\n",
      "      336    0.001    0.000    0.001    0.000 _ufunc_config.py:437(__init__)\n",
      "    14038    0.025    0.000    0.114    0.000 _ufunc_config.py:441(__enter__)\n",
      "    14038    0.014    0.000    0.064    0.000 _ufunc_config.py:446(__exit__)\n",
      "       14    0.000    0.000    0.000    0.000 _validators.py:207(validate_bool_kwarg)\n",
      "        7    0.000    0.000    0.000    0.000 _validators.py:217(validate_axis_style_args)\n",
      "   326580    0.178    0.000    0.235    0.000 _weakrefset.py:38(_remove)\n",
      "   330768    0.304    0.000    0.386    0.000 _weakrefset.py:81(add)\n",
      "      330    0.001    0.000    0.007    0.000 _weight_boosting.py:1009(_validate_estimator)\n",
      "    13701    0.776    0.000 1945.138    0.142 _weight_boosting.py:1014(_boost)\n",
      "      331    0.016    0.000  115.945    0.350 _weight_boosting.py:1110(_get_median_predict)\n",
      "      331    0.044    0.000  115.862    0.350 _weight_boosting.py:1112(<listcomp>)\n",
      "      331    0.002    0.000  115.975    0.350 _weight_boosting.py:1128(predict)\n",
      "      330    0.001    0.000    0.001    0.000 _weight_boosting.py:59(__init__)\n",
      "      331    0.001    0.000    0.022    0.000 _weight_boosting.py:75(_check_X)\n",
      "      330    0.165    0.000 1945.562    5.896 _weight_boosting.py:79(fit)\n",
      "      330    0.001    0.000    0.002    0.000 _weight_boosting.py:964(__init__)\n",
      "      330    0.001    0.000 1945.563    5.896 _weight_boosting.py:981(fit)\n",
      "   142512    0.044    0.000    0.112    0.000 abc.py:100(__subclasscheck__)\n",
      "  1581762    0.563    0.000    1.494    0.000 abc.py:96(__instancecheck__)\n",
      "       53    0.000    0.000    0.001    0.000 algorithms.py:1436(_get_take_nd_function)\n",
      "       53    0.000    0.000    0.003    0.000 algorithms.py:1565(take_nd)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:107(_get_combined_index)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:149(union_indexes)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:221(_sanitize_and_check)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:242(<setcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:260(get_consensus_names)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:278(<setcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:65(get_objs_combined_axis)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:89(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 api.py:93(_get_distinct_objs)\n",
      "        4    0.000    0.000    0.000    0.000 array_ops.py:202(comparison_op)\n",
      "        1    0.000    0.000    0.000    0.000 array_ops.py:264(na_logical_op)\n",
      "        1    0.000    0.000    0.000    0.000 array_ops.py:305(logical_op)\n",
      "        2    0.000    0.000    0.000    0.000 array_ops.py:326(fill_bool)\n",
      "    14693    0.010    0.000    0.013    0.000 arraysetops.py:138(_unpack_tuple)\n",
      "    14693    0.003    0.000    0.003    0.000 arraysetops.py:146(_unique_dispatcher)\n",
      "    14693    0.030    0.000    0.297    0.000 arraysetops.py:151(unique)\n",
      "    14693    0.122    0.000    0.197    0.000 arraysetops.py:298(_unique1d)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1026(__iter__)\n",
      "       44    0.000    0.000    0.000    0.000 base.py:1182(name)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:1186(name)\n",
      "   139269    0.040    0.000    0.059    0.000 base.py:1192(isspmatrix)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:1217(_get_names)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:1383(nlevels)\n",
      "  6905304   32.720    0.000  542.817    0.000 base.py:162(_get_param_names)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:1656(is_unique)\n",
      "       20    0.000    0.000    0.000    0.000 base.py:1667(is_boolean)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:1679(is_object)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:1682(is_categorical)\n",
      "       24    0.000    0.000    0.000    0.000 base.py:1730(inferred_type)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:1737(is_all_dates)\n",
      "  6905304   37.965    0.000   54.504    0.000 base.py:176(<listcomp>)\n",
      "  6905304   14.793    0.000   22.081    0.000 base.py:187(<listcomp>)\n",
      "  6905304   33.650    0.000  589.513    0.000 base.py:189(get_params)\n",
      "  2767602   12.043    0.000  254.404    0.000 base.py:221(set_params)\n",
      "      451    0.000    0.000    0.001    0.000 base.py:247(is_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:2637(get_loc)\n",
      "       20    0.001    0.000    0.003    0.000 base.py:2706(get_indexer)\n",
      "    36/19    0.001    0.000    0.004    0.000 base.py:276(__new__)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:2967(_convert_listlike_indexer)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3004(_convert_arr_indexer)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3044(_convert_list_indexer)\n",
      "        7    0.000    0.000    0.000    0.000 base.py:3084(_can_reindex)\n",
      "       10    0.000    0.000    0.001    0.000 base.py:3101(reindex)\n",
      "    14031    0.020    0.000    0.020    0.000 base.py:354(_check_n_features)\n",
      "      120    0.000    0.000    0.000    0.000 base.py:3639(values)\n",
      "       24    0.000    0.000    0.000    0.000 base.py:3671(_values)\n",
      "       58    0.000    0.000    0.000    0.000 base.py:3701(_internal_get_values)\n",
      "    14031    0.042    0.000    2.387    0.000 base.py:383(_validate_data)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:3898(__contains__)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:3912(__getitem__)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:3950(_can_hold_identifiers_and_holds_name)\n",
      "       31    0.000    0.000    0.001    0.000 base.py:4047(equals)\n",
      "        8    0.000    0.000    0.000    0.000 base.py:4077(identical)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:4091(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:429(<genexpr>)\n",
      "        3    0.000    0.000    0.001    0.000 base.py:4489(get_indexer_for)\n",
      "       20    0.000    0.000    0.000    0.000 base.py:4506(_maybe_promote)\n",
      "19441719/1383801   25.691    0.000  337.920    0.000 base.py:47(clone)\n",
      "       36    0.000    0.000    0.000    0.000 base.py:472(_simple_new)\n",
      "        7    0.000    0.000    0.001    0.000 base.py:4963(delete)\n",
      "        7    0.000    0.000    0.004    0.001 base.py:4993(drop)\n",
      "       19    0.000    0.000    0.000    0.000 base.py:505(_get_attributes_dict)\n",
      "       19    0.000    0.000    0.000    0.000 base.py:509(<dictcomp>)\n",
      "       16    0.000    0.000    0.000    0.000 base.py:526(_shallow_copy)\n",
      "       95    0.000    0.000    0.004    0.000 base.py:5294(ensure_index)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:5361(_ensure_has_len)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:5388(default_index)\n",
      "       59    0.000    0.000    0.000    0.000 base.py:5394(maybe_extract_name)\n",
      "       16    0.000    0.000    0.000    0.000 base.py:5410(_maybe_cast_with_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:544(_shallow_copy_with_infer)\n",
      "       16    0.000    0.000    0.000    0.000 base.py:5464(_maybe_cast_data_without_dtype)\n",
      "       31    0.000    0.000    0.000    0.000 base.py:573(is_)\n",
      "       42    0.000    0.000    0.000    0.000 base.py:592(_reset_identity)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:602(_engine)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:609(<lambda>)\n",
      "      172    0.000    0.000    0.000    0.000 base.py:615(__len__)\n",
      "       32    0.000    0.000    0.000    0.000 base.py:638(dtype)\n",
      "        6    0.000    0.000    0.000    0.000 base.py:660(view)\n",
      "        6    0.000    0.000    0.001    0.000 base.py:744(take)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:766(_assert_take_fillable)\n",
      "      330    0.000    0.000    0.000    0.000 base.py:777(is_regressor)\n",
      "       25    0.000    0.000    0.000    0.000 base.py:853(_ndarray_values)\n",
      "        2    0.000    0.000    0.000    0.000 blas.py:372(getter)\n",
      "       48    0.000    0.000    0.001    0.000 blocks.py:118(__init__)\n",
      "       23    0.000    0.000    0.002    0.000 blocks.py:1277(take_nd)\n",
      "       48    0.000    0.000    0.000    0.000 blocks.py:129(_check_ndim)\n",
      "       10    0.000    0.000    0.000    0.000 blocks.py:169(_consolidate_key)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:202(external_values)\n",
      "        4    0.000    0.000    0.000    0.000 blocks.py:213(internal_values)\n",
      "        9    0.000    0.000    0.000    0.000 blocks.py:219(array_values)\n",
      "       16    0.000    0.000    0.000    0.000 blocks.py:225(get_values)\n",
      "       29    0.000    0.000    0.000    0.000 blocks.py:243(fill_value)\n",
      "      175    0.000    0.000    0.000    0.000 blocks.py:247(mgr_locs)\n",
      "       48    0.000    0.000    0.000    0.000 blocks.py:251(mgr_locs)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:2597(__init__)\n",
      "       31    0.000    0.000    0.000    0.000 blocks.py:275(make_block_same_class)\n",
      "       26    0.000    0.000    0.001    0.000 blocks.py:2987(get_block_type)\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:300(__len__)\n",
      "       48    0.000    0.000    0.001    0.000 blocks.py:3033(make_block)\n",
      "        8    0.000    0.000    0.000    0.000 blocks.py:3059(_extend_blocks)\n",
      "        2    0.000    0.000    0.001    0.000 blocks.py:3091(_merge_blocks)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:3104(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:3105(<listcomp>)\n",
      "       37    0.000    0.000    0.000    0.000 blocks.py:335(shape)\n",
      "      110    0.000    0.000    0.000    0.000 blocks.py:339(dtype)\n",
      "       43    0.000    0.000    0.001    0.000 blocks.py:343(ftype)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:354(concat_same_type)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:359(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:365(iget)\n",
      "        6    0.000    0.000    0.000    0.000 blocks.py:694(copy)\n",
      "       15    0.000    0.000    0.000    0.000 cast.py:1088(maybe_castable)\n",
      "        6    0.000    0.000    0.000    0.000 cast.py:1102(maybe_infer_to_datetimelike)\n",
      "        8    0.000    0.000    0.000    0.000 cast.py:1209(maybe_cast_to_datetime)\n",
      "        2    0.000    0.000    0.000    0.000 cast.py:1342(find_common_type)\n",
      "        4    0.000    0.000    0.000    0.000 cast.py:1367(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 cast.py:1370(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 cast.py:1374(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 cast.py:1376(<genexpr>)\n",
      "        6    0.000    0.000    0.000    0.000 cast.py:1381(<genexpr>)\n",
      "        6    0.000    0.000    0.001    0.000 cast.py:1458(construct_1d_object_array_from_listlike)\n",
      "        6    0.000    0.000    0.000    0.000 cast.py:1483(construct_1d_ndarray_preserving_na)\n",
      "       36    0.000    0.000    0.001    0.000 cast.py:347(maybe_promote)\n",
      "       36    0.000    0.000    0.000    0.000 cast.py:503(_ensure_dtype_type)\n",
      "        2    0.000    0.000    0.000    0.000 codeop.py:135(__call__)\n",
      "        7    0.000    0.000    0.000    0.000 common.py:1108(is_datetime_or_timedelta_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:120(is_s3_url)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:127(is_gcs_url)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:1282(needs_i8_conversion)\n",
      "        9    0.000    0.000    0.000    0.000 common.py:1326(is_numeric_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1369(is_string_like_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1398(<lambda>)\n",
      "       69    0.000    0.000    0.000    0.000 common.py:1401(is_float_dtype)\n",
      "       57    0.001    0.000    0.001    0.000 common.py:1435(is_bool_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:144(get_filepath_or_buffer)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:151(cast_scalar_indexer)\n",
      "      453    0.000    0.000    0.001    0.000 common.py:1565(is_extension_array_dtype)\n",
      "       14    0.000    0.000    0.000    0.000 common.py:1647(_is_dtype)\n",
      "      167    0.000    0.000    0.000    0.000 common.py:1672(_get_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:169(not_none)\n",
      "      502    0.000    0.000    0.001    0.000 common.py:1708(_is_dtype_type)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:173(<genexpr>)\n",
      "       12    0.000    0.000    0.000    0.000 common.py:179(ensure_python_int)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:183(all_none)\n",
      "      179    0.000    0.000    0.000    0.000 common.py:1844(pandas_dtype)\n",
      "       12    0.000    0.000    0.000    0.000 common.py:187(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:190(any_not_none)\n",
      "        8    0.000    0.000    0.000    0.000 common.py:194(<genexpr>)\n",
      "        7    0.000    0.000    0.000    0.000 common.py:204(count_not_none)\n",
      "      385    0.000    0.000    0.000    0.000 common.py:206(classes)\n",
      "       21    0.000    0.000    0.000    0.000 common.py:208(<genexpr>)\n",
      "      385    0.000    0.000    0.000    0.000 common.py:208(<lambda>)\n",
      "      117    0.000    0.000    0.000    0.000 common.py:211(classes_and_not_datetimelike)\n",
      "      117    0.000    0.000    0.000    0.000 common.py:216(<lambda>)\n",
      "       43    0.000    0.000    0.000    0.000 common.py:219(asarray_tuplesafe)\n",
      "      123    0.001    0.000    0.001    0.000 common.py:222(is_object_dtype)\n",
      "        7    0.000    0.000    0.000    0.000 common.py:242(index_labels_to_array)\n",
      "       54    0.000    0.000    0.000    0.000 common.py:252(is_sparse)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:259(infer_compression)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:275(maybe_iterable_to_list)\n",
      "       10    0.000    0.000    0.000    0.000 common.py:330(apply_if_callable)\n",
      "       26    0.000    0.000    0.000    0.000 common.py:339(is_categorical)\n",
      "       84    0.000    0.000    0.000    0.000 common.py:372(is_datetime64_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:40(is_url)\n",
      "      144    0.000    0.000    0.000    0.000 common.py:403(is_datetime64tz_dtype)\n",
      "      102    0.000    0.000    0.000    0.000 common.py:441(is_timedelta64_dtype)\n",
      "      111    0.000    0.000    0.000    0.000 common.py:472(is_period_dtype)\n",
      "        5    0.000    0.000    0.002    0.000 common.py:49(new_method)\n",
      "      105    0.000    0.000    0.000    0.000 common.py:506(is_interval_dtype)\n",
      "      151    0.000    0.000    0.001    0.000 common.py:542(is_categorical_dtype)\n",
      "       13    0.000    0.000    0.000    0.000 common.py:575(is_string_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:58(_expand_user)\n",
      "       13    0.000    0.000    0.000    0.000 common.py:605(condition)\n",
      "        7    0.000    0.000    0.000    0.000 common.py:608(is_excluded_dtype)\n",
      "       21    0.000    0.000    0.000    0.000 common.py:613(<genexpr>)\n",
      "       48    0.000    0.000    0.000    0.000 common.py:685(is_dtype_equal)\n",
      "       41    0.000    0.000    0.000    0.000 common.py:775(is_integer_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:78(validate_header_arg)\n",
      "       35    0.000    0.000    0.000    0.000 common.py:830(is_signed_integer_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:88(stringify_path)\n",
      "       32    0.000    0.000    0.000    0.000 common.py:887(is_unsigned_integer_dtype)\n",
      "       72    0.000    0.000    0.000    0.000 common.py:987(is_datetime64_any_dtype)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:99(is_bool_indexer)\n",
      "        4    0.000    0.000    0.000    0.000 compilerop.py:138(extra_flags)\n",
      "       10    0.000    0.000    0.000    0.000 concat.py:104(<genexpr>)\n",
      "       10    0.000    0.000    0.000    0.000 concat.py:105(<genexpr>)\n",
      "       12    0.000    0.000    0.000    0.000 concat.py:115(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 concat.py:119(<genexpr>)\n",
      "       15    0.000    0.000    0.000    0.000 concat.py:120(<genexpr>)\n",
      "       10    0.000    0.000    0.000    0.000 concat.py:126(needs_filling)\n",
      "       10    0.000    0.000    0.000    0.000 concat.py:135(dtype)\n",
      "       12    0.000    0.000    0.001    0.000 concat.py:145(is_na)\n",
      "       10    0.000    0.000    0.001    0.000 concat.py:173(get_reindexed_values)\n",
      "        5    0.000    0.000    0.002    0.000 concat.py:236(concatenate_join_units)\n",
      "        5    0.000    0.000    0.001    0.000 concat.py:246(<listcomp>)\n",
      "        5    0.000    0.000    0.001    0.000 concat.py:268(_get_empty_dtype_and_na)\n",
      "        4    0.000    0.000    0.000    0.000 concat.py:28(get_mgr_concatenation_plan)\n",
      "        2    0.000    0.000    0.001    0.000 concat.py:292(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 concat.py:31(get_dtype_kinds)\n",
      "        6    0.000    0.000    0.001    0.000 concat.py:375(is_uniform_join_units)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:377(<listcomp>)\n",
      "       18    0.000    0.000    0.000    0.000 concat.py:384(<genexpr>)\n",
      "       18    0.000    0.000    0.001    0.000 concat.py:388(<genexpr>)\n",
      "       13    0.000    0.000    0.000    0.000 concat.py:391(<genexpr>)\n",
      "        5    0.000    0.000    0.000    0.000 concat.py:398(_is_uniform_reindex)\n",
      "       10    0.000    0.000    0.000    0.000 concat.py:401(<genexpr>)\n",
      "        8    0.000    0.000    0.000    0.000 concat.py:434(combine_concat_plans)\n",
      "        2    0.000    0.000    0.003    0.002 concat.py:454(get_result)\n",
      "       16    0.000    0.000    0.000    0.000 concat.py:459(_next_or_none)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:507(_get_result_dim)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:513(_get_new_axes)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:515(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:520(_get_comb_axis)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:526(_get_concat_axis)\n",
      "        2    0.000    0.000    0.000    0.000 concat.py:559(<listcomp>)\n",
      "        6    0.000    0.000    0.000    0.000 concat.py:562(<genexpr>)\n",
      "        2    0.000    0.000    0.004    0.002 concat.py:65(concat)\n",
      "        5    0.000    0.000    0.000    0.000 concat.py:72(concat_compat)\n",
      "        5    0.000    0.000    0.000    0.000 concat.py:91(is_nonempty)\n",
      "    82692    0.076    0.000    0.076    0.000 connection.py:117(__init__)\n",
      "    82692    0.069    0.000    0.410    0.000 connection.py:130(__del__)\n",
      "   124038    0.031    0.000    0.031    0.000 connection.py:134(_check_closed)\n",
      "   124038    0.022    0.000    0.022    0.000 connection.py:142(_check_writable)\n",
      "   124038    0.338    0.000    1.450    0.000 connection.py:181(send_bytes)\n",
      "    82692    0.048    0.000    0.341    0.000 connection.py:360(_close)\n",
      "   124038    0.106    0.000    0.781    0.000 connection.py:365(_send)\n",
      "   124038    0.190    0.000    1.040    0.000 connection.py:390(_send_bytes)\n",
      "    41346    0.100    0.000    0.461    0.000 connection.py:516(Pipe)\n",
      "        1    0.000    0.000    0.007    0.007 construction.py:213(init_dict)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:300(_homogenize)\n",
      "       79    0.000    0.000    0.000    0.000 construction.py:337(extract_array)\n",
      "       16    0.000    0.000    0.002    0.000 construction.py:388(sanitize_array)\n",
      "       16    0.000    0.000    0.001    0.000 construction.py:506(_try_cast)\n",
      "        1    0.000    0.000    0.002    0.002 construction.py:56(arrays_to_mgr)\n",
      "        9    0.000    0.000    0.000    0.000 construction.py:570(is_empty_data)\n",
      "        1    0.000    0.000    0.002    0.002 construction.py:590(create_series_with_explicit_dtype)\n",
      "    41346    0.210    0.000    5.899    0.000 context.py:110(SimpleQueue)\n",
      "   124038    0.024    0.000    0.024    0.000 context.py:187(get_context)\n",
      "    82692    0.021    0.000    0.021    0.000 context.py:197(get_start_method)\n",
      "    82692    0.035    0.000    0.035    0.000 context.py:233(get_context)\n",
      "    82692    0.263    0.000    5.034    0.000 context.py:65(Lock)\n",
      "    41348    0.037    0.000    0.057    0.000 contextlib.py:108(__enter__)\n",
      "    41348    0.067    0.000    0.116    0.000 contextlib.py:117(__exit__)\n",
      "    41348    0.039    0.000    0.115    0.000 contextlib.py:238(helper)\n",
      "    13702    0.002    0.000    0.002    0.000 contextlib.py:59(_recreate_cm)\n",
      "    13702    0.036    0.000    1.120    0.000 contextlib.py:72(inner)\n",
      "    41348    0.065    0.000    0.076    0.000 contextlib.py:82(__init__)\n",
      " 18057918   14.703    0.000   21.737    0.000 copy.py:128(deepcopy)\n",
      " 18057918    1.757    0.000    1.757    0.000 copy.py:182(_deepcopy_atomic)\n",
      "    41346    0.159    0.000    0.159    0.000 disk.py:42(memstr_to_bytes)\n",
      "        5    0.000    0.000    0.000    0.000 dispatch.py:21(should_extension_dispatch)\n",
      "       85    0.000    0.000    0.000    0.000 dtypes.py:1124(is_dtype)\n",
      "      454    0.000    0.000    0.000    0.000 dtypes.py:75(find)\n",
      "       91    0.000    0.000    0.000    0.000 dtypes.py:917(is_dtype)\n",
      " 96948276   33.550    0.000   46.968    0.000 enum.py:278(__call__)\n",
      " 96948276   13.418    0.000   13.418    0.000 enum.py:557(__new__)\n",
      "    56970    0.156    0.000    1.190    0.000 extmath.py:686(_safe_accumulator_op)\n",
      "      331    0.002    0.000    0.037    0.000 extmath.py:815(stable_cumsum)\n",
      "    41346    0.127    0.000    0.797    0.000 fixes.py:65(_joblib_parallel_args)\n",
      "       10    0.000    0.000    0.000    0.000 fractions.py:282(numerator)\n",
      "       10    0.000    0.000    0.000    0.000 fractions.py:286(denominator)\n",
      "        4    0.000    0.000    0.000    0.000 fractions.py:382(forward)\n",
      "        2    0.000    0.000    0.000    0.000 fractions.py:394(reverse)\n",
      "        4    0.000    0.000    0.000    0.000 fractions.py:409(_add)\n",
      "        2    0.000    0.000    0.000    0.000 fractions.py:431(_div)\n",
      "       10    0.000    0.000    0.000    0.000 fractions.py:84(__new__)\n",
      "        7    0.000    0.000    0.000    0.000 frame.py:1037(__len__)\n",
      "        4    0.000    0.000    0.002    0.000 frame.py:1249(to_numpy)\n",
      "        7    0.000    0.000    0.004    0.001 frame.py:2767(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:3066(_box_item_values)\n",
      "        1    0.000    0.000    0.000    0.000 frame.py:3073(_box_col_values)\n",
      "        7    0.000    0.000    0.004    0.001 frame.py:3732(_reindex_axes)\n",
      "        7    0.000    0.000    0.004    0.001 frame.py:3769(_reindex_columns)\n",
      "        7    0.000    0.000    0.005    0.001 frame.py:3837(reindex)\n",
      "        7    0.000    0.000    0.009    0.001 frame.py:3858(drop)\n",
      "       18    0.000    0.000    0.000    0.000 frame.py:399(_constructor)\n",
      "       19    0.000    0.000    0.007    0.000 frame.py:414(__init__)\n",
      "        3    0.000    0.000    0.001    0.000 frame.py:4369(reset_index)\n",
      "        8    0.000    0.000    0.000    0.000 frame.py:532(shape)\n",
      "      330    0.000    0.000    0.000    0.000 fromnumeric.py:1689(_ravel_dispatcher)\n",
      "      330    0.001    0.000    0.001    0.000 fromnumeric.py:1693(ravel)\n",
      "      330    0.000    0.000    0.000    0.000 fromnumeric.py:1899(_shape_dispatcher)\n",
      "      330    0.000    0.000    0.000    0.000 fromnumeric.py:1903(shape)\n",
      "    13701    0.003    0.000    0.003    0.000 fromnumeric.py:197(_reshape_dispatcher)\n",
      "    13701    0.011    0.000    0.049    0.000 fromnumeric.py:202(reshape)\n",
      "    71510    0.013    0.000    0.013    0.000 fromnumeric.py:2087(_sum_dispatcher)\n",
      "    71510    0.118    0.000    0.877    0.000 fromnumeric.py:2092(sum)\n",
      "      330    0.000    0.000    0.000    0.000 fromnumeric.py:2232(_any_dispatcher)\n",
      "      330    0.000    0.000    0.002    0.000 fromnumeric.py:2236(any)\n",
      "      993    0.000    0.000    0.000    0.000 fromnumeric.py:2320(_all_dispatcher)\n",
      "      993    0.001    0.000    0.005    0.000 fromnumeric.py:2324(all)\n",
      "    27976    0.006    0.000    0.006    0.000 fromnumeric.py:2401(_cumsum_dispatcher)\n",
      "    27976    0.031    0.000    0.171    0.000 fromnumeric.py:2405(cumsum)\n",
      "    13701    0.003    0.000    0.003    0.000 fromnumeric.py:2838(_prod_dispatcher)\n",
      "    13701    0.020    0.000    0.151    0.000 fromnumeric.py:2843(prod)\n",
      "    42010    0.035    0.000    0.192    0.000 fromnumeric.py:55(_wrapfunc)\n",
      "    86534    0.204    0.000    0.880    0.000 fromnumeric.py:73(_wrapreduction)\n",
      "    86534    0.052    0.000    0.052    0.000 fromnumeric.py:74(<dictcomp>)\n",
      "      333    0.000    0.000    0.000    0.000 fromnumeric.py:993(_argsort_dispatcher)\n",
      "      333    0.001    0.000    0.015    0.000 fromnumeric.py:997(argsort)\n",
      "        7    0.000    0.000    0.000    0.000 function.py:42(__call__)\n",
      "      602    0.000    0.000    0.000    0.000 function_base.py:289(_average_dispatcher)\n",
      "      602    0.001    0.000    0.010    0.000 function_base.py:293(average)\n",
      "        7    0.000    0.000    0.000    0.000 function_base.py:4214(_delete_dispatcher)\n",
      "        7    0.000    0.000    0.001    0.000 function_base.py:4218(delete)\n",
      "        2    0.000    0.000    0.000    0.000 function_base.py:435(asarray_chkfinite)\n",
      "   413460    0.886    0.000    1.571    0.000 functools.py:34(update_wrapper)\n",
      "   413460    0.176    0.000    0.176    0.000 functools.py:64(wraps)\n",
      "     2073    0.001    0.000    0.001    0.000 generic.py:10(_check)\n",
      "        1    0.000    0.000    0.001    0.001 generic.py:11341(logical_func)\n",
      "       28    0.000    0.000    0.000    0.000 generic.py:190(__init__)\n",
      "       18    0.000    0.000    0.000    0.000 generic.py:219(_init_mgr)\n",
      "       29    0.000    0.000    0.000    0.000 generic.py:238(attrs)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:255(_validate_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:3227(_set_as_cached)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:3294(_clear_item_cache)\n",
      "        6    0.000    0.000    0.004    0.001 generic.py:3300(take)\n",
      "        6    0.000    0.000    0.004    0.001 generic.py:3399(_take_with_is_copy)\n",
      "        8    0.000    0.000    0.000    0.000 generic.py:356(_construct_axes_from_arguments)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:3581(_get_item_cache)\n",
      "        6    0.000    0.000    0.000    0.000 generic.py:3627(_set_is_copy)\n",
      "        8    0.000    0.000    0.000    0.000 generic.py:381(<dictcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:384(_from_axes)\n",
      "        7    0.000    0.000    0.009    0.001 generic.py:3907(drop)\n",
      "        7    0.000    0.000    0.009    0.001 generic.py:3943(_drop_axis)\n",
      "       28    0.000    0.000    0.000    0.000 generic.py:396(_get_axis_number)\n",
      "       64    0.000    0.000    0.000    0.000 generic.py:409(_get_axis_name)\n",
      "       43    0.000    0.000    0.000    0.000 generic.py:422(_get_axis)\n",
      "       15    0.000    0.000    0.000    0.000 generic.py:426(_get_block_manager_axis)\n",
      "        8    0.000    0.000    0.005    0.001 generic.py:4299(reindex)\n",
      "       16    0.000    0.000    0.000    0.000 generic.py:4529(<genexpr>)\n",
      "        7    0.000    0.000    0.000    0.000 generic.py:4572(_needs_reindex_multi)\n",
      "        7    0.000    0.000    0.004    0.001 generic.py:4584(_reindex_with_indexers)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:491(_info_axis)\n",
      "        8    0.000    0.000    0.000    0.000 generic.py:515(ndim)\n",
      "       31    0.000    0.000    0.000    0.000 generic.py:5235(__finalize__)\n",
      "       18    0.000    0.000    0.000    0.000 generic.py:5257(__getattr__)\n",
      "       47    0.000    0.000    0.000    0.000 generic.py:5276(__setattr__)\n",
      "       22    0.000    0.000    0.001    0.000 generic.py:5331(_protect_consolidate)\n",
      "       22    0.000    0.000    0.001    0.000 generic.py:5341(_consolidate_inplace)\n",
      "       22    0.000    0.000    0.001    0.000 generic.py:5344(f)\n",
      "        4    0.000    0.000    0.000    0.000 generic.py:5349(_consolidate)\n",
      "        4    0.000    0.000    0.002    0.000 generic.py:5412(values)\n",
      "        3    0.000    0.000    0.001    0.000 generic.py:5706(copy)\n",
      "        3    0.000    0.000    0.000    0.000 generic.py:660(_set_axis)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:7264(isna)\n",
      "    27402    0.029    0.000    0.037    0.000 getlimits.py:365(__new__)\n",
      "  1383801    3.578    0.000    3.578    0.000 getlimits.py:497(__init__)\n",
      "  1383801    0.740    0.000    0.740    0.000 getlimits.py:521(max)\n",
      "        2    0.000    0.000    0.000    0.000 hooks.py:103(__call__)\n",
      "        2    0.000    0.000    0.000    0.000 hooks.py:168(pre_run_code_hook)\n",
      "        6    0.001    0.000    0.001    0.000 indexers.py:173(maybe_convert_indices)\n",
      "        3    0.000    0.000    0.000    0.000 indexers.py:278(check_array_indexer)\n",
      "        3    0.000    0.000    0.000    0.000 indexing.py:1344(_convert_for_reindex)\n",
      "        3    0.000    0.000    0.002    0.001 indexing.py:1503(_get_listlike_indexer)\n",
      "        3    0.000    0.000    0.000    0.000 indexing.py:1600(_validate_read_indexer)\n",
      "        3    0.000    0.000    0.003    0.001 indexing.py:1754(__getitem__)\n",
      "        3    0.000    0.000    0.003    0.001 indexing.py:1779(_getbool_axis)\n",
      "        3    0.000    0.000    0.000    0.000 indexing.py:1870(_get_partial_string_timestamp_match_key)\n",
      "        3    0.000    0.000    0.003    0.001 indexing.py:1902(_getitem_axis)\n",
      "        3    0.000    0.000    0.000    0.000 indexing.py:2261(convert_to_index_sliceable)\n",
      "        3    0.000    0.000    0.000    0.000 indexing.py:2286(check_bool_indexer)\n",
      "        6    0.000    0.000    0.000    0.000 indexing.py:231(loc)\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:130(is_file_like)\n",
      "        6    0.000    0.000    0.000    0.000 inference.py:220(is_array_like)\n",
      "        2    0.000    0.000    0.000    0.000 inference.py:299(is_dict_like)\n",
      "        7    0.000    0.000    0.000    0.000 inference.py:325(<genexpr>)\n",
      "       87    0.000    0.000    0.000    0.000 inference.py:358(is_hashable)\n",
      "       24    0.000    0.000    0.000    0.000 inference.py:96(is_iterator)\n",
      " 13810608    3.575    0.000    4.697    0.000 inspect.py:158(isfunction)\n",
      "  6905304  109.465    0.000  355.772    0.000 inspect.py:2112(_signature_from_function)\n",
      "  6905304   23.509    0.000  409.475    0.000 inspect.py:2206(_signature_from_callable)\n",
      "  6905304    1.576    0.000    2.350    0.000 inspect.py:2234(<lambda>)\n",
      " 96948276   89.735    0.000  154.245    0.000 inspect.py:2477(__init__)\n",
      "283939524   25.620    0.000   25.620    0.000 inspect.py:2527(name)\n",
      "180085944   15.315    0.000   15.315    0.000 inspect.py:2539(kind)\n",
      "  6905304   29.378    0.000   64.089    0.000 inspect.py:2760(__init__)\n",
      "103853580   24.899    0.000   34.711    0.000 inspect.py:2809(<genexpr>)\n",
      "  6905304    3.259    0.000  412.734    0.000 inspect.py:2839(from_callable)\n",
      " 29256302    3.398    0.000    3.398    0.000 inspect.py:2845(parameters)\n",
      "  6905304    3.553    0.000  416.287    0.000 inspect.py:3091(signature)\n",
      "  6905304   12.054    0.000   24.668    0.000 inspect.py:493(unwrap)\n",
      " 13810608    4.928    0.000    9.146    0.000 inspect.py:513(_is_wrapper)\n",
      "    55621    0.020    0.000    0.035    0.000 inspect.py:72(isclass)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:1276(user_global_ns)\n",
      "        2    0.000    0.000    0.000    0.000 interactiveshell.py:3240(compare)\n",
      "        2    0.000    0.000 2062.681 1031.340 interactiveshell.py:3302(run_code)\n",
      "       42    0.000    0.000    0.002    0.000 iostream.py:197(schedule)\n",
      "       40    0.000    0.000    0.000    0.000 iostream.py:310(_is_master_process)\n",
      "       40    0.000    0.000    0.000    0.000 iostream.py:323(_schedule_flush)\n",
      "       40    0.000    0.000    0.002    0.000 iostream.py:386(write)\n",
      "       42    0.000    0.000    0.000    0.000 iostream.py:93(_event_pipe)\n",
      "        2    0.000    0.000    0.000    0.000 ipstruct.py:125(__getattr__)\n",
      "    41346    0.042    0.000    0.063    0.000 logger.py:23(_squeeze_time)\n",
      "    41346    0.121    0.000    0.184    0.000 logger.py:39(short_format_time)\n",
      "       20    0.000    0.000    0.002    0.000 managers.py:122(__init__)\n",
      "       13    0.000    0.000    0.005    0.000 managers.py:1224(reindex_indexer)\n",
      "        3    0.000    0.000    0.001    0.000 managers.py:1259(<listcomp>)\n",
      "       10    0.001    0.000    0.003    0.000 managers.py:1274(_slice_take_blocks_ax0)\n",
      "       20    0.000    0.000    0.000    0.000 managers.py:128(<listcomp>)\n",
      "        6    0.000    0.000    0.003    0.001 managers.py:1373(take)\n",
      "        8    0.000    0.000    0.001    0.000 managers.py:1467(__init__)\n",
      "       34    0.000    0.000    0.000    0.000 managers.py:1520(_block)\n",
      "       20    0.000    0.000    0.000    0.000 managers.py:1548(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1562(external_values)\n",
      "        4    0.000    0.000    0.000    0.000 managers.py:1565(internal_values)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1576(is_consolidated)\n",
      "       83    0.000    0.000    0.000    0.000 managers.py:163(shape)\n",
      "      249    0.000    0.000    0.000    0.000 managers.py:165(<genexpr>)\n",
      "        1    0.000    0.000    0.001    0.001 managers.py:1667(create_block_manager_from_arrays)\n",
      "       86    0.000    0.000    0.000    0.000 managers.py:167(ndim)\n",
      "        1    0.000    0.000    0.001    0.001 managers.py:1700(form_blocks)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:171(set_axis)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1797(_simple_blockify)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1811(_multi_blockify)\n",
      "        8    0.000    0.000    0.000    0.000 managers.py:1815(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1828(_stack_arrays)\n",
      "        9    0.000    0.000    0.000    0.000 managers.py:1831(_asarray_compat)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1837(_shape_compat)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1855(_interleaved_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:1872(<listcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 managers.py:1875(_consolidate)\n",
      "       10    0.000    0.000    0.000    0.000 managers.py:1881(<lambda>)\n",
      "       10    0.000    0.000    0.000    0.000 managers.py:1970(_preprocess_slice_or_indexer)\n",
      "        2    0.000    0.000    0.003    0.002 managers.py:1988(concatenate_block_managers)\n",
      "       22    0.000    0.000    0.000    0.000 managers.py:199(_is_single_block)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:2000(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:2018(<listcomp>)\n",
      "       21    0.001    0.000    0.001    0.000 managers.py:212(_rebuild_blknos_and_blklocs)\n",
      "       25    0.000    0.000    0.000    0.000 managers.py:232(items)\n",
      "        6    0.000    0.000    0.000    0.000 managers.py:314(__len__)\n",
      "       17    0.000    0.000    0.000    0.000 managers.py:329(_verify_integrity)\n",
      "       54    0.000    0.000    0.000    0.000 managers.py:331(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:368(apply)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:419(<dictcomp>)\n",
      "       47    0.000    0.000    0.000    0.000 managers.py:647(is_consolidated)\n",
      "       20    0.000    0.000    0.001    0.000 managers.py:655(_consolidate_check)\n",
      "       20    0.000    0.000    0.001    0.000 managers.py:656(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 managers.py:660(is_mixed_type)\n",
      "        3    0.000    0.000    0.001    0.000 managers.py:766(copy)\n",
      "        6    0.000    0.000    0.000    0.000 managers.py:784(copy_func)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:790(<listcomp>)\n",
      "        4    0.000    0.000    0.001    0.000 managers.py:798(as_array)\n",
      "        2    0.000    0.000    0.001    0.000 managers.py:834(_interleave)\n",
      "       22    0.000    0.000    0.001    0.000 managers.py:927(consolidate)\n",
      "       26    0.000    0.000    0.001    0.000 managers.py:943(_consolidate_inplace)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:950(get)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:979(iget)\n",
      "        2    0.002    0.001    0.002    0.001 misc.py:19(norm)\n",
      "       48    0.000    0.000    0.001    0.000 missing.py:132(_isna_new)\n",
      "        7    0.001    0.000    0.001    0.000 missing.py:225(_isna_ndarraylike)\n",
      "       29    0.000    0.000    0.000    0.000 missing.py:410(array_equivalent)\n",
      "       48    0.000    0.000    0.001    0.000 missing.py:49(isna)\n",
      "       28    0.000    0.000    0.000    0.000 missing.py:601(clean_reindex_fill_method)\n",
      "       28    0.000    0.000    0.000    0.000 missing.py:73(clean_fill_method)\n",
      "    28012    0.006    0.000    0.006    0.000 multiarray.py:1043(copyto)\n",
      "    14621    0.003    0.000    0.003    0.000 multiarray.py:145(concatenate)\n",
      "       27    0.000    0.000    0.000    0.000 multiarray.py:469(can_cast)\n",
      "        7    0.000    0.000    0.000    0.000 multiarray.py:584(min_scalar_type)\n",
      "      331    0.000    0.000    0.000    0.000 multiarray.py:635(result_type)\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:707(dot)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:166(_get_fill_value)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:189(_maybe_get_mask)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:234(_get_values)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:329(_na_ok_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:396(nanany)\n",
      "        2    0.000    0.000    0.000    0.000 numbers.py:283(__float__)\n",
      "        6    0.000    0.000    0.000    0.000 numeric.py:107(_shallow_copy)\n",
      "        6    0.000    0.000    0.000    0.000 numeric.py:155(is_all_dates)\n",
      "      337    0.001    0.000    0.003    0.000 numeric.py:159(ones)\n",
      "      331    0.000    0.000    0.000    0.000 numeric.py:2163(_isclose_dispatcher)\n",
      "      331    0.003    0.000    0.019    0.000 numeric.py:2167(isclose)\n",
      "      331    0.004    0.000    0.010    0.000 numeric.py:2244(within_tol)\n",
      "        3    0.000    0.000    0.000    0.000 numeric.py:249(inferred_type)\n",
      "    27675    0.046    0.000    0.208    0.000 numeric.py:283(full)\n",
      "        3    0.000    0.000    0.000    0.000 numeric.py:53(__new__)\n",
      "        9    0.000    0.000    0.000    0.000 numeric.py:83(_validate_dtype)\n",
      "   142898    0.086    0.000    0.131    0.000 numerictypes.py:293(issubclass_)\n",
      "    71449    0.092    0.000    0.231    0.000 numerictypes.py:365(issubdtype)\n",
      "       14    0.000    0.000    0.000    0.000 numerictypes.py:578(_can_coerce_all)\n",
      "       28    0.000    0.000    0.000    0.000 numerictypes.py:587(<listcomp>)\n",
      "        7    0.000    0.000    0.000    0.000 numerictypes.py:602(find_common_type)\n",
      "        7    0.000    0.000    0.000    0.000 numerictypes.py:654(<listcomp>)\n",
      "        7    0.000    0.000    0.000    0.000 numerictypes.py:655(<listcomp>)\n",
      "        9    0.000    0.000    0.000    0.000 numpy_.py:138(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 numpy_.py:183(__array__)\n",
      "        6    0.000    0.000    0.000    0.000 numpy_.py:417(to_numpy)\n",
      "        9    0.000    0.000    0.000    0.000 numpy_.py:42(__init__)\n",
      "   413460    0.403    0.000    0.489    0.000 parallel.py:235(__init__)\n",
      "  1240380    0.150    0.000    0.150    0.000 parallel.py:265(__len__)\n",
      "   413460    0.455    0.000    2.202    0.000 parallel.py:302(delayed)\n",
      "   413460    0.061    0.000    0.061    0.000 parallel.py:312(delayed_function)\n",
      "   413460    0.148    0.000    0.148    0.000 parallel.py:333(__init__)\n",
      "    27645    0.048    0.000    0.436    0.000 parallel.py:373(effective_n_jobs)\n",
      "    41346    0.442    0.000    2.184    0.000 parallel.py:625(__init__)\n",
      "    41346    0.141    0.000    0.195    0.000 parallel.py:718(_initialize_backend)\n",
      "    41346    0.044    0.000   24.933    0.001 parallel.py:743(_terminate_backend)\n",
      "   413460    1.079    0.000   35.965    0.000 parallel.py:747(_dispatch)\n",
      "    68991    0.211    0.000    0.543    0.000 parallel.py:76(get_active_backend)\n",
      "   454806    2.081    0.000   46.449    0.000 parallel.py:784(dispatch_one_batch)\n",
      "    82692    0.025    0.000    0.025    0.000 parallel.py:850(_print)\n",
      "    41346   12.031    0.000 1213.020    0.029 parallel.py:906(retrieve)\n",
      "    41346    0.928    0.000 1287.097    0.031 parallel.py:946(__call__)\n",
      "        6    0.000    0.000    0.000    0.000 parse.py:110(_coerce_args)\n",
      "        3    0.000    0.000    0.000    0.000 parse.py:366(urlparse)\n",
      "        3    0.000    0.000    0.000    0.000 parse.py:417(urlsplit)\n",
      "        6    0.000    0.000    0.000    0.000 parse.py:99(_noop)\n",
      "        1    0.001    0.001    0.004    0.004 parsers.py:1112(_make_engine)\n",
      "        1    0.000    0.000    0.011    0.011 parsers.py:1131(read)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1156(_create_index)\n",
      "        3    0.000    0.000    0.000    0.000 parsers.py:1170(_is_index_col)\n",
      "        3    0.000    0.000    0.000    0.000 parsers.py:1174(_is_potential_multi_index)\n",
      "        6    0.000    0.000    0.000    0.000 parsers.py:1191(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1271(_validate_usecols_arg)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1321(_validate_parse_dates_arg)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1345(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1432(_has_complex_date_col)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1517(_maybe_dedup_names)\n",
      "        2    0.000    0.000    0.000    0.000 parsers.py:1545(_maybe_make_multi_index_columns)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1551(_make_index)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1842(_do_date_conversions)\n",
      "        1    0.003    0.003    0.003    0.003 parsers.py:1864(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1969(close)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:1979(_set_noconvert_columns)\n",
      "        1    0.000    0.000    0.003    0.003 parsers.py:2035(read)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:2108(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:2110(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:3213(_make_date_converter)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:3258(_process_date_conversion)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:3346(_clean_na_values)\n",
      "        2    0.000    0.000    0.000    0.000 parsers.py:367(_validate_integer)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:396(_validate_names)\n",
      "        1    0.000    0.000    0.015    0.015 parsers.py:416(_read)\n",
      "        1    0.000    0.000    0.016    0.016 parsers.py:530(parser_f)\n",
      "        1    0.000    0.000    0.004    0.004 parsers.py:792(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:882(close)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:885(_get_options_with_defaults)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:923(_check_file_or_buffer)\n",
      "        1    0.000    0.000    0.000    0.000 parsers.py:939(_clean_options)\n",
      "    41346    0.050    0.000    0.050    0.000 pool.py:157(__init__)\n",
      "    41346    0.762    0.000   30.828    0.001 pool.py:183(__init__)\n",
      "    41346    0.019    0.000    0.019    0.000 pool.py:263(__del__)\n",
      "    41346    0.065    0.000   16.096    0.000 pool.py:302(_repopulate_pool)\n",
      "    41346    0.808    0.000   16.032    0.000 pool.py:311(_repopulate_pool_static)\n",
      "   413460    0.078    0.000    0.078    0.000 pool.py:348(_check_running)\n",
      "   413460    0.503    0.000    2.671    0.000 pool.py:450(apply_async)\n",
      "    41346    0.116    0.000    4.123    0.000 pool.py:644(close)\n",
      "    41346    0.087    0.000   16.640    0.000 pool.py:651(terminate)\n",
      "    41346    0.526    0.000   16.344    0.000 pool.py:677(_terminate_pool)\n",
      "   413460    0.600    0.000    1.953    0.000 pool.py:744(__init__)\n",
      "  4134600    1.668    0.000    2.233    0.000 pool.py:753(ready)\n",
      "  4134600    1.967    0.000 1192.663    0.000 pool.py:761(wait)\n",
      "  4134600    3.173    0.000 1198.070    0.000 pool.py:764(get)\n",
      "   206730    0.660    0.000    4.539    0.000 pool.py:919(Process)\n",
      "    41346    0.048    0.000   30.876    0.001 pool.py:924(__init__)\n",
      "    41346    0.085    0.000    0.085    0.000 pool.py:927(_setup_queues)\n",
      "    41346    0.020    0.000    0.020    0.000 pool.py:933(_get_sentinels)\n",
      "    41346    0.144    0.000    0.264    0.000 pool.py:940(_help_stuff_finish)\n",
      "        3    0.000    0.000    0.000    0.000 posixpath.py:228(expanduser)\n",
      "    27645    0.023    0.000    0.030    0.000 process.py:198(daemon)\n",
      "    27645    0.007    0.000    0.007    0.000 process.py:37(current_process)\n",
      "   413460    0.643    0.000    1.776    0.000 queue.py:121(put)\n",
      "   537498    0.906    0.000    2.367    0.000 queue.py:153(get)\n",
      "    41346    0.024    0.000    0.024    0.000 queue.py:205(_init)\n",
      "   537498    0.164    0.000    0.239    0.000 queue.py:208(_qsize)\n",
      "   413460    0.143    0.000    0.190    0.000 queue.py:212(_put)\n",
      "   413460    0.140    0.000    0.193    0.000 queue.py:216(_get)\n",
      "    41346    0.138    0.000    0.426    0.000 queue.py:33(__init__)\n",
      "    41346    0.136    0.000    5.631    0.000 queues.py:334(__init__)\n",
      "   124038    0.416    0.000    6.331    0.000 queues.py:360(put)\n",
      "   661536    0.404    0.000    0.592    0.000 random.py:250(_randbelow_with_getrandbits)\n",
      "   661536    0.321    0.000    0.973    0.000 random.py:285(choice)\n",
      "    13702    0.029    0.000    0.142    0.000 random.py:721(getrandbits)\n",
      "        6    0.000    0.000    0.000    0.000 range.py:131(_simple_new)\n",
      "        7    0.000    0.000    0.000    0.000 range.py:155(_data)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:170(_int64index)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:210(start)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:233(stop)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:256(step)\n",
      "        3    0.000    0.000    0.000    0.000 range.py:316(dtype)\n",
      "        3    0.000    0.000    0.000    0.000 range.py:387(_shallow_copy)\n",
      "        4    0.000    0.000    0.000    0.000 range.py:444(equals)\n",
      "      102    0.000    0.000    0.000    0.000 range.py:675(__len__)\n",
      "        6    0.001    0.000    0.001    0.000 range.py:83(__new__)\n",
      "   124038    0.411    0.000    1.231    0.000 reduction.py:38(__init__)\n",
      "   124038    0.541    0.000    2.034    0.000 reduction.py:48(dumps)\n",
      "   165384    0.120    0.000    0.544    0.000 resource_tracker.py:134(_check_alive)\n",
      "    82692    0.055    0.000    0.865    0.000 resource_tracker.py:145(register)\n",
      "    82692    0.059    0.000    0.875    0.000 resource_tracker.py:149(unregister)\n",
      "   165384    0.376    0.000    1.626    0.000 resource_tracker.py:153(_send)\n",
      "   165384    0.225    0.000    0.768    0.000 resource_tracker.py:70(ensure_running)\n",
      "      9/8    0.000    0.000    0.004    0.001 series.py:183(__init__)\n",
      "        1    0.000    0.000    0.002    0.002 series.py:313(_init_dict)\n",
      "        6    0.000    0.000    0.000    0.000 series.py:359(_constructor)\n",
      "        9    0.000    0.000    0.000    0.000 series.py:376(_set_axis)\n",
      "        1    0.000    0.000    0.001    0.001 series.py:3857(_reduce)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:4027(reindex)\n",
      "        9    0.000    0.000    0.000    0.000 series.py:403(_set_subtyp)\n",
      "       20    0.000    0.000    0.000    0.000 series.py:414(dtype)\n",
      "       30    0.000    0.000    0.000    0.000 series.py:428(name)\n",
      "       20    0.000    0.000    0.000    0.000 series.py:432(name)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:438(values)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:4400(isna)\n",
      "        4    0.000    0.000    0.000    0.000 series.py:480(_values)\n",
      "        9    0.000    0.000    0.000    0.000 series.py:515(array)\n",
      "        3    0.000    0.000    0.000    0.000 series.py:707(__array__)\n",
      "        2    0.000    0.000    0.000    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n",
      "    13701    0.002    0.000    0.002    0.000 shape_base.py:21(_atleast_1d_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 shape_base.py:220(_vhstack_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 shape_base.py:224(vstack)\n",
      "    13701    0.022    0.000    0.034    0.000 shape_base.py:25(atleast_1d)\n",
      "        2    0.000    0.000    0.000    0.000 shape_base.py:79(_atleast_2d_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 shape_base.py:83(atleast_2d)\n",
      "       42    0.001    0.000    0.001    0.000 socket.py:342(send)\n",
      "        2    0.000    0.000    0.000    0.000 statistics.py:123(_sum)\n",
      "        6    0.000    0.000    0.000    0.000 statistics.py:177(<genexpr>)\n",
      "        4    0.000    0.000    0.000    0.000 statistics.py:188(_coerce)\n",
      "        4    0.000    0.000    0.000    0.000 statistics.py:219(_exact_ratio)\n",
      "        2    0.000    0.000    0.000    0.000 statistics.py:251(_convert)\n",
      "        2    0.000    0.000    0.000    0.000 statistics.py:295(mean)\n",
      "        1    0.002    0.002    0.010    0.010 stats.py:3376(pearsonr)\n",
      "    82692    0.085    0.000    4.689    0.000 synchronize.py:161(__init__)\n",
      "    82692    1.212    0.000    4.604    0.000 synchronize.py:50(__init__)\n",
      "    82692    0.368    0.000    1.555    0.000 synchronize.py:84(_cleanup)\n",
      "    82692    0.042    0.000    0.042    0.000 synchronize.py:90(_make_methods)\n",
      "   124038    0.106    0.000    2.182    0.000 synchronize.py:94(__enter__)\n",
      "   124038    0.068    0.000    0.248    0.000 synchronize.py:97(__exit__)\n",
      "    82692    0.074    0.000    0.102    0.000 tempfile.py:133(rng)\n",
      "    82692    0.166    0.000    1.449    0.000 tempfile.py:144(__next__)\n",
      "    82692    0.172    0.000    1.145    0.000 tempfile.py:147(<listcomp>)\n",
      "   165426    0.372    0.000   12.560    0.000 threading.py:1017(_wait_for_tstate_lock)\n",
      "   206730    0.049    0.000    0.049    0.000 threading.py:1031(name)\n",
      "   206730    0.094    0.000    0.094    0.000 threading.py:1042(name)\n",
      "    41388    0.063    0.000    0.126    0.000 threading.py:1071(is_alive)\n",
      "   454806    0.128    0.000    0.128    0.000 threading.py:1095(daemon)\n",
      "   330768    0.176    0.000    0.225    0.000 threading.py:1110(daemon)\n",
      "   330768    0.211    0.000    0.211    0.000 threading.py:1177(_make_invoke_excepthook)\n",
      "  1019949    0.461    0.000    0.611    0.000 threading.py:1306(current_thread)\n",
      "   868266    2.041    0.000    2.041    0.000 threading.py:222(__init__)\n",
      "  5416326    1.823    0.000    3.070    0.000 threading.py:246(__enter__)\n",
      "  5416326    1.883    0.000    2.536    0.000 threading.py:249(__exit__)\n",
      "  1569143    0.584    0.000    0.835    0.000 threading.py:255(_release_save)\n",
      "  1569143    0.947    0.000    1.581    0.000 threading.py:258(_acquire_restore)\n",
      "  2396063    0.879    0.000    1.634    0.000 threading.py:261(_is_owned)\n",
      "  1569143    5.840    0.000 1191.734    0.001 threading.py:270(wait)\n",
      "   826920    0.622    0.000    1.075    0.000 threading.py:341(notify)\n",
      "   744228    0.593    0.000    2.640    0.000 threading.py:505(__init__)\n",
      "  4961562    0.682    0.000    0.682    0.000 threading.py:513(is_set)\n",
      "  4465368    5.376    0.000 1201.818    0.000 threading.py:540(wait)\n",
      "   330768    0.306    0.000    0.306    0.000 threading.py:734(_newname)\n",
      "   330768    1.543    0.000    4.112    0.000 threading.py:761(__init__)\n",
      "    41346    0.035    0.000    0.035    0.000 threading.py:81(RLock)\n",
      "   330768    0.716    0.000   15.845    0.000 threading.py:834(start)\n",
      "   124038    0.208    0.000    0.270    0.000 threading.py:944(_stop)\n",
      "   124038    0.256    0.000   12.837    0.000 threading.py:979(join)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:526(get)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:545(__get__)\n",
      "    82692    0.099    0.000    0.436    0.000 util.py:171(register_after_fork)\n",
      "   124038    0.307    0.000    0.378    0.000 util.py:186(__init__)\n",
      "   124038    0.399    0.000   18.360    0.000 util.py:205(__call__)\n",
      "   124038    0.028    0.000    0.028    0.000 util.py:44(sub_debug)\n",
      "   578844    0.115    0.000    0.115    0.000 util.py:48(debug)\n",
      "    41346    0.195    0.000    0.246    0.000 uuid.py:130(__init__)\n",
      "    41346    0.049    0.000    0.049    0.000 uuid.py:325(hex)\n",
      "    41346    0.100    0.000    0.679    0.000 uuid.py:778(uuid4)\n",
      "    55621    0.265    0.000    0.554    0.000 validation.py:1016(<listcomp>)\n",
      "      330    0.001    0.000    0.021    0.000 validation.py:1255(_check_sample_weight)\n",
      "   114750    0.342    0.000    0.743    0.000 validation.py:181(_num_samples)\n",
      "    14693    0.037    0.000    0.509    0.000 validation.py:242(check_consistent_length)\n",
      "    14693    0.017    0.000    0.135    0.000 validation.py:253(<listcomp>)\n",
      "      180    0.000    0.000    0.000    0.000 validation.py:260(_make_indexable)\n",
      "       60    0.000    0.000    0.002    0.000 validation.py:280(indexable)\n",
      "       60    0.000    0.000    0.000    0.000 validation.py:292(<listcomp>)\n",
      "    56640    0.049    0.000    0.067    0.000 validation.py:391(_ensure_no_complex_data)\n",
      "    56640    0.558    0.000    3.696    0.000 validation.py:398(check_array)\n",
      "22350998/1482751   39.452    0.000  349.627    0.000 validation.py:60(inner_f)\n",
      "    14031    0.055    0.000    2.237    0.000 validation.py:689(check_X_y)\n",
      " 22350998    5.271    0.000    5.271    0.000 validation.py:72(<dictcomp>)\n",
      "    56970    0.483    0.000    1.825    0.000 validation.py:77(_assert_all_finite)\n",
      "      330    0.001    0.000    0.004    0.000 validation.py:818(column_or_1d)\n",
      "  1397832    2.429    0.000    5.787    0.000 validation.py:851(check_random_state)\n",
      "    55621    0.090    0.000    0.713    0.000 validation.py:956(check_is_fitted)\n",
      "    82692    0.068    0.000    0.564    0.000 version.py:302(__init__)\n",
      "    82692    0.230    0.000    0.496    0.000 version.py:307(parse)\n",
      "    82692    0.060    0.000    0.060    0.000 version.py:312(<listcomp>)\n",
      "    41346    0.055    0.000    0.244    0.000 version.py:331(_cmp)\n",
      "    41346    0.046    0.000    0.291    0.000 version.py:57(__le__)\n",
      "    56640    0.072    0.000    0.273    0.000 warnings.py:165(simplefilter)\n",
      "    56640    0.109    0.000    0.196    0.000 warnings.py:181(_add_filter)\n",
      "    56640    0.065    0.000    0.065    0.000 warnings.py:437(__init__)\n",
      "    56640    0.104    0.000    0.113    0.000 warnings.py:458(__enter__)\n",
      "    56640    0.062    0.000    0.068    0.000 warnings.py:477(__exit__)\n",
      "    82692    0.082    0.000    0.119    0.000 weakref.py:103(remove)\n",
      "    82692    0.145    0.000    0.303    0.000 weakref.py:159(__setitem__)\n",
      "    82692    0.058    0.000    0.096    0.000 weakref.py:323(__new__)\n",
      "    82692    0.062    0.000    0.062    0.000 weakref.py:328(__init__)\n",
      "   206730    0.230    0.000    0.230    0.000 weakref.py:343(__init__)\n",
      "   202542    0.111    0.000    0.111    0.000 weakref.py:345(remove)\n",
      "   206730    0.119    0.000    0.119    0.000 weakref.py:395(__setitem__)\n",
      "    82747    0.038    0.000    0.038    0.000 {built-in method __new__ of type object at 0x10e66f808}\n",
      "  1581762    0.820    0.000    0.932    0.000 {built-in method _abc._abc_instancecheck}\n",
      "   142512    0.068    0.000    0.068    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "    82692    0.220    0.000    0.220    0.000 {built-in method _multiprocessing.sem_unlink}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _operator.and_}\n",
      "   124038    0.058    0.000    0.058    0.000 {built-in method _struct.pack}\n",
      "  2382362    1.000    0.000    1.000    0.000 {built-in method _thread.allocate_lock}\n",
      "  1019949    0.150    0.000    0.150    0.000 {built-in method _thread.get_ident}\n",
      "   330768    3.970    0.000    3.970    0.000 {built-in method _thread.start_new_thread}\n",
      "   169920    0.022    0.000    0.022    0.000 {built-in method _warnings._filters_mutated}\n",
      "    82692    0.037    0.000    0.037    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "      665    0.001    0.000    0.001    0.000 {built-in method builtins.abs}\n",
      "    55/54    0.000    0.000    0.001    0.000 {built-in method builtins.all}\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "  6905321    0.874    0.000    0.874    0.000 {built-in method builtins.callable}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.compile}\n",
      "    41346    0.895    0.000    0.912    0.000 {built-in method builtins.eval}\n",
      "        2    0.000    0.000 2062.681 1031.340 {built-in method builtins.exec}\n",
      "126855247   12.924    0.000   12.924    0.000 {built-in method builtins.getattr}\n",
      " 95526385    9.617    0.000    9.618    0.000 {built-in method builtins.hasattr}\n",
      "       91    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      " 31951226    3.634    0.000    3.634    0.000 {built-in method builtins.id}\n",
      "130354189   11.872    0.000   13.359    0.000 {built-in method builtins.isinstance}\n",
      "   217392    0.054    0.000    0.054    0.000 {built-in method builtins.issubclass}\n",
      "    41349    0.007    0.000    0.007    0.000 {built-in method builtins.iter}\n",
      "61095993/61095706    6.577    0.000    6.727    0.000 {built-in method builtins.len}\n",
      "   124051    0.065    0.000    0.065    0.000 {built-in method builtins.max}\n",
      "    27652    0.017    0.000    0.017    0.000 {built-in method builtins.min}\n",
      "   785595    0.239    0.000    1.704    0.000 {built-in method builtins.next}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       12    0.000    0.000    0.002    0.000 {built-in method builtins.print}\n",
      " 18522201    2.400    0.000    2.400    0.000 {built-in method builtins.setattr}\n",
      "  8289116    7.280    0.000    7.280    0.000 {built-in method builtins.sorted}\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method builtins.sum}\n",
      "    55621    0.018    0.000    0.018    0.000 {built-in method builtins.vars}\n",
      "    55048    0.028    0.000    0.028    0.000 {built-in method from_bytes}\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method math.gcd}\n",
      "        1    0.003    0.003    0.003    0.003 {built-in method math.sqrt}\n",
      "    14470    0.044    0.000    0.044    0.000 {built-in method numpy.arange}\n",
      "160310/160304    0.278    0.000    0.279    0.000 {built-in method numpy.array}\n",
      "201541/200530    0.261    0.000    1.889    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "    42813    0.082    0.000    0.082    0.000 {built-in method numpy.empty}\n",
      "    56152    0.014    0.000    0.014    0.000 {built-in method numpy.geterrobj}\n",
      "    28076    0.021    0.000    0.021    0.000 {built-in method numpy.seterrobj}\n",
      "    28277    0.061    0.000    0.061    0.000 {built-in method numpy.zeros}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.lib.is_datetime_array}\n",
      "       41    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.checknull}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
      "    82692    0.293    0.000    0.293    0.000 {built-in method posix.close}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "   413500    0.084    0.000    0.084    0.000 {built-in method posix.getpid}\n",
      "    41346    0.284    0.000    0.284    0.000 {built-in method posix.pipe}\n",
      "    55048    0.440    0.000    0.440    0.000 {built-in method posix.urandom}\n",
      "   454806    1.299    0.000    1.299    0.000 {built-in method posix.write}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method sys.getfilesystemencoding}\n",
      "  6905304    1.023    0.000    1.023    0.000 {built-in method sys.getrecursionlimit}\n",
      "   496152    0.114    0.000    0.114    0.000 {built-in method time.time}\n",
      "    13702    0.908    0.000    0.908    0.000 {function SeedSequence.generate_state at 0x7fcc703260d0}\n",
      "   124038    2.076    0.000    2.076    0.000 {method '__enter__' of '_multiprocessing.SemLock' objects}\n",
      "  5416326    1.247    0.000    1.247    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "   124038    0.180    0.000    0.180    0.000 {method '__exit__' of '_multiprocessing.SemLock' objects}\n",
      "  5416326    0.653    0.000    0.653    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "  7268913 1194.619    0.000 1194.619    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "   330786    0.082    0.000    0.082    0.000 {method 'add' of 'set' objects}\n",
      "       26    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "       66    0.000    0.000    0.000    0.000 {method 'any' of 'numpy.ndarray' objects}\n",
      "  1982645    0.280    0.000    0.280    0.000 {method 'append' of 'collections.deque' objects}\n",
      " 97182854    8.951    0.000    8.951    0.000 {method 'append' of 'list' objects}\n",
      "      331    0.001    0.000    0.001    0.000 {method 'argmax' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'argmin' of 'numpy.ndarray' objects}\n",
      "      333    0.014    0.000    0.014    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'as_integer_ratio' of 'float' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'as_integer_ratio' of 'numpy.float64' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "   661536    0.063    0.000    0.063    0.000 {method 'bit_length' of 'int' objects}\n",
      "    13701    0.820    0.000    1.092    0.000 {method 'choice' of 'numpy.random.mtrand.RandomState' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'close' of 'pandas._libs.parsers.TextReader' objects}\n",
      "   181020    0.752    0.000    0.752    0.000 {method 'copy' of 'dict' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "    41346    0.017    0.000    0.017    0.000 {method 'count' of 'list' objects}\n",
      "    27976    0.100    0.000    0.100    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "   326580    0.057    0.000    0.057    0.000 {method 'discard' of 'set' objects}\n",
      "   124038    0.225    0.000    0.225    0.000 {method 'dump' of '_pickle.Pickler' objects}\n",
      "   165385    0.057    0.000    0.057    0.000 {method 'encode' of 'str' objects}\n",
      " 18115302    3.590    0.000    3.590    0.000 {method 'endswith' of 'str' objects}\n",
      "  4148304    0.741    0.000    0.741    0.000 {method 'extend' of 'list' objects}\n",
      "       42    0.000    0.000    0.000    0.000 {method 'fill' of 'numpy.ndarray' objects}\n",
      "    14693    0.018    0.000    0.018    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "   165560    0.162    0.000    0.162    0.000 {method 'format' of 'str' objects}\n",
      "    41413    0.029    0.000    0.029    0.000 {method 'get' of '_queue.SimpleQueue' objects}\n",
      "230026879   19.423    0.000   19.423    0.000 {method 'get' of 'dict' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'get_indexer' of 'pandas._libs.index.IndexEngine' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
      "   124038    0.038    0.000    0.038    0.000 {method 'getbuffer' of '_io.BytesIO' objects}\n",
      "  1143536    0.125    0.000    0.125    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "   470100    0.080    0.000    0.080    0.000 {method 'insert' of 'list' objects}\n",
      " 96948276   10.294    0.000   10.294    0.000 {method 'isidentifier' of 'str' objects}\n",
      "  6978198    0.814    0.000    0.814    0.000 {method 'items' of 'dict' objects}\n",
      "    82692    0.036    0.000    0.036    0.000 {method 'join' of 'str' objects}\n",
      "    27409    0.005    0.000    0.005    0.000 {method 'keys' of 'dict' objects}\n",
      "   124038    0.020    0.000    0.020    0.000 {method 'locked' of '_thread.lock' objects}\n",
      "    13731    0.023    0.000    0.143    0.000 {method 'max' of 'numpy.ndarray' objects}\n",
      "      664    0.001    0.000    0.009    0.000 {method 'mean' of 'numpy.ndarray' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      " 16454901    2.020    0.000    2.020    0.000 {method 'partition' of 'str' objects}\n",
      "      431    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "  4134728    0.892    0.000    0.892    0.000 {method 'pop' of 'list' objects}\n",
      "   413460    0.053    0.000    0.053    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "   661536    0.291    0.000    0.291    0.000 {method 'put' of '_queue.SimpleQueue' objects}\n",
      "  1383801    9.145    0.000    9.145    0.000 {method 'randint' of 'numpy.random.mtrand.RandomState' objects}\n",
      "      351    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "        1    0.001    0.001    0.003    0.003 {method 'read' of 'pandas._libs.parsers.TextReader' objects}\n",
      "   115146    0.762    0.000    0.762    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "  1693181    0.288    0.000    0.288    0.000 {method 'release' of '_thread.lock' objects}\n",
      "    56640    0.064    0.000    0.064    0.000 {method 'remove' of 'list' objects}\n",
      "   206730    0.056    0.000    0.056    0.000 {method 'replace' of 'str' objects}\n",
      "    14303    0.024    0.000    0.024    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "   553122    0.160    0.000    0.160    0.000 {method 'rpartition' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "    14693    0.029    0.000    0.029    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
      "    82692    0.206    0.000    0.206    0.000 {method 'split' of 're.Pattern' objects}\n",
      "   319464    0.071    0.000    0.071    0.000 {method 'startswith' of 'str' objects}\n",
      "    14125    0.016    0.000    0.079    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "      337    0.001    0.000    0.001    0.000 {method 'take' of 'numpy.ndarray' objects}\n",
      "    55290    0.022    0.000    0.022    0.000 {method 'tolist' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      " 22888523    4.927    0.000    4.927    0.000 {method 'update' of 'dict' objects}\n",
      "       19    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "       18    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "  6905304    1.761    0.000    1.761    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "      120    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "       60    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_int64}\n",
      "       14    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
      "       29    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_platform_int}\n",
      "       20    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_1d_int64_int64}\n",
      "       14    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis0_float64_float64}\n",
      "       13    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis0_int64_int64}\n",
      "        3    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis1_float64_float64}\n",
      "        3    0.000    0.000    0.000    0.000 {pandas._libs.algos.take_2d_axis1_int64_int64}\n",
      "       12    0.000    0.000    0.000    0.000 {pandas._libs.internals.get_blkno_placements}\n",
      "        6    0.000    0.000    0.000    0.000 {pandas._libs.lib.array_equivalent_object}\n",
      "        5    0.000    0.000    0.000    0.000 {pandas._libs.lib.clean_index_list}\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
      "       41    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_dtype}\n",
      "       35    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
      "       46    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
      "       49    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
      "       41    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
      "      122    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
      "       20    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "       59    0.000    0.000    0.000    0.000 {pandas._libs.lib.values_from_object}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x7fcca0ed4cd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.strip_dirs().sort_stats(-1).print_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f0423d9f2417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdask\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dask' is not defined"
     ]
    }
   ],
   "source": [
    "dask-scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
