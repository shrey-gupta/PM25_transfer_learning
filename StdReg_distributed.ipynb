{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories uploaded!!\n",
      "Second Upload Completed!!\n"
     ]
    }
   ],
   "source": [
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2 ##STrAdaBoost.R2\n",
    "# from TwoStageTrAdaBoostR2 import TwoStageTrAdaBoostR2 ##two-stage TrAdaBoost.R2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, Dropout, Flatten\n",
    "from keras import optimizers, utils, initializers, regularizers\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler #Importing the StandardScaler\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "\n",
    "#Geo plotting libraries\n",
    "import geopandas as gdp\n",
    "from matplotlib.colors import ListedColormap\n",
    "# import geoplot as glpt\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "import statistics\n",
    "\n",
    "from scipy.stats import rv_continuous\n",
    "from scipy.stats import *\n",
    "\n",
    "from statistics import mean\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "######### Instance Transfer repositories ####################\n",
    "from adapt.instance_based import TwoStageTrAdaBoostR2\n",
    "\n",
    "print(\"Repositories uploaded!!\")\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "print(\"Second Upload Completed!!\")\n",
    "\n",
    "######### Importing required Libraries for Plotting the Map #########\n",
    "\n",
    "import geopandas as gpd\n",
    "import json\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 60749 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Input data is:  (392, 8)\n",
      "Target Set:  (119, 7)\n",
      "Source Set:  (157, 7)\n",
      "Test Set:  (116, 7)\n",
      "---------------------------\n",
      "Inside STrAdaBoost.R2\n",
      "RMSE of STrAdaboostR2: 6.828245498594654\n",
      "R^2 of STrAdaboostR2: 0.5113371898216029\n",
      "\n",
      "\n",
      "RMSE of STrAdaboostR2: [6.828245498594654]\n",
      "R^2 of STrAdaboostR2: [0.5113371898216029]\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################################################## Automobile ################################################################\n",
    "## horsepower column has correlation 0.4 :: [46 - 230] :: 30\n",
    "#################################################################################################################################\n",
    "\n",
    "dropcol_initial_auto = ['name']\n",
    "AutoData_df = pd.read_csv('UCI_regression/MPG/Auto.csv') ## horsepower column has correlation 0.4 :: [46 - 230] :: 30\n",
    "AutoData_df = AutoData_df.drop(dropcol_initial_auto, axis = 1)\n",
    "print(\"The shape of the Input data is: \", AutoData_df.shape)\n",
    "\n",
    "drop_col_auto = ['horsepower']\n",
    "\n",
    "auto_tgt_df = AutoData_df.loc[(AutoData_df['horsepower'] <= 80)]\n",
    "auto_tgt_df = auto_tgt_df.drop(drop_col_auto, axis = 1)\n",
    "auto_tgt_df = auto_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",auto_tgt_df.shape)\n",
    "\n",
    "auto_source_df = AutoData_df.loc[(AutoData_df['horsepower'] > 80) & (AutoData_df['horsepower'] <= 110)]\n",
    "auto_source_df = auto_source_df.drop(drop_col_auto, axis = 1)\n",
    "auto_source_df = auto_source_df.reset_index(drop=True)\n",
    "print(\"Source Set: \",auto_source_df.shape)\n",
    "\n",
    "auto_test_df = AutoData_df.loc[(AutoData_df['horsepower'] > 110)]\n",
    "auto_test_df = auto_test_df.drop(drop_col_auto, axis = 1)\n",
    "auto_test_df = auto_test_df.reset_index(drop=True)\n",
    "print(\"Test Set: \",auto_test_df.shape)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_column_auto = ['mpg']\n",
    "\n",
    "auto_tgt_df_y = auto_tgt_df[target_column_auto]\n",
    "auto_tgt_df_X = auto_tgt_df.drop(target_column_auto, axis = 1)\n",
    "\n",
    "auto_source_df_y = auto_source_df[target_column_auto]\n",
    "auto_source_df_X = auto_source_df.drop(target_column_auto, axis = 1)\n",
    "\n",
    "auto_test_df_y = auto_test_df[target_column_auto]\n",
    "auto_test_df_X = auto_test_df.drop(target_column_auto, axis = 1)\n",
    "\n",
    "############## Merging the datasets ##########################################\n",
    "auto_X_df = pd.concat([auto_tgt_df_X, auto_source_df_X], ignore_index=True)\n",
    "auto_y_df = pd.concat([auto_tgt_df_y, auto_source_df_y], ignore_index=True)\n",
    "\n",
    "auto_np_train_X = auto_X_df.to_numpy()\n",
    "auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "\n",
    "src_size_auto = len(auto_source_df_y)\n",
    "tgt_size_auto = len(auto_tgt_df_y)\n",
    "\n",
    "print(\"---------------------------\")\n",
    "\n",
    "\n",
    "#################################### STrAdaBoost.R2 Auto ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "sample_size = [len(auto_tgt_df_X), len(auto_source_df_X)]\n",
    "n_estimators = 50\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "r2scorelist_stradaboost_auto = []\n",
    "rmselist_stradaboost_auto = []\n",
    "\n",
    "for x in range(0, 1):\n",
    "\n",
    "    model_stradaboost_auto = TwoStageTrAdaBoostR2(RandomForestRegressor(max_depth = 4, n_jobs = 5),\n",
    "                        n_estimators = n_estimators, sample_size = sample_size,\n",
    "                        steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "    with joblib.parallel_backend('dask'):\n",
    "        model_stradaboost_auto.fit(auto_np_train_X, auto_np_train_y_list)\n",
    "        y_pred_stradaboost_auto = model_stradaboost_auto.predict(auto_np_test_X)\n",
    "\n",
    "\n",
    "    mse_stradaboost_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_stradaboost_auto))\n",
    "    rmselist_stradaboost_auto.append(mse_stradaboost_auto)\n",
    "\n",
    "    r2_score_stradaboost_auto = pearsonr(auto_np_test_y_list, y_pred_stradaboost_auto)\n",
    "    r2_score_stradaboost_auto = (r2_score_stradaboost_auto[0])**2\n",
    "    r2scorelist_stradaboost_auto.append(r2_score_stradaboost_auto)\n",
    "\n",
    "\n",
    "print(\"RMSE of STrAdaboostR2:\", statistics.mean(rmselist_stradaboost_auto))\n",
    "print(\"R^2 of STrAdaboostR2:\", statistics.mean(r2scorelist_stradaboost_auto))\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of STrAdaboostR2:\", rmselist_stradaboost_auto)\n",
    "print(\"R^2 of STrAdaboostR2:\", r2scorelist_stradaboost_auto)\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### Gradient Boosting Regression Elevators #######################################\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBR_elevators = []\n",
    "rmselist_GBR_elevators = []\n",
    "\n",
    "for x in range(0, 10):\n",
    "\n",
    "    model_GBR_elevators = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100)\n",
    "    model_GBR_elevators.fit(Elevators_tgt_df_X, Elevators_tgt_df_y)\n",
    "\n",
    "    y_pred_GBR_elevators = model_GBR_elevators.predict(elevators_np_test_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBR_elevators = sqrt(mean_squared_error(elevators_np_test_y, y_pred_GBR_elevators))\n",
    "    rmselist_GBR_elevators.append(mse_GBR_elevators)\n",
    "        \n",
    "    r2_score_GBR_elevators = pearsonr(elevators_np_test_y_list, y_pred_GBR_elevators)\n",
    "    r2_score_GBR_elevators = (r2_score_GBR_elevators[0])**2\n",
    "    r2scorelist_GBR_elevators.append(r2_score_GBR_elevators)\n",
    "\n",
    "\n",
    "print(\"RMSE of GBR:\", statistics.mean(rmselist_GBR_elevators))\n",
    "print(\"R^2 of GBR:\", statistics.mean(r2scorelist_GBR_elevators))\n",
    "print(\"\\n\")\n",
    "print(\"RMSE of GBR:\", rmselist_GBR_elevators)\n",
    "print(\"R^2 of GBR:\", r2scorelist_GBR_elevators)\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
