{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repositories uploaded!!\n"
     ]
    }
   ],
   "source": [
    "# from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2 ##STrAdaBoost.R2\n",
    "# from TwoStageTrAdaBoostR2 import TwoStageTrAdaBoostR2 ##two-stage TrAdaBoost.R2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats.stats import pearsonr\n",
    "from math import sqrt\n",
    "import statistics \n",
    "from scipy.stats import *\n",
    "from scipy.spatial import distance\n",
    "\n",
    "######### Instance Transfer repositories ####################\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "print(\"Repositories uploaded!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concrete Data\n",
      "-------------------------------------------\n",
      "(1030, 9)\n",
      "Target :  (368, 8)\n",
      "Source 1:  (406, 8)\n",
      "Source 2:  (256, 8)\n"
     ]
    }
   ],
   "source": [
    "################################### Concrete ###########################################################################################################\n",
    "ConcreteData_df = pd.read_excel('UCI_regression/Concrete/Concrete_Data.xls') ## 'Cement' found to be correlated at 0.4 :: 100\n",
    "print(\"Concrete Data\")\n",
    "print(\"-------------------------------------------\")\n",
    "print(ConcreteData_df.shape)\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# concrete_cols = ConcreteData_df.columns\n",
    "# ss = StandardScaler()\n",
    "# ConcreteData_df[concrete_cols] = ss.fit_transform(ConcreteData_df[concrete_cols])\n",
    "# print(ConcreteData_df)\n",
    "\n",
    "\n",
    "drop_col_concrete = ['Cement']\n",
    "\n",
    "concrete_tgt_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] <= 225)]\n",
    "concrete_tgt_df = concrete_tgt_df.drop(drop_col_concrete, axis = 1)\n",
    "concrete_tgt_df = concrete_tgt_df.reset_index(drop=True)\n",
    "print(\"Target : \",concrete_tgt_df.shape)\n",
    "\n",
    "concrete_source1_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] > 225) & (ConcreteData_df['Cement'] <= 350)]\n",
    "concrete_source1_df = concrete_source1_df.drop(drop_col_concrete, axis = 1)\n",
    "concrete_source1_df = concrete_source1_df.reset_index(drop=True)\n",
    "print(\"Source 1: \",concrete_source1_df.shape)\n",
    "\n",
    "concrete_source2_df = ConcreteData_df.loc[(ConcreteData_df['Cement'] > 350)]\n",
    "concrete_source2_df = concrete_source2_df.drop(drop_col_concrete, axis = 1)\n",
    "concrete_source2_df = concrete_source2_df.reset_index(drop=True)\n",
    "print(\"Source 2: \",concrete_source2_df.shape)\n",
    "\n",
    "################################# Standardization ############################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "concrete_cols = concrete_tgt_df.columns.difference(['ConcreteCompressiveStrength'])\n",
    "\n",
    "ss = StandardScaler()\n",
    "concrete_tgt_df[concrete_cols] = ss.fit_transform(concrete_tgt_df[concrete_cols])\n",
    "concrete_source1_df[concrete_cols] = ss.fit_transform(concrete_source1_df[concrete_cols])\n",
    "concrete_source2_df[concrete_cols] = ss.fit_transform(concrete_source2_df[concrete_cols])\n",
    "\n",
    "\n",
    "############################ Concatenating the source datasets ############################\n",
    "concrete_source_df = pd.concat([concrete_source1_df, concrete_source2_df], ignore_index = True)\n",
    "concrete_source_df = concrete_source_df.reset_index(drop = True)\n",
    "\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_concrete = ['ConcreteCompressiveStrength']\n",
    "\n",
    "concrete_source_df_y = concrete_source_df[target_concrete]\n",
    "concrete_source_df_X = concrete_source_df.drop(target_concrete, axis = 1)\n",
    "\n",
    "features_concrete = concrete_source_df_X.columns\n",
    "################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specification for TrAdaboost.R2 requirement complete!\n",
      "Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "Binary search has not converged. Set value to the current best.\n",
      "RMSE List of Two-Stage TrAdaboost.R2: [5.809211408696263, 7.789066720392749, 8.957489047138598, 8.263744616657963, 8.760590871962252, 6.889771112642312, 6.085981882299316, 5.799087003967696, 5.602282791650463, 5.631358842544836]\n",
      "R^2 List of TrAdaboostR2: [0.8120508206082601, 0.6500653970810222, 0.7118824741791502, 0.6601635119289769, 0.7906092117479931, 0.6802344210649145, 0.797685700198735, 0.7235199217672004, 0.5507047981805997, 0.6609043092340013]\n",
      "Mean, STDev of RMSE: 6.958858429795245 1.360912074806487\n",
      "Mean, STDev of R^2: 0.7037820565990853 0.0810677842927172\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Concrete #######################################\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "print(\"Specification for TrAdaboost.R2 requirement complete!\")\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_TwoTrAda_concrete = []\n",
    "rmselist_TwoTrAda_concrete = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(concrete_tgt_df):\n",
    "        \n",
    "    concrete_train_df_X = concrete_tgt_df.iloc[train_idx].loc[:, features_concrete]\n",
    "    concrete_test_df_X = concrete_tgt_df.iloc[test_idx][features_concrete]\n",
    "    concrete_train_df_y = concrete_tgt_df.iloc[train_idx].loc[:,target_concrete]\n",
    "    concrete_test_df_y = concrete_tgt_df.loc[test_idx][target_concrete]\n",
    "        \n",
    "    concrete_X_df = pd.concat([concrete_source_df_X, concrete_train_df_X], ignore_index=True)\n",
    "    concrete_y_df = pd.concat([concrete_source_df_y, concrete_train_df_y], ignore_index=True)\n",
    "\n",
    "    concrete_np_train_X = concrete_X_df.to_numpy()\n",
    "    concrete_np_train_y = concrete_y_df.to_numpy()\n",
    "\n",
    "    concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "    concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "    concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "\n",
    "    src_size_concrete = len(concrete_source_df_y)\n",
    "    tgt_size_concrete = len(concrete_train_df_y)\n",
    "    \n",
    "    src_idx = np.arange(start = 0, stop = (src_size_concrete - 1), step=1)\n",
    "    tgt_idx = np.arange(start = src_size_concrete, stop = ((src_size_concrete + tgt_size_concrete)-1), step=1)\n",
    "\n",
    "\n",
    "    model_TwoTrAda_concrete = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100) #, cv = 10) \n",
    "    model_TwoTrAda_concrete.fit(concrete_np_train_X, concrete_np_train_y_list, src_idx, tgt_idx)\n",
    "\n",
    "    y_pred_TwoTrAda_concrete = model_TwoTrAda_concrete.predict(concrete_np_test_X)\n",
    "    \n",
    "    mse_TwoTrAda_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_TwoTrAda_concrete))\n",
    "    rmselist_TwoTrAda_concrete.append(mse_TwoTrAda_concrete)\n",
    "        \n",
    "    r2_score_TwoTrAda_concrete = pearsonr(concrete_np_test_y_list, y_pred_TwoTrAda_concrete)\n",
    "    r2_score_TwoTrAda_concrete = (r2_score_TwoTrAda_concrete[0])**2\n",
    "    r2scorelist_TwoTrAda_concrete.append(r2_score_TwoTrAda_concrete)\n",
    "\n",
    "\n",
    "print(\"RMSE List of Two-Stage TrAdaboost.R2:\", rmselist_TwoTrAda_concrete)\n",
    "print(\"R^2 List of TrAdaboostR2:\", r2scorelist_TwoTrAda_concrete)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_TwoTrAda_concrete), statistics.stdev(rmselist_TwoTrAda_concrete))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_TwoTrAda_concrete), statistics.stdev(r2scorelist_TwoTrAda_concrete))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STrAdaboost.R2\n",
      "-------------------------------------------\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "First revision introduced!\n",
      "RMSE List of STrAdaboost.R2: [4.444579434770904, 3.742944174953133, 10.910652691192638, 5.104878938921855, 7.483584223122021, 8.485051614462312, 6.74056824566643, 6.0610626479377485, 4.2488291860626894, 5.502053261306182, 8.140069965812248, 3.5312307622053734, 4.545352899326206, 4.67204759169676, 4.6230827419990534, 4.920592138037679, 4.773515369055116, 7.629051953773225, 3.998902482391223, 4.891236470571407]\n",
      "R^2 List of STrAdaboost.R2: [0.9619482026114131, 0.8871922818944356, 0.4210230427963537, 0.8384053000992543, 0.770974724304041, 0.9233633778134436, 0.6474204402688912, 0.2972974002535621, 0.7532234505050701, 0.9095346934660254, 0.6783796529107642, 0.9341745831885185, 0.9005498627502386, 0.9090902756178918, 0.8376571182677445, 0.8397538008165117, 0.792399710012982, 0.5083387784449455, 0.9172890027991168, 0.8013624003448732]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 5.72246433966321 1.921336028927374\n",
      "Mean, STDev of R^2: 0.7764689049583039 0.182205434923663\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Active Sampling Concrete ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 20\n",
    "\n",
    "r2scorelist_stradaboost_concrete = []\n",
    "rmselist_stradaboost_concrete = []\n",
    "\n",
    "print(\"STrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(concrete_tgt_df):\n",
    "        \n",
    "    concrete_train_df_X = concrete_tgt_df.iloc[train_idx].loc[:, features_concrete]\n",
    "    concrete_test_df_X = concrete_tgt_df.iloc[test_idx][features_concrete]\n",
    "    concrete_train_df_y = concrete_tgt_df.iloc[train_idx].loc[:,target_concrete]\n",
    "    concrete_test_df_y = concrete_tgt_df.loc[test_idx][target_concrete]\n",
    "        \n",
    "    concrete_X_df = pd.concat([concrete_source_df_X, concrete_train_df_X], ignore_index=True)\n",
    "    concrete_y_df = pd.concat([concrete_source_df_y, concrete_train_df_y], ignore_index=True)\n",
    "\n",
    "    concrete_np_train_X = concrete_X_df.to_numpy()\n",
    "    concrete_np_train_y = concrete_y_df.to_numpy()\n",
    "\n",
    "    concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "    concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "    concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "    \n",
    "    sample_size = [len(concrete_source_df_X), len(concrete_train_df_X)]\n",
    "\n",
    "\n",
    "    model_stradaboost_concrete = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth = 6),\n",
    "                        n_estimators = n_estimators, sample_size = sample_size,\n",
    "                        steps = steps, fold = fold)\n",
    "\n",
    "\n",
    "    model_stradaboost_concrete.fit(concrete_np_train_X, concrete_np_train_y_list)\n",
    "    y_pred_stradaboost_concrete = model_stradaboost_concrete.predict(concrete_np_test_X)\n",
    "\n",
    "\n",
    "    mse_stradaboost_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_stradaboost_concrete))\n",
    "    rmselist_stradaboost_concrete.append(mse_stradaboost_concrete)\n",
    "        \n",
    "    r2_score_stradaboost_concrete = pearsonr(concrete_np_test_y_list, y_pred_stradaboost_concrete)\n",
    "    r2_score_stradaboost_concrete = (r2_score_stradaboost_concrete[0])**2\n",
    "    r2scorelist_stradaboost_concrete.append(r2_score_stradaboost_concrete)\n",
    "\n",
    "\n",
    "print(\"RMSE List of STrAdaboost.R2:\", rmselist_stradaboost_concrete)\n",
    "print(\"R^2 List of STrAdaboost.R2:\", r2scorelist_stradaboost_concrete)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_stradaboost_concrete), statistics.stdev(rmselist_stradaboost_concrete))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_stradaboost_concrete), statistics.stdev(r2scorelist_stradaboost_concrete))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of GBRTL: [4.515900133547423, 6.210888075169717, 11.106553564755211, 5.4387640270864255, 8.736268180436614, 6.651579682770761, 7.569485973285755, 5.721255297352209, 5.924887590435582, 4.228793444505553, 6.904398932197838, 2.228612660557733, 3.2416230725746726, 2.7184888202522903, 3.646487449836652, 2.6163093112480342, 3.0562610932156598, 5.487844230567313, 2.3974127443453592, 3.3803243903341977]\n",
      "R^2 List of GBRTL: [0.948425804686607, 0.6517085074672222, 0.4062170357132619, 0.8166978291188532, 0.7155094772890215, 0.8906731339754911, 0.645851504650881, 0.4052614707560652, 0.7468216868330175, 0.9358695449368434, 0.7421593141277638, 0.9621149559631862, 0.9541496141859611, 0.9640332927063733, 0.8986326011576428, 0.9216748677859443, 0.9005107662119758, 0.6674720122760992, 0.9498949259870788, 0.8877494078243132]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 5.08910693372375 2.348748570144169\n",
      "Mean, STDev of R^2: 0.8005713876826801 0.17445409818476312\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning Concrete #######################################\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_concrete = []\n",
    "rmselist_GBRTL_concrete = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(concrete_tgt_df):\n",
    "        \n",
    "    concrete_train_df_X = concrete_tgt_df.iloc[train_idx].loc[:, features_concrete]\n",
    "    concrete_test_df_X = concrete_tgt_df.iloc[test_idx][features_concrete]\n",
    "    concrete_train_df_y = concrete_tgt_df.iloc[train_idx].loc[:,target_concrete]\n",
    "    concrete_test_df_y = concrete_tgt_df.loc[test_idx][target_concrete]\n",
    "        \n",
    "    concrete_X_df = pd.concat([concrete_source_df_X, concrete_train_df_X], ignore_index=True)\n",
    "    concrete_y_df = pd.concat([concrete_source_df_y, concrete_train_df_y], ignore_index=True)\n",
    "\n",
    "    concrete_np_train_X = concrete_X_df.to_numpy()\n",
    "    concrete_np_train_y = concrete_y_df.to_numpy()\n",
    "\n",
    "    concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "    concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "    concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "\n",
    "\n",
    "    model_GBRTL_concrete = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100)\n",
    "    model_GBRTL_concrete.fit(concrete_np_train_X, concrete_np_train_y_list)\n",
    "\n",
    "    y_pred_GBRTL_concrete = model_GBRTL_concrete.predict(concrete_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "    \n",
    "    mse_GBRTL_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_GBRTL_concrete))\n",
    "    rmselist_GBRTL_concrete.append(mse_GBRTL_concrete)\n",
    "        \n",
    "    r2_score_GBRTL_concrete = pearsonr(concrete_np_test_y_list, y_pred_GBRTL_concrete)\n",
    "    r2_score_GBRTL_concrete = (r2_score_GBRTL_concrete[0])**2\n",
    "    r2scorelist_GBRTL_concrete.append(r2_score_GBRTL_concrete)\n",
    "\n",
    "\n",
    "print(\"RMSE List of GBRTL:\", rmselist_GBRTL_concrete)\n",
    "print(\"R^2 List of GBRTL:\", r2scorelist_GBRTL_concrete)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_GBRTL_concrete), statistics.stdev(rmselist_GBRTL_concrete))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_GBRTL_concrete), statistics.stdev(r2scorelist_GBRTL_concrete))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE List of Adaboost.R2: [4.971678335785356, 4.050848823930435, 11.010233910021816, 5.6851970093267274, 7.716322228981622, 7.629343552697231, 7.158032975984863, 5.857658798998065, 4.062017132325135, 5.229707744399672, 7.497593408557027, 4.221068427604768, 5.1043846928798695, 5.127297457086784, 5.208835016212533, 5.935554715161531, 5.016325446832422, 8.122051439460494, 4.958353300738871, 5.327307648866592]\n",
      "R^2 List of TrAdaboostR2: [0.9576526478008768, 0.8740324433260943, 0.41468583025646266, 0.7955998313349472, 0.7779544932321402, 0.9053067277466689, 0.608483744068395, 0.3160048064903876, 0.743353502917773, 0.9077652622565813, 0.7472879017958575, 0.9062261004927639, 0.8859144041933634, 0.8931975435408611, 0.812889676957114, 0.7773127948996449, 0.7921793405102375, 0.49800737019525704, 0.8986236291661793, 0.7485485000589447]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 5.994490603292591 1.7164529071133592\n",
      "Mean, STDev of R^2: 0.7630513275620275 0.17521265474704778\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning Concrete #####################################################\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_AdaTL_concrete = []\n",
    "rmselist_AdaTL_concrete = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(concrete_tgt_df):\n",
    "        \n",
    "    concrete_train_df_X = concrete_tgt_df.iloc[train_idx].loc[:, features_concrete]\n",
    "    concrete_test_df_X = concrete_tgt_df.iloc[test_idx][features_concrete]\n",
    "    concrete_train_df_y = concrete_tgt_df.iloc[train_idx].loc[:,target_concrete]\n",
    "    concrete_test_df_y = concrete_tgt_df.loc[test_idx][target_concrete]\n",
    "        \n",
    "    concrete_X_df = pd.concat([concrete_source_df_X, concrete_train_df_X], ignore_index=True)\n",
    "    concrete_y_df = pd.concat([concrete_source_df_y, concrete_train_df_y], ignore_index=True)\n",
    "\n",
    "    concrete_np_train_X = concrete_X_df.to_numpy()\n",
    "    concrete_np_train_y = concrete_y_df.to_numpy()\n",
    "\n",
    "    concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "    concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "    concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "\n",
    "\n",
    "    model_AdaTL_concrete = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_AdaTL_concrete.fit(concrete_np_train_X, concrete_np_train_y_list)\n",
    "    \n",
    "    y_pred_AdaTL_concrete = model_AdaTL_concrete.predict(concrete_np_test_X)\n",
    "    \n",
    "    mse_AdaTL_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_AdaTL_concrete))\n",
    "    rmselist_AdaTL_concrete.append(mse_AdaTL_concrete)\n",
    "        \n",
    "    r2_score_AdaTL_concrete = pearsonr(concrete_np_test_y_list, y_pred_AdaTL_concrete)\n",
    "    r2_score_AdaTL_concrete = (r2_score_AdaTL_concrete[0])**2\n",
    "    r2scorelist_AdaTL_concrete.append(r2_score_AdaTL_concrete)\n",
    "    \n",
    "\n",
    "print(\"RMSE List of Adaboost.R2:\", rmselist_AdaTL_concrete)\n",
    "print(\"R^2 List of TrAdaboostR2:\", r2scorelist_AdaTL_concrete)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_AdaTL_concrete), statistics.stdev(rmselist_AdaTL_concrete))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_AdaTL_concrete), statistics.stdev(r2scorelist_AdaTL_concrete))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Adaboost.R2\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of Adaboost.R2: [4.748099173416622, 4.193142739067393, 9.80807404544599, 6.613389246521382, 5.177454123552435, 10.880350401818246, 8.164593651147321, 7.781811825844132, 6.180351368300683, 4.588869053658558, 7.136203126696669, 4.240250832578044, 5.175834045634039, 4.969144673621939, 4.591976195780937, 4.005867620045321, 3.5528526941331147, 4.951957625096265, 3.0134378854019137, 4.694470720418787]\n",
      "R^2 List of AdaboostR2: [0.9429491450341873, 0.8693517059043606, 0.49451256932132903, 0.769372578024711, 0.8749279839519757, 0.8422515038192517, 0.6252595143214322, 0.3731101694196606, 0.6208619874457955, 0.9150277702008566, 0.7044111686616642, 0.8635940458595132, 0.8410010813588894, 0.8794088118751837, 0.8546322271851177, 0.8308758104604077, 0.8387128527726913, 0.7193107915791445, 0.9198335282746206, 0.7789291776915598]\n",
      "\n",
      "\n",
      "RMSE of Adaboost.R2: 5.723406552408989 2.0819738487138593\n",
      "R^2 of AdaboostR2: 0.7779167211581176 0.14923690697886408\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "########################### Regular AdaBoostR2 Concrete #####################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "print(\"Regular Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_Ada_concrete = []\n",
    "rmselist_Ada_concrete = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(concrete_tgt_df):\n",
    "        \n",
    "    concrete_train_df_X = concrete_tgt_df.iloc[train_idx].loc[:, features_concrete]\n",
    "    concrete_test_df_X = concrete_tgt_df.iloc[test_idx][features_concrete]\n",
    "    concrete_train_df_y = concrete_tgt_df.iloc[train_idx].loc[:,target_concrete]\n",
    "    concrete_test_df_y = concrete_tgt_df.loc[test_idx][target_concrete]\n",
    "    \n",
    "    concrete_np_train_X = concrete_train_df_X.to_numpy()\n",
    "    concrete_np_train_y = concrete_train_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "    concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "    concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "    \n",
    "    model_Ada_concrete = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_Ada_concrete.fit(concrete_train_df_X, concrete_train_df_y)\n",
    "    \n",
    "    y_pred_Ada_concrete = model_Ada_concrete.predict(concrete_np_test_X)\n",
    "    \n",
    "    mse_Ada_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_Ada_concrete))\n",
    "    rmselist_Ada_concrete.append(mse_Ada_concrete)\n",
    "        \n",
    "    r2_score_Ada_concrete = pearsonr(concrete_np_test_y_list, y_pred_Ada_concrete)\n",
    "    r2_score_Ada_concrete = (r2_score_Ada_concrete[0])**2\n",
    "    r2scorelist_Ada_concrete.append(r2_score_Ada_concrete)\n",
    "\n",
    "print(\"RMSE List of Adaboost.R2:\", rmselist_Ada_concrete)\n",
    "print(\"R^2 List of AdaboostR2:\", r2scorelist_Ada_concrete)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of Adaboost.R2:\", statistics.mean(rmselist_Ada_concrete), statistics.stdev(rmselist_Ada_concrete))\n",
    "print(\"R^2 of AdaboostR2:\", statistics.mean(r2scorelist_Ada_concrete), statistics.stdev(r2scorelist_Ada_concrete))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of GBR: [5.901930671157144, 5.15337288272756, 9.265388049083601, 5.738781819708581, 5.5256500594423965, 9.774874451372645, 8.935231598947555, 6.859322120694691, 5.7393575272356, 4.028620374862914, 8.95317594139937, 2.2334276157948123, 3.7365644569260983, 3.0168474523839337, 2.167892596744059, 1.3718077127916302, 2.721870229734329, 4.807620069095459, 1.1216067790127804, 1.2942313635899643]\n",
      "R^2 of GBR: [0.9105964696442186, 0.8074813612958679, 0.5347861111395603, 0.8110548508652644, 0.8583022687839148, 0.8407367941548819, 0.5467881243304514, 0.5786039807666902, 0.6748558944752804, 0.9544245180763558, 0.5813070503951928, 0.9710642366143599, 0.9177991009409214, 0.9612368871656646, 0.9702060358500241, 0.9788516462624213, 0.8912714113904493, 0.7716571847598206, 0.9847584011713646, 0.98610265654788]\n",
      "\n",
      "\n",
      "RMSE of GBR: 4.917378688635257 2.781004523310294\n",
      "R^2 of GBR: 0.8265942492315292 0.1592957121538132\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Regular Gradient Boosting Regression Concrete #######################################\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "print(\"Regular Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBR_concrete = []\n",
    "rmselist_GBR_concrete = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(concrete_tgt_df):\n",
    "        \n",
    "    concrete_train_df_X = concrete_tgt_df.iloc[train_idx].loc[:, features_concrete]\n",
    "    concrete_test_df_X = concrete_tgt_df.iloc[test_idx][features_concrete]\n",
    "    concrete_train_df_y = concrete_tgt_df.iloc[train_idx].loc[:,target_concrete]\n",
    "    concrete_test_df_y = concrete_tgt_df.loc[test_idx][target_concrete]\n",
    "    \n",
    "    concrete_np_train_X = concrete_train_df_X.to_numpy()\n",
    "    concrete_np_train_y = concrete_train_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "    concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "    concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "\n",
    "    model_GBR_concrete = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100, subsample=0.5)\n",
    "    model_GBR_concrete.fit(concrete_train_df_X, concrete_train_df_y)\n",
    "\n",
    "    y_pred_GBR_concrete = model_GBR_concrete.predict(concrete_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "    \n",
    "    mse_GBR_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_GBR_concrete))\n",
    "    rmselist_GBR_concrete.append(mse_GBR_concrete)\n",
    "        \n",
    "    r2_score_GBR_concrete = pearsonr(concrete_np_test_y_list, y_pred_GBR_concrete)\n",
    "    r2_score_GBR_concrete = (r2_score_GBR_concrete[0])**2\n",
    "    r2scorelist_GBR_concrete.append(r2_score_GBR_concrete)\n",
    "\n",
    "print(\"RMSE of GBR:\", rmselist_GBR_concrete)\n",
    "print(\"R^2 of GBR:\", r2scorelist_GBR_concrete)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of GBR:\", statistics.mean(rmselist_GBR_concrete), statistics.stdev(rmselist_GBR_concrete))\n",
    "print(\"R^2 of GBR:\", statistics.mean(r2scorelist_GBR_concrete), statistics.stdev(r2scorelist_GBR_concrete))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Mean Matching\n",
      "-------------------------------------------\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.5426e+04 -7.3445e+07  8e+07  5e-03  7e-15\n",
      " 1: -2.5276e+04 -1.4002e+06  1e+06  5e-05  2e-15\n",
      " 2: -3.1024e+04 -2.8143e+05  3e+05  9e-06  8e-16\n",
      " 3: -5.2630e+04 -1.7924e+05  1e+05  2e-07  7e-16\n",
      " 4: -5.5094e+04 -8.8084e+04  3e+04  4e-08  7e-16\n",
      " 5: -5.6627e+04 -6.8578e+04  1e+04  2e-16  7e-16\n",
      " 6: -5.7519e+04 -6.0887e+04  3e+03  2e-16  7e-16\n",
      " 7: -5.7887e+04 -5.9225e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.8043e+04 -5.8581e+04  5e+02  2e-16  7e-16\n",
      " 9: -5.8117e+04 -5.8339e+04  2e+02  2e-16  8e-16\n",
      "10: -5.8153e+04 -5.8239e+04  9e+01  2e-16  7e-16\n",
      "11: -5.8171e+04 -5.8196e+04  3e+01  2e-16  7e-16\n",
      "12: -5.8178e+04 -5.8182e+04  5e+00  2e-16  7e-16\n",
      "13: -5.8179e+04 -5.8180e+04  8e-01  1e-16  7e-16\n",
      "14: -5.8180e+04 -5.8180e+04  1e-01  2e-16  7e-16\n",
      "15: -5.8180e+04 -5.8180e+04  2e-03  2e-16  8e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1608e+04 -7.3162e+07  8e+07  5e-03  2e-15\n",
      " 1: -2.0895e+04 -1.3920e+06  1e+06  5e-05  2e-15\n",
      " 2: -2.6967e+04 -2.8080e+05  3e+05  9e-06  9e-16\n",
      " 3: -4.9377e+04 -1.7600e+05  1e+05  2e-16  7e-16\n",
      " 4: -5.1732e+04 -8.5189e+04  3e+04  2e-16  7e-16\n",
      " 5: -5.2935e+04 -6.9281e+04  2e+04  2e-16  7e-16\n",
      " 6: -5.3890e+04 -5.8516e+04  5e+03  2e-16  7e-16\n",
      " 7: -5.4361e+04 -5.5856e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.4547e+04 -5.5089e+04  5e+02  2e-16  8e-16\n",
      " 9: -5.4608e+04 -5.4854e+04  2e+02  2e-16  7e-16\n",
      "10: -5.4639e+04 -5.4759e+04  1e+02  2e-16  7e-16\n",
      "11: -5.4663e+04 -5.4698e+04  3e+01  2e-16  7e-16\n",
      "12: -5.4669e+04 -5.4685e+04  2e+01  2e-16  7e-16\n",
      "13: -5.4674e+04 -5.4676e+04  2e+00  2e-16  7e-16\n",
      "14: -5.4675e+04 -5.4675e+04  3e-01  2e-16  7e-16\n",
      "15: -5.4675e+04 -5.4675e+04  3e-02  1e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2512e+04 -7.3262e+07  8e+07  5e-03  1e-14\n",
      " 1: -2.1946e+04 -1.4011e+06  1e+06  5e-05  2e-15\n",
      " 2: -2.7862e+04 -2.8107e+05  3e+05  9e-06  1e-15\n",
      " 3: -5.0187e+04 -1.7837e+05  1e+05  6e-08  8e-16\n",
      " 4: -5.2497e+04 -8.4868e+04  3e+04  1e-08  7e-16\n",
      " 5: -5.3779e+04 -6.8350e+04  1e+04  3e-10  8e-16\n",
      " 6: -5.4723e+04 -5.8469e+04  4e+03  3e-11  7e-16\n",
      " 7: -5.5153e+04 -5.6487e+04  1e+03  5e-12  7e-16\n",
      " 8: -5.5324e+04 -5.5881e+04  6e+02  7e-15  7e-16\n",
      " 9: -5.5405e+04 -5.5545e+04  1e+02  1e-15  7e-16\n",
      "10: -5.5427e+04 -5.5502e+04  8e+01  2e-16  7e-16\n",
      "11: -5.5444e+04 -5.5463e+04  2e+01  2e-16  6e-16\n",
      "12: -5.5447e+04 -5.5456e+04  9e+00  2e-16  6e-16\n",
      "13: -5.5450e+04 -5.5452e+04  2e+00  2e-16  7e-16\n",
      "14: -5.5451e+04 -5.5451e+04  3e-01  2e-16  7e-16\n",
      "15: -5.5451e+04 -5.5451e+04  1e-02  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2035e+04 -7.3174e+07  8e+07  5e-03  4e-15\n",
      " 1: -2.1290e+04 -1.3967e+06  1e+06  5e-05  2e-15\n",
      " 2: -2.7298e+04 -2.8104e+05  3e+05  9e-06  9e-16\n",
      " 3: -4.9796e+04 -1.7731e+05  1e+05  2e-08  7e-16\n",
      " 4: -5.2154e+04 -8.5900e+04  3e+04  4e-09  7e-16\n",
      " 5: -5.3424e+04 -6.7975e+04  1e+04  2e-16  8e-16\n",
      " 6: -5.4359e+04 -5.8082e+04  4e+03  2e-16  7e-16\n",
      " 7: -5.4783e+04 -5.6018e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.4842e+04 -5.5875e+04  1e+03  2e-16  6e-16\n",
      " 9: -5.4985e+04 -5.5264e+04  3e+02  2e-16  7e-16\n",
      "10: -5.5028e+04 -5.5163e+04  1e+02  2e-16  7e-16\n",
      "11: -5.5056e+04 -5.5087e+04  3e+01  2e-16  7e-16\n",
      "12: -5.5065e+04 -5.5070e+04  5e+00  2e-16  8e-16\n",
      "13: -5.5067e+04 -5.5068e+04  8e-01  2e-16  7e-16\n",
      "14: -5.5067e+04 -5.5067e+04  8e-02  2e-16  7e-16\n",
      "15: -5.5067e+04 -5.5067e+04  2e-02  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1017e+04 -7.3129e+07  8e+07  5e-03  2e-15\n",
      " 1: -2.0398e+04 -1.3986e+06  1e+06  5e-05  2e-15\n",
      " 2: -2.6360e+04 -2.8125e+05  3e+05  9e-06  1e-15\n",
      " 3: -4.8971e+04 -1.7877e+05  1e+05  9e-08  8e-16\n",
      " 4: -5.1269e+04 -8.2440e+04  3e+04  2e-08  7e-16\n",
      " 5: -5.2254e+04 -7.1083e+04  2e+04  5e-09  7e-16\n",
      " 6: -5.3228e+04 -5.8789e+04  6e+03  9e-10  7e-16\n",
      " 7: -5.3752e+04 -5.5431e+04  2e+03  2e-16  7e-16\n",
      " 8: -5.3952e+04 -5.4546e+04  6e+02  2e-16  7e-16\n",
      " 9: -5.4026e+04 -5.4255e+04  2e+02  2e-16  6e-16\n",
      "10: -5.4057e+04 -5.4172e+04  1e+02  1e-16  8e-16\n",
      "11: -5.4080e+04 -5.4113e+04  3e+01  2e-16  6e-16\n",
      "12: -5.4086e+04 -5.4100e+04  1e+01  2e-16  7e-16\n",
      "13: -5.4091e+04 -5.4093e+04  2e+00  2e-16  7e-16\n",
      "14: -5.4091e+04 -5.4092e+04  3e-01  2e-16  7e-16\n",
      "15: -5.4092e+04 -5.4092e+04  3e-02  1e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2025e+04 -7.3168e+07  8e+07  5e-03  2e-15\n",
      " 1: -2.1721e+04 -1.4027e+06  1e+06  5e-05  3e-15\n",
      " 2: -2.7506e+04 -2.8172e+05  3e+05  9e-06  8e-16\n",
      " 3: -4.9972e+04 -1.8047e+05  1e+05  1e-07  7e-16\n",
      " 4: -5.2283e+04 -8.1286e+04  3e+04  3e-08  6e-16\n",
      " 5: -5.3716e+04 -6.5418e+04  1e+04  2e-16  7e-16\n",
      " 6: -5.4526e+04 -5.7388e+04  3e+03  2e-16  7e-16\n",
      " 7: -5.4859e+04 -5.5937e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.4906e+04 -5.5809e+04  9e+02  2e-16  7e-16\n",
      " 9: -5.5021e+04 -5.5309e+04  3e+02  2e-16  7e-16\n",
      "10: -5.5068e+04 -5.5181e+04  1e+02  2e-16  7e-16\n",
      "11: -5.5091e+04 -5.5123e+04  3e+01  2e-16  7e-16\n",
      "12: -5.5097e+04 -5.5110e+04  1e+01  2e-16  7e-16\n",
      "13: -5.5101e+04 -5.5103e+04  2e+00  2e-16  7e-16\n",
      "14: -5.5102e+04 -5.5102e+04  3e-01  2e-16  7e-16\n",
      "15: -5.5102e+04 -5.5102e+04  3e-02  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1850e+04 -7.3193e+07  8e+07  6e-03  2e-15\n",
      " 1: -2.0035e+04 -1.4373e+06  1e+06  6e-05  2e-15\n",
      " 2: -2.5926e+04 -2.8148e+05  3e+05  1e-05  9e-16\n",
      " 3: -4.9070e+04 -1.9142e+05  1e+05  7e-07  8e-16\n",
      " 4: -5.1638e+04 -8.8855e+04  4e+04  2e-07  7e-16\n",
      " 5: -5.2769e+04 -7.3423e+04  2e+04  3e-08  7e-16\n",
      " 6: -5.3901e+04 -5.9756e+04  6e+03  4e-09  7e-16\n",
      " 7: -5.4504e+04 -5.6295e+04  2e+03  3e-10  7e-16\n",
      " 8: -5.4738e+04 -5.5280e+04  5e+02  8e-13  7e-16\n",
      " 9: -5.4807e+04 -5.5072e+04  3e+02  2e-13  7e-16\n",
      "10: -5.4847e+04 -5.4944e+04  1e+02  5e-14  7e-16\n",
      "11: -5.4861e+04 -5.4906e+04  4e+01  5e-15  7e-16\n",
      "12: -5.4872e+04 -5.4883e+04  1e+01  9e-16  7e-16\n",
      "13: -5.4876e+04 -5.4878e+04  2e+00  2e-16  7e-16\n",
      "14: -5.4876e+04 -5.4877e+04  2e-01  2e-16  7e-16\n",
      "15: -5.4877e+04 -5.4877e+04  2e-02  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0476e+04 -7.3093e+07  8e+07  6e-03  3e-15\n",
      " 1: -1.7876e+04 -1.4509e+06  1e+06  6e-05  2e-15\n",
      " 2: -2.3840e+04 -2.8172e+05  3e+05  1e-05  1e-15\n",
      " 3: -4.7548e+04 -1.9682e+05  1e+05  1e-06  7e-16\n",
      " 4: -5.0276e+04 -8.8392e+04  4e+04  2e-07  7e-16\n",
      " 5: -5.1197e+04 -7.6479e+04  3e+04  7e-08  6e-16\n",
      " 6: -5.2365e+04 -6.1007e+04  9e+03  2e-08  7e-16\n",
      " 7: -5.3047e+04 -5.6242e+04  3e+03  2e-16  7e-16\n",
      " 8: -5.3333e+04 -5.4510e+04  1e+03  2e-16  7e-16\n",
      " 9: -5.3381e+04 -5.4359e+04  1e+03  2e-16  6e-16\n",
      "10: -5.3509e+04 -5.3794e+04  3e+02  2e-16  7e-16\n",
      "11: -5.3552e+04 -5.3673e+04  1e+02  2e-16  7e-16\n",
      "12: -5.3574e+04 -5.3622e+04  5e+01  2e-16  7e-16\n",
      "13: -5.3586e+04 -5.3597e+04  1e+01  2e-16  7e-16\n",
      "14: -5.3589e+04 -5.3592e+04  3e+00  2e-16  7e-16\n",
      "15: -5.3590e+04 -5.3591e+04  5e-01  2e-16  7e-16\n",
      "16: -5.3590e+04 -5.3590e+04  6e-02  2e-16  7e-16\n",
      "17: -5.3590e+04 -5.3590e+04  9e-04  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1616e+04 -7.3176e+07  8e+07  6e-03  6e-15\n",
      " 1: -1.9659e+04 -1.4423e+06  1e+06  6e-05  2e-15\n",
      " 2: -2.5536e+04 -2.8169e+05  3e+05  1e-05  9e-16\n",
      " 3: -4.8841e+04 -1.9344e+05  1e+05  8e-07  7e-16\n",
      " 4: -5.1529e+04 -8.4251e+04  3e+04  2e-07  7e-16\n",
      " 5: -5.2704e+04 -7.1349e+04  2e+04  3e-08  7e-16\n",
      " 6: -5.3774e+04 -5.8719e+04  5e+03  5e-09  7e-16\n",
      " 7: -5.4282e+04 -5.5885e+04  2e+03  6e-10  7e-16\n",
      " 8: -5.4498e+04 -5.5051e+04  6e+02  2e-16  8e-16\n",
      " 9: -5.4579e+04 -5.4746e+04  2e+02  2e-16  7e-16\n",
      "10: -5.4608e+04 -5.4680e+04  7e+01  2e-16  7e-16\n",
      "11: -5.4625e+04 -5.4640e+04  2e+01  2e-16  7e-16\n",
      "12: -5.4629e+04 -5.4632e+04  3e+00  2e-16  8e-16\n",
      "13: -5.4630e+04 -5.4631e+04  7e-01  2e-16  7e-16\n",
      "14: -5.4630e+04 -5.4630e+04  1e-01  2e-16  7e-16\n",
      "15: -5.4630e+04 -5.4630e+04  2e-03  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3184e+04 -7.3233e+07  8e+07  5e-03  5e-15\n",
      " 1: -2.2538e+04 -1.4023e+06  1e+06  5e-05  2e-15\n",
      " 2: -2.8432e+04 -2.8126e+05  3e+05  9e-06  9e-16\n",
      " 3: -5.0790e+04 -1.7892e+05  1e+05  7e-08  7e-16\n",
      " 4: -5.3150e+04 -8.4675e+04  3e+04  1e-08  6e-16\n",
      " 5: -5.4631e+04 -6.6897e+04  1e+04  2e-16  7e-16\n",
      " 6: -5.5512e+04 -5.8682e+04  3e+03  2e-16  7e-16\n",
      " 7: -5.5925e+04 -5.7024e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.5951e+04 -5.6966e+04  1e+03  2e-16  6e-16\n",
      " 9: -5.6099e+04 -5.6357e+04  3e+02  2e-16  7e-16\n",
      "10: -5.6149e+04 -5.6238e+04  9e+01  2e-16  7e-16\n",
      "11: -5.6160e+04 -5.6213e+04  5e+01  2e-16  6e-16\n",
      "12: -5.6175e+04 -5.6185e+04  1e+01  2e-16  7e-16\n",
      "13: -5.6177e+04 -5.6181e+04  4e+00  2e-16  7e-16\n",
      "14: -5.6178e+04 -5.6179e+04  4e-01  2e-16  7e-16\n",
      "15: -5.6178e+04 -5.6178e+04  7e-02  2e-16  7e-16\n",
      "16: -5.6178e+04 -5.6178e+04  1e-03  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3961e+04 -7.3271e+07  8e+07  5e-03  1e-14\n",
      " 1: -2.3497e+04 -1.3943e+06  1e+06  5e-05  2e-15\n",
      " 2: -2.9422e+04 -2.8112e+05  3e+05  9e-06  9e-16\n",
      " 3: -5.1466e+04 -1.7652e+05  1e+05  2e-16  7e-16\n",
      " 4: -5.3838e+04 -8.6415e+04  3e+04  2e-16  7e-16\n",
      " 5: -5.5339e+04 -6.6993e+04  1e+04  2e-16  7e-16\n",
      " 6: -5.6271e+04 -5.9240e+04  3e+03  2e-16  7e-16\n",
      " 7: -5.6675e+04 -5.7674e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.6736e+04 -5.7500e+04  8e+02  2e-16  7e-16\n",
      " 9: -5.6851e+04 -5.7045e+04  2e+02  2e-16  7e-16\n",
      "10: -5.6874e+04 -5.6998e+04  1e+02  2e-16  6e-16\n",
      "11: -5.6902e+04 -5.6934e+04  3e+01  2e-16  6e-16\n",
      "12: -5.6910e+04 -5.6918e+04  9e+00  2e-16  8e-16\n",
      "13: -5.6912e+04 -5.6914e+04  2e+00  2e-16  7e-16\n",
      "14: -5.6913e+04 -5.6913e+04  3e-01  2e-16  7e-16\n",
      "15: -5.6913e+04 -5.6913e+04  3e-02  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.4024e+04 -7.3337e+07  8e+07  5e-03  4e-15\n",
      " 1: -2.3976e+04 -1.3899e+06  1e+06  5e-05  2e-15\n",
      " 2: -2.9891e+04 -2.8099e+05  3e+05  9e-06  9e-16\n",
      " 3: -5.1673e+04 -1.7542e+05  1e+05  2e-16  8e-16\n",
      " 4: -5.4013e+04 -8.5809e+04  3e+04  2e-16  7e-16\n",
      " 5: -5.5490e+04 -6.6553e+04  1e+04  2e-16  7e-16\n",
      " 6: -5.6307e+04 -5.9187e+04  3e+03  2e-16  7e-16\n",
      " 7: -5.6657e+04 -5.7705e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.6787e+04 -5.7158e+04  4e+02  2e-16  7e-16\n",
      " 9: -5.6842e+04 -5.6991e+04  1e+02  2e-16  7e-16\n",
      "10: -5.6872e+04 -5.6915e+04  4e+01  2e-16  8e-16\n",
      "11: -5.6883e+04 -5.6892e+04  9e+00  2e-16  8e-16\n",
      "12: -5.6886e+04 -5.6888e+04  2e+00  2e-16  7e-16\n",
      "13: -5.6887e+04 -5.6887e+04  4e-01  2e-16  7e-16\n",
      "14: -5.6887e+04 -5.6887e+04  5e-02  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.4046e+04 -7.3328e+07  8e+07  5e-03  7e-15\n",
      " 1: -2.3891e+04 -1.3914e+06  1e+06  5e-05  2e-15\n",
      " 2: -2.9810e+04 -2.8099e+05  3e+05  9e-06  9e-16\n",
      " 3: -5.1660e+04 -1.7574e+05  1e+05  2e-16  7e-16\n",
      " 4: -5.4011e+04 -8.5909e+04  3e+04  2e-16  7e-16\n",
      " 5: -5.5501e+04 -6.6654e+04  1e+04  2e-16  8e-16\n",
      " 6: -5.6308e+04 -5.9351e+04  3e+03  2e-16  7e-16\n",
      " 7: -5.6702e+04 -5.7566e+04  9e+02  2e-16  8e-16\n",
      " 8: -5.6821e+04 -5.7183e+04  4e+02  2e-16  7e-16\n",
      " 9: -5.6870e+04 -5.7002e+04  1e+02  2e-16  7e-16\n",
      "10: -5.6892e+04 -5.6940e+04  5e+01  2e-16  7e-16\n",
      "11: -5.6903e+04 -5.6917e+04  1e+01  2e-16  7e-16\n",
      "12: -5.6907e+04 -5.6910e+04  3e+00  2e-16  8e-16\n",
      "13: -5.6908e+04 -5.6908e+04  5e-01  2e-16  7e-16\n",
      "14: -5.6908e+04 -5.6908e+04  7e-02  2e-16  8e-16\n",
      "15: -5.6908e+04 -5.6908e+04  8e-04  2e-16  8e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.4191e+04 -7.3323e+07  8e+07  5e-03  2e-15\n",
      " 1: -2.4171e+04 -1.3916e+06  1e+06  5e-05  2e-15\n",
      " 2: -3.0032e+04 -2.8125e+05  3e+05  9e-06  8e-16\n",
      " 3: -5.1869e+04 -1.7601e+05  1e+05  2e-16  8e-16\n",
      " 4: -5.4187e+04 -8.6143e+04  3e+04  2e-16  7e-16\n",
      " 5: -5.5653e+04 -6.6919e+04  1e+04  2e-16  8e-16\n",
      " 6: -5.6489e+04 -5.9340e+04  3e+03  2e-16  7e-16\n",
      " 7: -5.6837e+04 -5.7941e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.6983e+04 -5.7323e+04  3e+02  2e-16  8e-16\n",
      " 9: -5.7038e+04 -5.7166e+04  1e+02  2e-16  7e-16\n",
      "10: -5.7068e+04 -5.7097e+04  3e+01  2e-16  7e-16\n",
      "11: -5.7072e+04 -5.7089e+04  2e+01  2e-16  6e-16\n",
      "12: -5.7077e+04 -5.7080e+04  2e+00  2e-16  7e-16\n",
      "13: -5.7078e+04 -5.7078e+04  4e-01  2e-16  7e-16\n",
      "14: -5.7078e+04 -5.7078e+04  6e-02  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.4295e+04 -7.3230e+07  8e+07  6e-03  5e-15\n",
      " 1: -2.3611e+04 -1.4137e+06  1e+06  5e-05  2e-15\n",
      " 2: -2.9294e+04 -2.8185e+05  3e+05  1e-05  9e-16\n",
      " 3: -5.1722e+04 -1.8420e+05  1e+05  3e-07  7e-16\n",
      " 4: -5.4160e+04 -8.8861e+04  3e+04  7e-08  7e-16\n",
      " 5: -5.5639e+04 -6.9732e+04  1e+04  2e-16  7e-16\n",
      " 6: -5.6658e+04 -6.0208e+04  4e+03  2e-16  7e-16\n",
      " 7: -5.7107e+04 -5.8315e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.7145e+04 -5.8226e+04  1e+03  2e-16  6e-16\n",
      " 9: -5.7294e+04 -5.7598e+04  3e+02  2e-16  7e-16\n",
      "10: -5.7346e+04 -5.7471e+04  1e+02  2e-16  7e-16\n",
      "11: -5.7371e+04 -5.7414e+04  4e+01  2e-16  7e-16\n",
      "12: -5.7384e+04 -5.7391e+04  8e+00  2e-16  7e-16\n",
      "13: -5.7386e+04 -5.7387e+04  1e+00  2e-16  6e-16\n",
      "14: -5.7386e+04 -5.7387e+04  2e-01  2e-16  7e-16\n",
      "15: -5.7387e+04 -5.7387e+04  6e-03  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2643e+04 -7.3190e+07  8e+07  6e-03  2e-15\n",
      " 1: -2.0960e+04 -1.4318e+06  1e+06  6e-05  2e-15\n",
      " 2: -2.6821e+04 -2.8173e+05  3e+05  1e-05  9e-16\n",
      " 3: -4.9886e+04 -1.8982e+05  1e+05  6e-07  7e-16\n",
      " 4: -5.2454e+04 -8.9069e+04  4e+04  1e-07  7e-16\n",
      " 5: -5.3794e+04 -6.9901e+04  2e+04  2e-09  7e-16\n",
      " 6: -5.4855e+04 -5.9333e+04  4e+03  2e-10  7e-16\n",
      " 7: -5.5360e+04 -5.6787e+04  1e+03  3e-11  7e-16\n",
      " 8: -5.5545e+04 -5.6189e+04  6e+02  8e-13  8e-16\n",
      " 9: -5.5634e+04 -5.5821e+04  2e+02  2e-13  7e-16\n",
      "10: -5.5643e+04 -5.5802e+04  2e+02  1e-13  6e-16\n",
      "11: -5.5675e+04 -5.5727e+04  5e+01  3e-14  7e-16\n",
      "12: -5.5690e+04 -5.5696e+04  7e+00  3e-16  7e-16\n",
      "13: -5.5692e+04 -5.5693e+04  1e+00  2e-16  7e-16\n",
      "14: -5.5693e+04 -5.5693e+04  2e-01  2e-16  7e-16\n",
      "15: -5.5693e+04 -5.5693e+04  4e-03  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3565e+04 -7.3234e+07  8e+07  6e-03  6e-15\n",
      " 1: -2.2235e+04 -1.4288e+06  1e+06  6e-05  2e-15\n",
      " 2: -2.8031e+04 -2.8168e+05  3e+05  1e-05  8e-16\n",
      " 3: -5.0842e+04 -1.8837e+05  1e+05  5e-07  8e-16\n",
      " 4: -5.3377e+04 -8.9456e+04  4e+04  1e-07  7e-16\n",
      " 5: -5.4819e+04 -6.9631e+04  1e+04  2e-16  7e-16\n",
      " 6: -5.5844e+04 -5.9790e+04  4e+03  2e-16  7e-16\n",
      " 7: -5.6302e+04 -5.7605e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.6346e+04 -5.7495e+04  1e+03  2e-16  6e-16\n",
      " 9: -5.6498e+04 -5.6849e+04  4e+02  2e-16  7e-16\n",
      "10: -5.6558e+04 -5.6685e+04  1e+02  2e-16  7e-16\n",
      "11: -5.6579e+04 -5.6637e+04  6e+01  2e-16  7e-16\n",
      "12: -5.6594e+04 -5.6607e+04  1e+01  2e-16  7e-16\n",
      "13: -5.6597e+04 -5.6602e+04  5e+00  2e-16  7e-16\n",
      "14: -5.6599e+04 -5.6599e+04  7e-01  2e-16  7e-16\n",
      "15: -5.6599e+04 -5.6599e+04  2e-01  2e-16  7e-16\n",
      "16: -5.6599e+04 -5.6599e+04  6e-03  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3791e+04 -7.3266e+07  8e+07  6e-03  2e-14\n",
      " 1: -2.2825e+04 -1.4207e+06  1e+06  5e-05  3e-15\n",
      " 2: -2.8594e+04 -2.8167e+05  3e+05  1e-05  8e-16\n",
      " 3: -5.1170e+04 -1.8539e+05  1e+05  3e-07  7e-16\n",
      " 4: -5.3604e+04 -8.9069e+04  4e+04  8e-08  6e-16\n",
      " 5: -5.5017e+04 -6.9555e+04  1e+04  2e-16  7e-16\n",
      " 6: -5.6035e+04 -5.9877e+04  4e+03  2e-16  7e-16\n",
      " 7: -5.6477e+04 -5.7782e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.6568e+04 -5.7525e+04  1e+03  2e-16  7e-16\n",
      " 9: -5.6701e+04 -5.6968e+04  3e+02  2e-16  7e-16\n",
      "10: -5.6756e+04 -5.6834e+04  8e+01  2e-16  7e-16\n",
      "11: -5.6771e+04 -5.6803e+04  3e+01  1e-16  7e-16\n",
      "12: -5.6780e+04 -5.6787e+04  7e+00  2e-16  7e-16\n",
      "13: -5.6782e+04 -5.6783e+04  1e+00  2e-16  7e-16\n",
      "14: -5.6783e+04 -5.6783e+04  3e-01  2e-16  7e-16\n",
      "15: -5.6783e+04 -5.6783e+04  2e-02  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2957e+04 -7.3207e+07  8e+07  6e-03  8e-15\n",
      " 1: -2.1444e+04 -1.4272e+06  1e+06  6e-05  2e-15\n",
      " 2: -2.7296e+04 -2.8153e+05  3e+05  1e-05  1e-15\n",
      " 3: -5.0215e+04 -1.8819e+05  1e+05  5e-07  7e-16\n",
      " 4: -5.2761e+04 -8.9073e+04  4e+04  1e-07  6e-16\n",
      " 5: -5.4160e+04 -6.9646e+04  2e+04  2e-16  8e-16\n",
      " 6: -5.5207e+04 -5.9470e+04  4e+03  2e-16  7e-16\n",
      " 7: -5.5692e+04 -5.7075e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.5793e+04 -5.6778e+04  1e+03  2e-16  6e-16\n",
      " 9: -5.5924e+04 -5.6209e+04  3e+02  2e-16  7e-16\n",
      "10: -5.5981e+04 -5.6065e+04  8e+01  2e-16  7e-16\n",
      "11: -5.5998e+04 -5.6028e+04  3e+01  2e-16  7e-16\n",
      "12: -5.6008e+04 -5.6012e+04  4e+00  2e-16  7e-16\n",
      "13: -5.6009e+04 -5.6010e+04  2e+00  2e-16  7e-16\n",
      "14: -5.6009e+04 -5.6009e+04  1e-01  2e-16  7e-16\n",
      "15: -5.6009e+04 -5.6009e+04  5e-03  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3979e+04 -7.3210e+07  8e+07  6e-03  2e-15\n",
      " 1: -2.2986e+04 -1.4210e+06  1e+06  6e-05  2e-15\n",
      " 2: -2.8694e+04 -2.8184e+05  3e+05  1e-05  8e-16\n",
      " 3: -5.1347e+04 -1.8655e+05  1e+05  4e-07  7e-16\n",
      " 4: -5.3829e+04 -8.9157e+04  4e+04  9e-08  7e-16\n",
      " 5: -5.5296e+04 -6.9887e+04  1e+04  2e-16  7e-16\n",
      " 6: -5.6333e+04 -6.0053e+04  4e+03  2e-16  7e-16\n",
      " 7: -5.6792e+04 -5.8068e+04  1e+03  2e-16  7e-16\n",
      " 8: -5.6837e+04 -5.7951e+04  1e+03  2e-16  6e-16\n",
      " 9: -5.6986e+04 -5.7322e+04  3e+02  2e-16  6e-16\n",
      "10: -5.7043e+04 -5.7171e+04  1e+02  2e-16  6e-16\n",
      "11: -5.7062e+04 -5.7129e+04  7e+01  2e-16  7e-16\n",
      "12: -5.7078e+04 -5.7095e+04  2e+01  2e-16  7e-16\n",
      "13: -5.7083e+04 -5.7086e+04  4e+00  2e-16  8e-16\n",
      "14: -5.7084e+04 -5.7085e+04  4e-01  2e-16  7e-16\n",
      "15: -5.7084e+04 -5.7084e+04  5e-02  2e-16  7e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "RMSE List of KMM: [16.31598678436139, 24.87761850353384, 19.67677092401533, 11.721721099786688, 14.674733461803777, 9.220538443550785, 13.477346699049393, 19.021477216128357, 22.721629633362394, 18.03861118662604, 26.12146861895187, 14.126535189078993, 15.21973502313892, 11.607515947176632, 29.574287505450858, 35.240026660475586, 30.51666500163175, 29.773208715507057, 40.47975577435641, 30.09147217410201]\n",
      "R^2 List of KMM: [0.613144964915499, 0.5003885030959551, 0.20508351888967497, 0.6083589970891807, 0.6705793639875621, 0.6868287994525731, 0.40530487269651, 0.029334366852617293, 0.43526682675393724, 0.5651671123605255, 0.227636125738626, 0.6796889769721985, 0.4980827022562948, 0.7927254919712137, 0.23847283878468484, 0.031428000964021034, 0.03297159874452097, 0.02790706554678015, 0.005730831556795108, 0.043041215128550296]\n",
      "\n",
      "\n",
      "RMSE of KMM: 21.624855228104405 8.793121196569865\n",
      "R^2 of KMM: 0.364857108687886 0.2737073886797923\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Kernel Mean Matching Concrete #######################################\n",
    "\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_KMM_concrete = []\n",
    "rmselist_KMM_concrete = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(concrete_tgt_df):\n",
    "        \n",
    "    concrete_train_df_X = concrete_tgt_df.iloc[train_idx].loc[:, features_concrete]\n",
    "    concrete_test_df_X = concrete_tgt_df.iloc[test_idx][features_concrete]\n",
    "    concrete_train_df_y = concrete_tgt_df.iloc[train_idx].loc[:,target_concrete]\n",
    "    concrete_test_df_y = concrete_tgt_df.loc[test_idx][target_concrete]\n",
    "        \n",
    "    concrete_np_train_X = concrete_train_df_X.to_numpy()\n",
    "    concrete_np_train_y = concrete_train_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_source_X = concrete_source_df_X.to_numpy()\n",
    "    concrete_np_source_y = concrete_source_df_y.to_numpy()\n",
    "\n",
    "\n",
    "    concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "    concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "    concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "    \n",
    "    src_size_concrete = len(concrete_source_df_y)\n",
    "    tgt_size_concrete = len(concrete_train_df_y)\n",
    "    \n",
    "    src_idx = np.arange(start = 0, stop = (src_size_concrete - 1), step=1)\n",
    "    tgt_idx = np.arange(start = 0, stop = (tgt_size_concrete - 1), step=1)\n",
    "\n",
    "\n",
    "    model_KMM_concrete = KMM(estimator = DecisionTreeRegressor(max_depth = 6))\n",
    "    model_KMM_concrete.fit(concrete_np_source_X[src_idx], concrete_np_source_y[src_idx], concrete_np_train_X[tgt_idx], concrete_np_train_y[tgt_idx])\n",
    "\n",
    "    y_pred_KMM_concrete = model_KMM_concrete.predict(concrete_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "    \n",
    "    mse_KMM_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_KMM_concrete))\n",
    "    rmselist_KMM_concrete.append(mse_KMM_concrete)\n",
    "        \n",
    "    r2_score_KMM_concrete = pearsonr(concrete_np_test_y_list, y_pred_KMM_concrete)\n",
    "    r2_score_KMM_concrete = (r2_score_KMM_concrete[0])**2\n",
    "    r2scorelist_KMM_concrete.append(r2_score_KMM_concrete)\n",
    "\n",
    "print(\"RMSE List of KMM:\", rmselist_KMM_concrete)\n",
    "print(\"R^2 List of KMM:\", r2scorelist_KMM_concrete)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of KMM:\", statistics.mean(rmselist_KMM_concrete), statistics.stdev(rmselist_KMM_concrete))\n",
    "print(\"R^2 of KMM:\", statistics.mean(r2scorelist_KMM_concrete), statistics.stdev(r2scorelist_KMM_concrete))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLIEP\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.094 (0.042)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.726 (0.083)\n",
      "Parameter sigma = 10.0000 -- J-score = -5.896 (1.260)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.061 (0.020)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.590 (0.186)\n",
      "Parameter sigma = 10.0000 -- J-score = -6.937 (1.598)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.070 (0.013)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.644 (0.069)\n",
      "Parameter sigma = 10.0000 -- J-score = -6.490 (1.097)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.063 (0.029)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.461 (0.184)\n",
      "Parameter sigma = 10.0000 -- J-score = -7.267 (0.887)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.043 (0.059)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.335 (0.535)\n",
      "Parameter sigma = 10.0000 -- J-score = -6.932 (1.734)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.041 (0.024)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.446 (0.216)\n",
      "Parameter sigma = 10.0000 -- J-score = -7.338 (1.515)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.052 (0.052)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.400 (0.455)\n",
      "Parameter sigma = 10.0000 -- J-score = -7.233 (1.454)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.036 (0.089)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.243 (0.793)\n",
      "Parameter sigma = 10.0000 -- J-score = -7.753 (1.011)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.052 (0.036)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.585 (0.185)\n",
      "Parameter sigma = 10.0000 -- J-score = -6.812 (1.145)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.062 (0.020)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.602 (0.192)\n",
      "Parameter sigma = 10.0000 -- J-score = -8.067 (1.582)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.063 (0.033)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.589 (0.184)\n",
      "Parameter sigma = 10.0000 -- J-score = -7.974 (0.481)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.055 (0.036)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.560 (0.117)\n",
      "Parameter sigma = 10.0000 -- J-score = -6.865 (1.303)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.061 (0.041)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.457 (0.324)\n",
      "Parameter sigma = 10.0000 -- J-score = -7.809 (1.517)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.050 (0.063)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.528 (0.306)\n",
      "Parameter sigma = 10.0000 -- J-score = -7.141 (0.837)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.072 (0.051)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.581 (0.228)\n",
      "Parameter sigma = 10.0000 -- J-score = -7.174 (1.449)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.048 (0.025)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.430 (0.210)\n",
      "Parameter sigma = 10.0000 -- J-score = -6.670 (0.654)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.065 (0.030)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.475 (0.070)\n",
      "Parameter sigma = 10.0000 -- J-score = -7.576 (1.109)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.059 (0.032)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.538 (0.167)\n",
      "Parameter sigma = 10.0000 -- J-score = -6.654 (1.041)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.073 (0.035)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.628 (0.195)\n",
      "Parameter sigma = 10.0000 -- J-score = -6.438 (1.403)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.062 (0.073)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.528 (0.202)\n",
      "Parameter sigma = 10.0000 -- J-score = -7.507 (0.595)\n",
      "Fit Estimator...\n",
      "RMSE List of KLIEP: [9.127493468753718, 15.692883015236283, 18.218732103555833, 21.09565257548467, 13.767984740677958, 8.200144807846725, 9.3915395940665, 12.731212949014683, 10.504473264072526, 14.12615457318217, 15.44520577984452, 12.022331368672624, 10.727987141225451, 6.5115014066351, 26.58179802798826, 31.550603246331985, 26.607504169005857, 33.33815540541994, 28.19922611846967, 25.180435729935155]\n",
      "R^2 List of KLIEP: [0.6531592991461642, 0.7254015597833461, 0.7854286941175819, 0.725744692227366, 0.7653570153638146, 0.7324815517153864, 0.6147531311060808, 0.3520966957654744, 0.036059995415357295, 0.7018912943705412, 0.5832715431775459, 0.8524836349266519, 0.7512170651211949, 0.8646573247313055, 0.3022576003224445, 0.21565873357595694, 0.6568227004354389, 0.1014315369541677, 0.6359464690839852, 0.2984041270994722]\n",
      "\n",
      "\n",
      "RMSE of KLIEP: 17.45105097427098 8.347628006003205\n",
      "R^2 of KLIEP: 0.5677262332219638 0.2534240741545759\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### KLIEP Concrete #######################################\n",
    "\n",
    "from adapt.instance_based import KLIEP\n",
    "\n",
    "\n",
    "print(\"KLIEP\")\n",
    "\n",
    "r2scorelist_KLIEP_concrete = []\n",
    "rmselist_KLIEP_concrete = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "\n",
    "for train_idx, test_idx in kf.split(concrete_tgt_df):\n",
    "        \n",
    "    concrete_train_df_X = concrete_tgt_df.iloc[train_idx].loc[:, features_concrete]\n",
    "    concrete_test_df_X = concrete_tgt_df.iloc[test_idx][features_concrete]\n",
    "    concrete_train_df_y = concrete_tgt_df.iloc[train_idx].loc[:,target_concrete]\n",
    "    concrete_test_df_y = concrete_tgt_df.loc[test_idx][target_concrete]\n",
    "        \n",
    "    \n",
    "    concrete_np_train_X = concrete_train_df_X.to_numpy()\n",
    "    concrete_np_train_y = concrete_train_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_source_X = concrete_source_df_X.to_numpy()\n",
    "    concrete_np_source_y = concrete_source_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "    concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "    concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "    \n",
    "    src_size_concrete = len(concrete_source_df_y)\n",
    "    tgt_size_concrete = len(concrete_train_df_y)\n",
    "    \n",
    "    src_idx = np.arange(start = 0, stop = (src_size_concrete - 1), step=1)\n",
    "    tgt_idx = np.arange(start = 0, stop = (tgt_size_concrete - 1), step=1)\n",
    "    \n",
    "    model_KLIEP_concrete = KLIEP(DecisionTreeRegressor(max_depth = 6), sigmas = [0.1, 1, 10])\n",
    "    model_KLIEP_concrete.fit(concrete_np_source_X[src_idx], concrete_np_source_y[src_idx], concrete_np_train_X[tgt_idx], concrete_np_train_y[tgt_idx])\n",
    "\n",
    "    y_pred_KLIEP_concrete = model_KLIEP_concrete.predict(concrete_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_KLIEP_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_KLIEP_concrete))\n",
    "    rmselist_KLIEP_concrete.append(mse_KLIEP_concrete)\n",
    "\n",
    "    r2_score_KLIEP_concrete = pearsonr(concrete_np_test_y_list, y_pred_KLIEP_concrete)\n",
    "    r2_score_KLIEP_concrete = (r2_score_KLIEP_concrete[0])**2\n",
    "    r2scorelist_KLIEP_concrete.append(r2_score_KLIEP_concrete)\n",
    "\n",
    "print(\"RMSE List of KLIEP:\", rmselist_KLIEP_concrete)\n",
    "print(\"R^2 List of KLIEP:\", r2scorelist_KLIEP_concrete)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of KLIEP:\", statistics.mean(rmselist_KLIEP_concrete), statistics.stdev(rmselist_KLIEP_concrete))\n",
    "print(\"R^2 of KLIEP:\", statistics.mean(r2scorelist_KLIEP_concrete), statistics.stdev(r2scorelist_KLIEP_concrete))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWKRR\n",
      "-------------------------------------------\n",
      "RMSE List of IWKRR: [20.07003732832034, 3.988114324353895, 9.779637685989034, 6.23869987191788, 6.6708341206436925, 10.404389117810204, 10.01714410091622, 6.2486948615174525, 5.816797936313644, 4.167496310679201, 5.496034620668809, 4.599772013897692, 4.215502931187524, 6.197911781314202, 5.782198697525159, 6.537777155464826, 4.997241717259456, 6.954448071017532, 4.324018448449184, 5.235736044224286]\n",
      "R^2 List of IWKRR: [0.25940604586146426, 0.8634674259621745, 0.4078417229450757, 0.8678351774797147, 0.813959201040746, 0.8081553562033738, 0.26040046992884786, 0.7897785735283335, 0.6391646117275991, 0.9448060333675046, 0.7918442547639006, 0.881700317788597, 0.8911831525739363, 0.8252633935480108, 0.8009856959858908, 0.5011643393353158, 0.6709018792732043, 0.3131666540787474, 0.8128299855240224, 0.7429707714336812]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 6.887124356973511 3.635645457898324\n",
      "Mean, STDev of R^2: 0.694341253117507 0.22145955044136847\n"
     ]
    }
   ],
   "source": [
    "#################################### Instance_KRR Concrete ################################################################\n",
    "from IW_KRR import InstanceKRR\n",
    "\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 20\n",
    "\n",
    "r2scorelist_IWKRR_concrete = []\n",
    "rmselist_IWKRR_concrete = []\n",
    "\n",
    "print(\"IWKRR\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(concrete_tgt_df):\n",
    "        \n",
    "    concrete_train_df_X = concrete_tgt_df.iloc[train_idx].loc[:, features_concrete]\n",
    "    concrete_test_df_X = concrete_tgt_df.iloc[test_idx][features_concrete]\n",
    "    concrete_train_df_y = concrete_tgt_df.iloc[train_idx].loc[:,target_concrete]\n",
    "    concrete_test_df_y = concrete_tgt_df.loc[test_idx][target_concrete]\n",
    "    \n",
    "    concrete_np_tgt_X = concrete_train_df_X.to_numpy()\n",
    "    concrete_np_tgt_y = concrete_train_df_y.to_numpy()\n",
    "\n",
    "        \n",
    "    concrete_X_df = pd.concat([concrete_source_df_X, concrete_train_df_X], ignore_index=True)\n",
    "    concrete_y_df = pd.concat([concrete_source_df_y, concrete_train_df_y], ignore_index=True)\n",
    "\n",
    "    concrete_np_train_X = concrete_X_df.to_numpy()\n",
    "    concrete_np_train_y = concrete_y_df.to_numpy()\n",
    "\n",
    "    concrete_np_test_X = concrete_test_df_X.to_numpy()\n",
    "    concrete_np_test_y = concrete_test_df_y.to_numpy()\n",
    "\n",
    "    concrete_np_train_y_list = concrete_np_train_y.ravel()\n",
    "    concrete_np_test_y_list = concrete_np_test_y.ravel()\n",
    "    \n",
    "    sample_size = [len(concrete_source_df_X), len(concrete_train_df_X)]\n",
    "\n",
    "    model_IWKRR_concrete = InstanceKRR(lmbd = 0.5, kernel = 'rbf', gamma = None, degree = 3, coef0 = 1, kernel_params = None)\n",
    "    model_IWKRR_concrete.fit(concrete_np_train_X, concrete_np_train_y_list)\n",
    "    model_IWKRR_concrete.Solve_alpha(concrete_np_tgt_X,concrete_np_tgt_y)\n",
    "    \n",
    "    y_pred_IWKRR_concrete = model_IWKRR_concrete.predict(concrete_np_test_X)\n",
    "    y_pred_IWKRR_concrete = [item for sublist in y_pred_IWKRR_concrete for item in sublist]\n",
    "\n",
    "\n",
    "    mse_IWKRR_concrete = sqrt(mean_squared_error(concrete_np_test_y, y_pred_IWKRR_concrete))\n",
    "    rmselist_IWKRR_concrete.append(mse_IWKRR_concrete)\n",
    "        \n",
    "    r2_score_IWKRR_concrete = pearsonr(concrete_np_test_y_list, y_pred_IWKRR_concrete)\n",
    "    r2_score_IWKRR_concrete = (r2_score_IWKRR_concrete[0])**2\n",
    "    r2scorelist_IWKRR_concrete.append(r2_score_IWKRR_concrete)\n",
    "\n",
    "\n",
    "print(\"RMSE List of IWKRR:\", rmselist_IWKRR_concrete)\n",
    "print(\"R^2 List of IWKRR:\", r2scorelist_IWKRR_concrete)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_IWKRR_concrete), statistics.stdev(rmselist_IWKRR_concrete))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_IWKRR_concrete), statistics.stdev(r2scorelist_IWKRR_concrete))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IW_KRR import InstanceKRR\n",
    "    \n",
    "#============================\n",
    "rng = np.random.RandomState(0)\n",
    "# Generate sample data\n",
    "X = 15 * rng.rand(100, 1)\n",
    "y = np.sin(X).ravel()\n",
    "y += 2 * (0.5 - rng.rand(X.shape[0]))\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "Xa = 15 * rng.rand(25, 1)\n",
    "ya = np.sin(Xa-1).ravel()\n",
    "ya += (0.5 - rng.rand(Xa.shape[0])) \n",
    "\n",
    "rng = np.random.RandomState(2)\n",
    "Xt = 15 * rng.rand(50, 1)\n",
    "yt = np.sin(Xt-1).ravel()\n",
    "\n",
    "X_plot = np.linspace(0, 20, 10000)[:, None]\n",
    "\n",
    "       \n",
    "krr = InstanceKRR(lmbd = 0.5)\n",
    "krr.fit(X,y)\n",
    "yhat = krr.kRR_predict(X_plot)\n",
    "\n",
    "krr.Solve_alpha(Xa,ya)\n",
    "y_prd = krr.predict(X_plot)\n",
    "\n",
    "\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "lw = 2\n",
    "plt.scatter(X, np.array(y), c='k', label='data w\\ noise')\n",
    "plt.plot(X_plot, np.array(yhat), c='g', lw = 5, label='KRR')\n",
    "\n",
    "plt.scatter(Xa, ya, c = 'r', label = \"Auxilary data\")\n",
    "plt.plot(X_plot, y_prd, c = 'r', lw = 5, label = \"Instance weighted KRR\")\n",
    "plt.plot(X_plot, np.sin(X_plot), color='navy', lw=lw, label='True value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from adapt.instance_based import KLIEP\n",
    "\n",
    "np.random.seed(0)\n",
    "Xs = np.random.randn(50) * 0.1\n",
    "Xs = np.concatenate((Xs, Xs + 1.))\n",
    "Xt = np.random.randn(100) * 0.1\n",
    "ys = np.array([-0.2 * x if x<0.5 else 1. for x in Xs])\n",
    "yt = -0.2 * Xt\n",
    "\n",
    "print(np.shape(Xs))\n",
    "print(np.shape(ys))\n",
    "print(np.shape(Xt))\n",
    "print(np.shape(yt))\n",
    "print(np.shape(Xs.reshape(-1,1)))\n",
    "\n",
    "# kliep = KLIEP(sigmas = [0.1, 1, 10], random_state=0)\n",
    "# kliep.fit_estimator(Xs.reshape(-1,1), ys)\n",
    "# np.abs(kliep.predict(Xt.reshape(-1,1)).ravel() - yt).mean()\n",
    "# kliep.fit(Xs.reshape(-1,1), ys, Xt.reshape(-1,1))\n",
    "# np.abs(kliep.predict(Xt.reshape(-1,1)).ravel() - yt).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "np.random.seed(0)\n",
    "Xs = np.random.randn(50) * 0.1\n",
    "Xs = np.concatenate((Xs, Xs + 1.))\n",
    "Xt = np.random.randn(100) * 0.1\n",
    "ys = np.array([-0.2 * x if x<0.5 else 1. for x in Xs])\n",
    "yt = -0.2 * Xt\n",
    "\n",
    "kmm = KMM(random_state=0)\n",
    "kmm.fit_estimator(Xs.reshape(-1,1), ys)\n",
    "np.abs(kmm.predict(Xt.reshape(-1,1)).ravel() - yt).mean()\n",
    "kmm.fit(Xs.reshape(-1,1), ys, Xt.reshape(-1,1))\n",
    "np.abs(kmm.predict(Xt.reshape(-1,1)).ravel() - yt).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06642893536867998 0.9477686137441723\n",
      "1.803370278742918 0.08809539363436718\n",
      "-0.6402691951701012 0.5300643497257027\n",
      "\n",
      "\n",
      "0.543419163483719 0.5935081302926962\n",
      "-1.064876041637561 0.30100883616380025\n",
      "1.3293754446871224 0.20032802775973285\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats_StAd_rmse, pval_StAd_rmse = stats.ttest_ind(rmselist_stradaboost_concrete, rmselist_AdaTL_concrete)\n",
    "print(stats_StAd_rmse, pval_StAd_rmse)\n",
    "\n",
    "stats_StGb_rmse, pval_StGb_rmse = stats.ttest_ind(rmselist_stradaboost_concrete, rmselist_GBRTL_concrete)\n",
    "print(stats_StGb_rmse, pval_StGb_rmse)\n",
    "\n",
    "stats_StTr_rmse, pval_StTr_rmse = stats.ttest_ind(rmselist_stradaboost_concrete, rmselist_TwoTrAda_concrete)\n",
    "print(stats_StTr_rmse, pval_StTr_rmse)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "stats_StAd_r2, pval_StAd_r2 = stats.ttest_ind(r2scorelist_stradaboost_concrete, r2scorelist_AdaTL_concrete)\n",
    "print(stats_StAd_r2, pval_StAd_r2)\n",
    "\n",
    "stats_StGb_r2, pval_StGb_r2 = stats.ttest_ind(r2scorelist_stradaboost_concrete, r2scorelist_GBRTL_concrete)\n",
    "print(stats_StGb_r2, pval_StGb_r2)\n",
    "\n",
    "stats_StTr_r2, pval_StTr_r2 = stats.ttest_ind(r2scorelist_stradaboost_concrete, r2scorelist_TwoTrAda_concrete)\n",
    "print(stats_StTr_r2, pval_StTr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2664013235666798 0.7959330728063094\n",
      "2.3414918477916933 0.04391284579630366\n",
      "-0.745171561376906 0.47517702097403447\n",
      "\n",
      "\n",
      "2.137024794237644 0.06131719383991011\n",
      "-2.2358256739080944 0.052197892656036644\n",
      "2.702336607860335 0.024300531692972208\n"
     ]
    }
   ],
   "source": [
    "#### Dependent(paired) t-test\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "\n",
    "stats_StAd_rmse, pval_StAd_rmse = stats.ttest_rel(rmselist_stradaboost_concrete, rmselist_AdaTL_concrete)\n",
    "print(stats_StAd_rmse, pval_StAd_rmse)\n",
    "\n",
    "stats_StGb_rmse, pval_StGb_rmse = stats.ttest_rel(rmselist_stradaboost_concrete, rmselist_GBRTL_concrete)\n",
    "print(stats_StGb_rmse, pval_StGb_rmse)\n",
    "\n",
    "stats_StTr_rmse, pval_StTr_rmse = stats.ttest_rel(rmselist_stradaboost_concrete, rmselist_TwoTrAda_concrete)\n",
    "print(stats_StTr_rmse, pval_StTr_rmse)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "stats_StAd_r2, pval_StAd_r2 = stats.ttest_rel(r2scorelist_stradaboost_concrete, r2scorelist_AdaTL_concrete)\n",
    "print(stats_StAd_r2, pval_StAd_r2)\n",
    "\n",
    "stats_StGb_r2, pval_StGb_r2 = stats.ttest_rel(r2scorelist_stradaboost_concrete, r2scorelist_GBRTL_concrete)\n",
    "print(stats_StGb_r2, pval_StGb_r2)\n",
    "\n",
    "stats_StTr_r2, pval_StTr_r2 = stats.ttest_rel(r2scorelist_stradaboost_concrete, r2scorelist_TwoTrAda_concrete)\n",
    "print(stats_StTr_r2, pval_StTr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing Data\n",
      "(506, 14)\n",
      "Target Set:  (155, 13)\n",
      "Source Set 1:  (186, 13)\n",
      "Source Set 2:  (165, 13)\n"
     ]
    }
   ],
   "source": [
    "################################### Housing ################################################################\n",
    "## 'nox' found to be correlated at 0.4 :: [0.385 - 0.871] :: 50\n",
    "#################################################################################################################################\n",
    "HousingData_df = pd.read_csv('UCI_regression/BostonHousing/BostonHousing.csv') \n",
    "print(\"Housing Data\")\n",
    "print(HousingData_df.shape)\n",
    "\n",
    "drop_col_housing = ['nox']\n",
    "housing_tgt_df = HousingData_df.loc[(HousingData_df['nox'] <= 0.475)]\n",
    "housing_tgt_df = housing_tgt_df.drop(drop_col_housing, axis = 1)\n",
    "housing_tgt_df = housing_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",housing_tgt_df.shape)\n",
    "\n",
    "\n",
    "housing_source1_df = HousingData_df.loc[(HousingData_df['nox'] > 0.475) & (HousingData_df['nox'] <= 0.600)]\n",
    "housing_source1_df = housing_source1_df.drop(drop_col_housing, axis = 1)\n",
    "housing_source1_df = housing_source1_df.reset_index(drop=True)\n",
    "print(\"Source Set 1: \",housing_source1_df.shape)\n",
    "\n",
    "\n",
    "housing_source2_df = HousingData_df.loc[(HousingData_df['nox'] > 0.600)]\n",
    "housing_source2_df = housing_source2_df.drop(drop_col_housing, axis = 1)\n",
    "housing_source2_df = housing_source2_df.reset_index(drop=True)\n",
    "print(\"Source Set 2: \",housing_source2_df.shape)\n",
    "\n",
    "################################# Standardization ############################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing_cols = housing_tgt_df.columns.difference(['medv'])\n",
    "\n",
    "ss = StandardScaler()\n",
    "housing_tgt_df[housing_cols] = ss.fit_transform(housing_tgt_df[housing_cols])\n",
    "housing_source1_df[housing_cols] = ss.fit_transform(housing_source1_df[housing_cols])\n",
    "housing_source2_df[housing_cols] = ss.fit_transform(housing_source2_df[housing_cols])\n",
    "\n",
    "\n",
    "############################ Concatenating the source datasets ############################\n",
    "housing_source_df = pd.concat([housing_source1_df, housing_source2_df], ignore_index = True)\n",
    "housing_source_df = housing_source_df.reset_index(drop = True)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_housing = ['medv']\n",
    "\n",
    "housing_source_df_y = housing_source_df[target_housing]\n",
    "housing_source_df_X = housing_source_df.drop(target_housing, axis = 1)\n",
    "\n",
    "features_housing = housing_source_df_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specification requirement complete!\n",
      "Two-Stage TrAdaboost.R2\n",
      "-------------------------------------------\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Binary search has not converged. Set value to the current best.\n",
      "Mean, STDev of RMSE: 3.775719346926139 1.7425547256522251\n",
      "Mean, STDev of R^2: 0.6920150510406161 0.13655146445255306\n",
      "\n",
      "\n",
      "RMSE List TrAdaboost.R2: [5.025387687737488, 2.820080520506125, 1.6118240941085065, 5.2742895362755, 6.096489452553898, 2.301659822903144, 6.437286541364474, 2.6932904849582098, 2.7623825495150305, 2.734502779339012]\n",
      "R^2 List TrAdaboost.R2: [0.7243684192351424, 0.7178474835189516, 0.7073885450107534, 0.645728130856852, 0.5034121557770581, 0.6888049023616531, 0.46840898896650573, 0.942099910513274, 0.7059558865786913, 0.8161360875872793]\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStagetrAdaBoostR2 Housing #######################################\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "print(\"Specification requirement complete!\")\n",
    "\n",
    "###########################################################################################################################\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_TwoTrAda_housing = []\n",
    "rmselist_TwoTrAda_housing = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(housing_tgt_df):\n",
    "        \n",
    "    housing_train_df_X = housing_tgt_df.iloc[train_idx].loc[:, features_housing]\n",
    "    housing_test_df_X = housing_tgt_df.iloc[test_idx][features_housing]\n",
    "    housing_train_df_y = housing_tgt_df.iloc[train_idx].loc[:,target_housing]\n",
    "    housing_test_df_y = housing_tgt_df.loc[test_idx][target_housing]\n",
    "    \n",
    "    housing_X_df = pd.concat([housing_source_df_X, housing_train_df_X], ignore_index = True)\n",
    "    housing_y_df = pd.concat([housing_source_df_y, housing_train_df_y], ignore_index = True)\n",
    "\n",
    "    housing_np_train_X = housing_X_df.to_numpy()\n",
    "    housing_np_train_y = housing_y_df.to_numpy()\n",
    "\n",
    "    housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "    housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "    housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "    housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "\n",
    "    src_size_housing = len(housing_source_df_y)\n",
    "    tgt_size_housing = len(housing_train_df_y)\n",
    "    \n",
    "    src_idx_housing = np.arange(start = 0, stop = (src_size_housing - 1), step=1)\n",
    "    tgt_idx_housing = np.arange(start = src_size_housing, stop = ((src_size_housing + tgt_size_housing)-1), step = 1)\n",
    "\n",
    "\n",
    "    model_TwoTrAda_housing = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100) #, cv = 10) \n",
    "    model_TwoTrAda_housing.fit(housing_np_train_X, housing_np_train_y_list, src_idx_housing, tgt_idx_housing)\n",
    "\n",
    "    y_pred_TwoTrAda_housing = model_TwoTrAda_housing.predict(housing_np_test_X)\n",
    "\n",
    "    mse_TwoTrAda_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_TwoTrAda_housing))\n",
    "    rmselist_TwoTrAda_housing.append(mse_TwoTrAda_housing)\n",
    "        \n",
    "    r2_score_TwoTrAda_housing = pearsonr(housing_np_test_y_list, y_pred_TwoTrAda_housing)\n",
    "    r2_score_TwoTrAda_housing = (r2_score_TwoTrAda_housing[0])**2\n",
    "    r2scorelist_TwoTrAda_housing.append(r2_score_TwoTrAda_housing)\n",
    "\n",
    "print(\"RMSE List TrAdaboost.R2:\", rmselist_TwoTrAda_housing)\n",
    "print(\"R^2 List TrAdaboost.R2:\", r2scorelist_TwoTrAda_housing)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_TwoTrAda_housing), statistics.stdev(rmselist_TwoTrAda_housing))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_TwoTrAda_housing), statistics.stdev(r2scorelist_TwoTrAda_housing))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STrAdaboost.R2\n",
      "-------------------------------------------\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "RMSE of STrAdaboost.R2: [2.643518097047088, 2.0446110978325023, 1.3264814902392026, 3.1412323088120258, 6.055358754659789, 2.107677222789961, 7.369388206228197, 2.616042210901775, 3.104185474452117, 1.7473932471670033]\n",
      "R^2 of STrAdaboost.R2: [0.929416103939321, 0.9273003801642, 0.7701803567088483, 0.92194781914337, 0.7690628160942707, 0.7433110429384416, 0.5842195424875491, 0.953111794488, 0.6663405802785274, 0.9329793790565483]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 3.215588811012966 1.9535149217076844\n",
      "Mean, STDev of R^2: 0.8197869815299077 0.13103124329668592\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Housing ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "r2scorelist_stradaboost_housing = []\n",
    "rmselist_stradaboost_housing = []\n",
    "\n",
    "print(\"STrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "for train_idx, test_idx in kf.split(housing_tgt_df):\n",
    "        \n",
    "    housing_train_df_X = housing_tgt_df.iloc[train_idx].loc[:, features_housing]\n",
    "    housing_test_df_X = housing_tgt_df.iloc[test_idx][features_housing]\n",
    "    housing_train_df_y = housing_tgt_df.iloc[train_idx].loc[:,target_housing]\n",
    "    housing_test_df_y = housing_tgt_df.loc[test_idx][target_housing]\n",
    "    \n",
    "    housing_X_df = pd.concat([housing_source_df_X, housing_train_df_X], ignore_index = True)\n",
    "    housing_y_df = pd.concat([housing_source_df_y, housing_train_df_y], ignore_index = True)\n",
    "\n",
    "    housing_np_train_X = housing_X_df.to_numpy()\n",
    "    housing_np_train_y = housing_y_df.to_numpy()\n",
    "\n",
    "    housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "    housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "    housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "    housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "    \n",
    "    sample_size = [len(housing_source_df_X), len(housing_train_df_X)]\n",
    "\n",
    "\n",
    "    model_stradaboost_housing = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth = 6),\n",
    "                        n_estimators = n_estimators, sample_size = sample_size,\n",
    "                        steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "    model_stradaboost_housing.fit(housing_np_train_X, housing_np_train_y_list)\n",
    "    y_pred_stradaboost_housing = model_stradaboost_housing.predict(housing_np_test_X)\n",
    "\n",
    "\n",
    "    mse_stradaboost_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_stradaboost_housing))\n",
    "    rmselist_stradaboost_housing.append(mse_stradaboost_housing)\n",
    "        \n",
    "    r2_score_stradaboost_housing = pearsonr(housing_np_test_y_list, y_pred_stradaboost_housing)\n",
    "    r2_score_stradaboost_housing = (r2_score_stradaboost_housing[0])**2\n",
    "    r2scorelist_stradaboost_housing.append(r2_score_stradaboost_housing)\n",
    "\n",
    "print(\"RMSE of STrAdaboost.R2:\", rmselist_stradaboost_housing)\n",
    "print(\"R^2 of STrAdaboost.R2:\", r2scorelist_stradaboost_housing)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_stradaboost_housing), statistics.stdev(rmselist_stradaboost_housing))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_stradaboost_housing), statistics.stdev(r2scorelist_stradaboost_housing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE List of Adaboost.R2: [3.08093208818374, 2.1387404887311665, 1.4568218936233506, 3.1149603921322124, 5.649134873022684, 2.019204145681526, 7.443647763089025, 2.773863640063722, 2.891185148078168, 1.9126907919331761]\n",
      "R^2 List of AdaboostR2: [0.8876367480075871, 0.9105254644040658, 0.7649082994209835, 0.9192629947440659, 0.8606479246265066, 0.8178371107386858, 0.5822544847648489, 0.9477779258828463, 0.7337170468465634, 0.9510545290145113]\n",
      "\n",
      "\n",
      "Mean, Stdev of RMSE: 3.248118122453877 1.8707814067465698\n",
      "Mean, Stdev of R^2: 0.8375622528450665 0.11628537575902734\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning Housing #####################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_AdaTL_housing = []\n",
    "rmselist_AdaTL_housing = []\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "for train_idx, test_idx in kf.split(housing_tgt_df):\n",
    "        \n",
    "    housing_train_df_X = housing_tgt_df.iloc[train_idx].loc[:, features_housing]\n",
    "    housing_test_df_X = housing_tgt_df.iloc[test_idx][features_housing]\n",
    "    housing_train_df_y = housing_tgt_df.iloc[train_idx].loc[:,target_housing]\n",
    "    housing_test_df_y = housing_tgt_df.loc[test_idx][target_housing]\n",
    "    \n",
    "    housing_X_df = pd.concat([housing_source_df_X, housing_train_df_X], ignore_index = True)\n",
    "    housing_y_df = pd.concat([housing_source_df_y, housing_train_df_y], ignore_index = True)\n",
    "\n",
    "    housing_np_train_X = housing_X_df.to_numpy()\n",
    "    housing_np_train_y = housing_y_df.to_numpy()\n",
    "\n",
    "    housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "    housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "    housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "    housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "\n",
    "\n",
    "    model_AdaTL_housing = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_AdaTL_housing.fit(housing_np_train_X, housing_np_train_y_list)\n",
    "\n",
    "    y_pred_AdaTL_housing = model_AdaTL_housing.predict(housing_np_test_X)\n",
    "\n",
    "    mse_AdaTL_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_AdaTL_housing))\n",
    "    rmselist_AdaTL_housing.append(mse_AdaTL_housing)\n",
    "        \n",
    "    r2_score_AdaTL_housing = pearsonr(housing_np_test_y_list, y_pred_AdaTL_housing)\n",
    "    r2_score_AdaTL_housing = (r2_score_AdaTL_housing[0])**2\n",
    "    r2scorelist_AdaTL_housing.append(r2_score_AdaTL_housing)\n",
    "\n",
    "print(\"RMSE List of Adaboost.R2:\", rmselist_AdaTL_housing)\n",
    "print(\"R^2 List of AdaboostR2:\", r2scorelist_AdaTL_housing)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, Stdev of RMSE:\", statistics.mean(rmselist_AdaTL_housing), statistics.stdev(rmselist_AdaTL_housing))\n",
    "print(\"Mean, Stdev of R^2:\", statistics.mean(r2scorelist_AdaTL_housing), statistics.stdev(r2scorelist_AdaTL_housing))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of GBRTL: [3.2002238942191252, 2.410123507159773, 2.0796830343326946, 1.9183806855293195, 1.2964843885771486, 1.3847024597606314, 1.9859445723197668, 3.239165729889791, 4.849700620126591, 6.893720392358554, 1.2454158407456728, 6.811744835440854, 4.150265760834754, 4.480156585180506, 2.4656947427360456, 2.542496429628167, 2.634456217477316, 1.4216845280443506, 1.615131473191891, 1.8397452247446722]\n",
      "R^2 List of GBRTL: [0.6457829656897999, 0.835314875976937, 0.8661669337923578, 0.8723578018974302, 0.763981693575525, 0.7707173457901498, 0.2064254041578625, 0.9403030638965592, 0.8431105233430062, 0.6434496456022448, 0.8169108464325716, 0.17391533264923068, 0.8719305225167314, 0.7751525210238152, 0.9558589263767592, 0.769019760499597, 0.7074283921909684, 0.9485767404177595, 0.9835511091717741, 0.8700048641978019]\n",
      "\n",
      "\n",
      "Mean, Stdev of RMSE: 2.9232460461148815 1.7009548396131993\n",
      "Mean, Stdev of R^2: 0.7629979634599441 0.21768461179218776\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "################################## Gradient Boosting Regression Transfer Learning Housing #######################################\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_housing = []\n",
    "rmselist_GBRTL_housing = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(housing_tgt_df):\n",
    "        \n",
    "    housing_train_df_X = housing_tgt_df.iloc[train_idx].loc[:, features_housing]\n",
    "    housing_test_df_X = housing_tgt_df.iloc[test_idx][features_housing]\n",
    "    housing_train_df_y = housing_tgt_df.iloc[train_idx].loc[:,target_housing]\n",
    "    housing_test_df_y = housing_tgt_df.loc[test_idx][target_housing]\n",
    "    \n",
    "    housing_X_df = pd.concat([housing_source_df_X, housing_train_df_X], ignore_index = True)\n",
    "    housing_y_df = pd.concat([housing_source_df_y, housing_train_df_y], ignore_index = True)\n",
    "\n",
    "    housing_np_train_X = housing_X_df.to_numpy()\n",
    "    housing_np_train_y = housing_y_df.to_numpy()\n",
    "\n",
    "    housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "    housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "    housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "    housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "\n",
    "    model_GBRTL_housing = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100) #, subsample=0.5)\n",
    "    model_GBRTL_housing.fit(housing_np_train_X, housing_np_train_y_list)\n",
    "\n",
    "    y_pred_GBRTL_housing = model_GBRTL_housing.predict(housing_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBRTL_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_GBRTL_housing))\n",
    "    rmselist_GBRTL_housing.append(mse_GBRTL_housing)\n",
    "        \n",
    "    r2_score_GBRTL_housing = pearsonr(housing_np_test_y_list, y_pred_GBRTL_housing)\n",
    "    r2_score_GBRTL_housing = (r2_score_GBRTL_housing[0])**2\n",
    "    r2scorelist_GBRTL_housing.append(r2_score_GBRTL_housing)\n",
    "\n",
    "print(\"RMSE List of GBRTL:\", rmselist_GBRTL_housing)\n",
    "print(\"R^2 List of GBRTL:\", r2scorelist_GBRTL_housing)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Mean, Stdev of RMSE:\", statistics.mean(rmselist_GBRTL_housing), statistics.stdev(rmselist_GBRTL_housing))\n",
    "print(\"Mean, Stdev of R^2:\", statistics.mean(r2scorelist_GBRTL_housing), statistics.stdev(r2scorelist_GBRTL_housing))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Adaboost.R2\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of Adaboost.R2: [2.76372249076749, 2.4995357931053293, 1.8437763872588113, 1.413670654683692, 1.2381669528361698, 1.2195771486617735, 1.6621481765708483, 2.9571963471463487, 3.871185604343538, 2.4522453964172244, 1.9218766496419573, 2.605526831930049, 5.147678447880924, 3.5264182459914135, 1.3381775216605296, 2.724961057189721, 3.078334422195404, 2.3955474482371595, 2.5230684077432883, 3.080083551227089]\n",
      "R^2 List of AdaboostR2: [0.6884043235888353, 0.7859726919188234, 0.8931793035010221, 0.9503064627037221, 0.6928970707225619, 0.8611049133716916, 0.5851320648229225, 0.8917538368879923, 0.7583574052312779, 0.9323758255103389, 0.7655502629689449, 0.9258575205492496, 0.6516808417877064, 0.8962925538110625, 0.99468029689039, 0.7399570121167331, 0.8321595951694181, 0.8497331641697172, 0.9921954085796764, 0.7442760209179091]\n",
      "\n",
      "\n",
      "RMSE of Adaboost.R2: 2.513144876774438 0.9785580695019643\n",
      "R^2 of AdaboostR2: 0.8215933287609998 0.11630355442197252\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "###################################### Regular AdaBoostR2 Housing ##############################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "print(\"Regular Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_Ada_housing = []\n",
    "rmselist_Ada_housing = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(housing_tgt_df):\n",
    "        \n",
    "    housing_train_df_X = housing_tgt_df.iloc[train_idx].loc[:, features_housing]\n",
    "    housing_test_df_X = housing_tgt_df.iloc[test_idx][features_housing]\n",
    "    housing_train_df_y = housing_tgt_df.iloc[train_idx].loc[:,target_housing]\n",
    "    housing_test_df_y = housing_tgt_df.loc[test_idx][target_housing]\n",
    "    \n",
    "    housing_np_train_X = housing_X_df.to_numpy()\n",
    "    housing_np_train_y = housing_y_df.to_numpy()\n",
    "\n",
    "    housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "    housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "    housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "    housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "\n",
    "    model_Ada_housing = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_Ada_housing.fit(housing_train_df_X, housing_train_df_y)\n",
    "\n",
    "    y_pred_Ada_housing = model_Ada_housing.predict(housing_np_test_X)\n",
    "\n",
    "    mse_Ada_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_Ada_housing))\n",
    "    rmselist_Ada_housing.append(mse_Ada_housing)\n",
    "        \n",
    "    r2_score_Ada_housing = pearsonr(housing_np_test_y_list, y_pred_Ada_housing)\n",
    "    r2_score_Ada_housing = (r2_score_Ada_housing[0])**2\n",
    "    r2scorelist_Ada_housing.append(r2_score_Ada_housing)\n",
    "\n",
    "print(\"RMSE List of Adaboost.R2:\", rmselist_Ada_housing)\n",
    "print(\"R^2 List of AdaboostR2:\", r2scorelist_Ada_housing)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of Adaboost.R2:\", statistics.mean(rmselist_Ada_housing), statistics.stdev(rmselist_Ada_housing))\n",
    "print(\"R^2 of AdaboostR2:\", statistics.mean(r2scorelist_Ada_housing), statistics.stdev(r2scorelist_Ada_housing))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of GBR: [2.9609357147171944, 1.9799132947974447, 1.2849348954085653, 2.1467431926029605, 1.199058300816874, 0.9313947146593611, 1.3073712198748983, 2.5184964175042164, 2.8320290986676167, 2.107307803616224, 2.4253043626454494, 2.0899431828354986, 3.1417774201516755, 3.0574756936240832, 1.0373030292774024, 2.70973694467034, 3.595336392697529, 2.1896197482170088, 2.3567945849649763, 2.5837254573388075]\n",
      "R^2 List of GBR: [0.6930207798390742, 0.9032760963097143, 0.9557441467767738, 0.9558693605022983, 0.7557580047652949, 0.9404464038923338, 0.657312647994583, 0.9442469012525332, 0.836291214431168, 0.9572984272907852, 0.7647663764406228, 0.9086396654977117, 0.8617034029690337, 0.9562458448049314, 0.9915463337565664, 0.7515993562441233, 0.6507092378911823, 0.8712719921188293, 0.9892377451211978, 0.8613123109717782]\n",
      "\n",
      "\n",
      "RMSE of GBR: 2.222760073454406 0.753604835705814\n",
      "R^2 of GBR: 0.8603148124435268 0.11098789523865255\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "############################# Regular Gradient Boosting Regression Housing #######################################\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "print(\"Regular Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBR_housing = []\n",
    "rmselist_GBR_housing = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(housing_tgt_df):\n",
    "        \n",
    "    housing_train_df_X = housing_tgt_df.iloc[train_idx].loc[:, features_housing]\n",
    "    housing_test_df_X = housing_tgt_df.iloc[test_idx][features_housing]\n",
    "    housing_train_df_y = housing_tgt_df.iloc[train_idx].loc[:,target_housing]\n",
    "    housing_test_df_y = housing_tgt_df.loc[test_idx][target_housing]\n",
    "    \n",
    "    housing_np_train_X = housing_X_df.to_numpy()\n",
    "    housing_np_train_y = housing_y_df.to_numpy()\n",
    "\n",
    "    housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "    housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "    housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "    housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "\n",
    "\n",
    "    model_GBR_housing = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100, subsample=0.5)\n",
    "    model_GBR_housing.fit(housing_train_df_X, housing_train_df_y)\n",
    "\n",
    "    y_pred_GBR_housing = model_GBR_housing.predict(housing_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBR_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_GBR_housing))\n",
    "    rmselist_GBR_housing.append(mse_GBR_housing)\n",
    "        \n",
    "    r2_score_GBR_housing = pearsonr(housing_np_test_y_list, y_pred_GBR_housing)\n",
    "    r2_score_GBR_housing = (r2_score_GBR_housing[0])**2\n",
    "    r2scorelist_GBR_housing.append(r2_score_GBR_housing)\n",
    "\n",
    "print(\"RMSE List of GBR:\", rmselist_GBR_housing)\n",
    "print(\"R^2 List of GBR:\", r2scorelist_GBR_housing)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of GBR:\", statistics.mean(rmselist_GBR_housing), statistics.stdev(rmselist_GBR_housing))\n",
    "print(\"R^2 of GBR:\", statistics.mean(r2scorelist_GBR_housing), statistics.stdev(r2scorelist_GBR_housing))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Mean Matching\n",
      "-------------------------------------------\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.3595e+03 -3.0574e+06  5e+07  2e-01  6e-15\n",
      " 1: -3.7469e+03 -7.2771e+05  1e+06  2e-03  3e-13\n",
      " 2: -1.5031e+03 -1.0681e+05  1e+05  1e-05  5e-13\n",
      " 3: -4.1540e+03 -4.2551e+04  4e+04  5e-06  1e-13\n",
      " 4: -1.1889e+04 -5.6735e+04  4e+04  7e-07  2e-14\n",
      " 5: -1.2223e+04 -2.2167e+04  1e+04  2e-07  5e-15\n",
      " 6: -1.2391e+04 -1.6341e+04  4e+03  2e-16  5e-16\n",
      " 7: -1.2539e+04 -1.3650e+04  1e+03  2e-16  5e-16\n",
      " 8: -1.2616e+04 -1.3194e+04  6e+02  2e-16  5e-16\n",
      " 9: -1.2652e+04 -1.2816e+04  2e+02  2e-16  5e-16\n",
      "10: -1.2678e+04 -1.2717e+04  4e+01  2e-16  5e-16\n",
      "11: -1.2685e+04 -1.2698e+04  1e+01  2e-16  5e-16\n",
      "12: -1.2688e+04 -1.2690e+04  2e+00  2e-16  6e-16\n",
      "13: -1.2689e+04 -1.2689e+04  1e-01  2e-16  5e-16\n",
      "14: -1.2689e+04 -1.2689e+04  4e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9138e+03 -3.0574e+06  5e+07  2e-01  7e-15\n",
      " 1: -4.3585e+03 -7.2761e+05  1e+06  2e-03  8e-13\n",
      " 2: -2.3262e+03 -1.0098e+05  1e+05  1e-05  3e-13\n",
      " 3: -4.8806e+03 -4.2692e+04  4e+04  5e-06  1e-13\n",
      " 4: -1.1837e+04 -5.4278e+04  4e+04  2e-06  5e-14\n",
      " 5: -1.2576e+04 -2.1341e+04  9e+03  4e-07  9e-15\n",
      " 6: -1.2880e+04 -1.6207e+04  3e+03  1e-16  5e-16\n",
      " 7: -1.3023e+04 -1.3955e+04  9e+02  2e-16  5e-16\n",
      " 8: -1.3094e+04 -1.3635e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.3125e+04 -1.3303e+04  2e+02  2e-16  4e-16\n",
      "10: -1.3139e+04 -1.3246e+04  1e+02  2e-16  4e-16\n",
      "11: -1.3152e+04 -1.3187e+04  4e+01  2e-16  4e-16\n",
      "12: -1.3158e+04 -1.3165e+04  7e+00  2e-16  5e-16\n",
      "13: -1.3160e+04 -1.3161e+04  1e+00  2e-16  5e-16\n",
      "14: -1.3160e+04 -1.3160e+04  8e-02  2e-16  5e-16\n",
      "15: -1.3160e+04 -1.3160e+04  3e-03  2e-16  6e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.4079e+03 -3.0577e+06  5e+07  2e-01  7e-15\n",
      " 1: -3.7914e+03 -7.2747e+05  1e+06  2e-03  3e-13\n",
      " 2: -1.6170e+03 -1.0457e+05  1e+05  1e-05  2e-13\n",
      " 3: -4.2263e+03 -4.2631e+04  4e+04  5e-06  7e-14\n",
      " 4: -1.1709e+04 -5.5649e+04  4e+04  1e-06  2e-14\n",
      " 5: -1.2236e+04 -2.0054e+04  8e+03  2e-07  3e-15\n",
      " 6: -1.2461e+04 -1.5634e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.2593e+04 -1.3516e+04  9e+02  2e-16  5e-16\n",
      " 8: -1.2663e+04 -1.3173e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.2695e+04 -1.2842e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2713e+04 -1.2781e+04  7e+01  2e-16  5e-16\n",
      "11: -1.2722e+04 -1.2746e+04  2e+01  2e-16  4e-16\n",
      "12: -1.2726e+04 -1.2731e+04  5e+00  2e-16  5e-16\n",
      "13: -1.2727e+04 -1.2728e+04  8e-01  2e-16  5e-16\n",
      "14: -1.2728e+04 -1.2728e+04  2e-02  2e-16  5e-16\n",
      "15: -1.2728e+04 -1.2728e+04  1e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7910e+03 -3.0556e+06  5e+07  2e-01  2e-15\n",
      " 1: -4.2220e+03 -7.2696e+05  1e+06  1e-03  8e-13\n",
      " 2: -2.1853e+03 -9.8477e+04  1e+05  1e-05  4e-13\n",
      " 3: -4.7610e+03 -4.2508e+04  4e+04  5e-06  9e-14\n",
      " 4: -1.1190e+04 -5.2415e+04  4e+04  2e-06  5e-14\n",
      " 5: -1.2355e+04 -1.9422e+04  7e+03  4e-07  8e-15\n",
      " 6: -1.2766e+04 -1.5434e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.2917e+04 -1.3556e+04  6e+02  2e-16  4e-16\n",
      " 8: -1.2988e+04 -1.3203e+04  2e+02  2e-16  5e-16\n",
      " 9: -1.3009e+04 -1.3094e+04  9e+01  2e-16  4e-16\n",
      "10: -1.3021e+04 -1.3049e+04  3e+01  2e-16  5e-16\n",
      "11: -1.3027e+04 -1.3034e+04  7e+00  2e-16  5e-16\n",
      "12: -1.3028e+04 -1.3030e+04  1e+00  2e-16  5e-16\n",
      "13: -1.3029e+04 -1.3029e+04  6e-02  2e-16  5e-16\n",
      "14: -1.3029e+04 -1.3029e+04  1e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.3209e+03 -3.0375e+06  5e+07  2e-01  6e-15\n",
      " 1: -3.7236e+03 -7.2633e+05  1e+06  2e-03  3e-13\n",
      " 2: -1.6126e+03 -1.0101e+05  1e+05  1e-05  2e-13\n",
      " 3: -4.2278e+03 -4.2523e+04  4e+04  5e-06  6e-14\n",
      " 4: -1.1302e+04 -5.4200e+04  4e+04  2e-06  2e-14\n",
      " 5: -1.2115e+04 -2.0487e+04  8e+03  4e-07  5e-15\n",
      " 6: -1.2418e+04 -1.5597e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.2555e+04 -1.3340e+04  8e+02  2e-16  5e-16\n",
      " 8: -1.2626e+04 -1.3070e+04  4e+02  2e-16  5e-16\n",
      " 9: -1.2652e+04 -1.2817e+04  2e+02  2e-16  5e-16\n",
      "10: -1.2671e+04 -1.2728e+04  6e+01  2e-16  5e-16\n",
      "11: -1.2680e+04 -1.2695e+04  1e+01  2e-16  5e-16\n",
      "12: -1.2684e+04 -1.2686e+04  2e+00  2e-16  5e-16\n",
      "13: -1.2685e+04 -1.2685e+04  1e-01  2e-16  5e-16\n",
      "14: -1.2685e+04 -1.2685e+04  7e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.5682e+03 -3.0196e+06  5e+07  2e-01  3e-15\n",
      " 1: -3.9847e+03 -7.2586e+05  1e+06  2e-03  2e-13\n",
      " 2: -1.9570e+03 -9.8813e+04  1e+05  1e-05  1e-13\n",
      " 3: -4.5500e+03 -4.2597e+04  4e+04  5e-06  6e-14\n",
      " 4: -1.1054e+04 -5.2570e+04  4e+04  2e-06  3e-14\n",
      " 5: -1.2248e+04 -1.9760e+04  8e+03  4e-07  5e-15\n",
      " 6: -1.2671e+04 -1.5457e+04  3e+03  1e-16  5e-16\n",
      " 7: -1.2825e+04 -1.3746e+04  9e+02  2e-16  5e-16\n",
      " 8: -1.2900e+04 -1.3339e+04  4e+02  2e-16  5e-16\n",
      " 9: -1.2931e+04 -1.3083e+04  2e+02  2e-16  4e-16\n",
      "10: -1.2943e+04 -1.3039e+04  1e+02  2e-16  4e-16\n",
      "11: -1.2958e+04 -1.2976e+04  2e+01  2e-16  4e-16\n",
      "12: -1.2961e+04 -1.2967e+04  5e+00  2e-16  5e-16\n",
      "13: -1.2963e+04 -1.2964e+04  9e-01  2e-16  5e-16\n",
      "14: -1.2963e+04 -1.2963e+04  1e-01  2e-16  5e-16\n",
      "15: -1.2963e+04 -1.2963e+04  4e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.0820e+03 -3.0429e+06  5e+07  2e-01  4e-15\n",
      " 1: -3.4537e+03 -7.2649e+05  1e+06  2e-03  3e-13\n",
      " 2: -1.2133e+03 -1.0384e+05  1e+05  1e-05  6e-13\n",
      " 3: -3.8959e+03 -4.2339e+04  4e+04  5e-06  3e-13\n",
      " 4: -1.1362e+04 -5.5232e+04  4e+04  1e-06  8e-14\n",
      " 5: -1.1932e+04 -2.1466e+04  1e+04  3e-07  2e-14\n",
      " 6: -1.2171e+04 -1.5794e+04  4e+03  2e-16  5e-16\n",
      " 7: -1.2311e+04 -1.3462e+04  1e+03  2e-16  4e-16\n",
      " 8: -1.2391e+04 -1.3040e+04  6e+02  2e-16  5e-16\n",
      " 9: -1.2427e+04 -1.2614e+04  2e+02  2e-16  5e-16\n",
      "10: -1.2436e+04 -1.2587e+04  2e+02  2e-16  5e-16\n",
      "11: -1.2455e+04 -1.2496e+04  4e+01  2e-16  5e-16\n",
      "12: -1.2463e+04 -1.2475e+04  1e+01  1e-16  5e-16\n",
      "13: -1.2465e+04 -1.2468e+04  3e+00  2e-16  5e-16\n",
      "14: -1.2466e+04 -1.2466e+04  4e-01  1e-16  5e-16\n",
      "15: -1.2466e+04 -1.2466e+04  5e-02  2e-16  5e-16\n",
      "16: -1.2466e+04 -1.2466e+04  1e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8715e+03 -3.0016e+06  5e+07  2e-01  2e-15\n",
      " 1: -4.3801e+03 -7.2630e+05  1e+06  2e-03  4e-13\n",
      " 2: -2.3364e+03 -1.0147e+05  1e+05  1e-05  6e-13\n",
      " 3: -4.8899e+03 -4.2673e+04  4e+04  4e-06  1e-13\n",
      " 4: -1.1893e+04 -5.4435e+04  4e+04  2e-06  5e-14\n",
      " 5: -1.2580e+04 -2.1135e+04  9e+03  3e-07  1e-14\n",
      " 6: -1.2858e+04 -1.6185e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.2997e+04 -1.4013e+04  1e+03  2e-16  5e-16\n",
      " 8: -1.3069e+04 -1.3566e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.3099e+04 -1.3282e+04  2e+02  2e-16  5e-16\n",
      "10: -1.3118e+04 -1.3209e+04  9e+01  2e-16  5e-16\n",
      "11: -1.3131e+04 -1.3153e+04  2e+01  2e-16  5e-16\n",
      "12: -1.3136e+04 -1.3139e+04  4e+00  2e-16  5e-16\n",
      "13: -1.3137e+04 -1.3137e+04  5e-01  2e-16  5e-16\n",
      "14: -1.3137e+04 -1.3137e+04  1e-02  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.5951e+03 -3.0426e+06  5e+07  2e-01  2e-15\n",
      " 1: -4.0688e+03 -7.2758e+05  1e+06  2e-03  3e-13\n",
      " 2: -1.9640e+03 -1.0505e+05  1e+05  1e-05  2e-13\n",
      " 3: -4.5099e+03 -4.2892e+04  4e+04  5e-06  7e-14\n",
      " 4: -1.2005e+04 -5.6039e+04  4e+04  1e-06  2e-14\n",
      " 5: -1.2489e+04 -1.8870e+04  6e+03  2e-07  3e-15\n",
      " 6: -1.2693e+04 -1.5271e+04  3e+03  1e-16  5e-16\n",
      " 7: -1.2797e+04 -1.3720e+04  9e+02  1e-16  5e-16\n",
      " 8: -1.2862e+04 -1.3231e+04  4e+02  2e-16  5e-16\n",
      " 9: -1.2892e+04 -1.3029e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2913e+04 -1.2955e+04  4e+01  2e-16  5e-16\n",
      "11: -1.2921e+04 -1.2930e+04  1e+01  2e-16  5e-16\n",
      "12: -1.2923e+04 -1.2924e+04  9e-01  2e-16  5e-16\n",
      "13: -1.2924e+04 -1.2924e+04  8e-02  2e-16  5e-16\n",
      "14: -1.2924e+04 -1.2924e+04  4e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0932e+03 -3.0274e+06  5e+07  2e-01  4e-15\n",
      " 1: -4.6645e+03 -7.2749e+05  1e+06  2e-03  3e-13\n",
      " 2: -2.6948e+03 -1.0212e+05  1e+05  1e-05  2e-13\n",
      " 3: -5.1559e+03 -4.3066e+04  4e+04  5e-06  9e-14\n",
      " 4: -1.2197e+04 -5.4912e+04  4e+04  2e-06  4e-14\n",
      " 5: -1.2893e+04 -1.7377e+04  4e+03  2e-07  4e-15\n",
      " 6: -1.3167e+04 -1.4797e+04  2e+03  1e-16  5e-16\n",
      " 7: -1.3280e+04 -1.3760e+04  5e+02  2e-16  5e-16\n",
      " 8: -1.3321e+04 -1.3500e+04  2e+02  2e-16  5e-16\n",
      " 9: -1.3336e+04 -1.3461e+04  1e+02  2e-16  4e-16\n",
      "10: -1.3353e+04 -1.3389e+04  4e+01  2e-16  5e-16\n",
      "11: -1.3359e+04 -1.3372e+04  1e+01  2e-16  5e-16\n",
      "12: -1.3363e+04 -1.3364e+04  1e+00  2e-16  5e-16\n",
      "13: -1.3363e+04 -1.3363e+04  1e-01  2e-16  5e-16\n",
      "14: -1.3363e+04 -1.3363e+04  3e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.3441e+03 -3.1531e+06  5e+07  2e-01  3e-15\n",
      " 1: -3.6691e+03 -7.2909e+05  1e+06  2e-03  7e-13\n",
      " 2: -1.5696e+03 -1.0037e+05  1e+05  1e-05  3e-13\n",
      " 3: -4.1851e+03 -4.2552e+04  4e+04  5e-06  1e-13\n",
      " 4: -1.1098e+04 -5.3614e+04  4e+04  2e-06  5e-14\n",
      " 5: -1.2069e+04 -2.0074e+04  8e+03  4e-07  9e-15\n",
      " 6: -1.2426e+04 -1.5566e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.2571e+04 -1.3362e+04  8e+02  2e-16  5e-16\n",
      " 8: -1.2638e+04 -1.2870e+04  2e+02  2e-16  5e-16\n",
      " 9: -1.2663e+04 -1.2786e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2678e+04 -1.2711e+04  3e+01  2e-16  5e-16\n",
      "11: -1.2685e+04 -1.2693e+04  8e+00  2e-16  5e-16\n",
      "12: -1.2687e+04 -1.2688e+04  7e-01  2e-16  5e-16\n",
      "13: -1.2687e+04 -1.2687e+04  1e-01  2e-16  5e-16\n",
      "14: -1.2687e+04 -1.2687e+04  4e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9646e+03 -3.0657e+06  5e+07  2e-01  2e-15\n",
      " 1: -4.4296e+03 -7.2734e+05  1e+06  1e-03  3e-13\n",
      " 2: -2.4869e+03 -9.7263e+04  1e+05  1e-05  3e-13\n",
      " 3: -5.0059e+03 -4.2765e+04  4e+04  5e-06  1e-13\n",
      " 4: -1.1116e+04 -5.1832e+04  4e+04  3e-06  8e-14\n",
      " 5: -1.2522e+04 -1.9609e+04  7e+03  4e-07  1e-14\n",
      " 6: -1.3001e+04 -1.5651e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.3159e+04 -1.3846e+04  7e+02  2e-16  5e-16\n",
      " 8: -1.3226e+04 -1.3568e+04  3e+02  1e-16  5e-16\n",
      " 9: -1.3252e+04 -1.3371e+04  1e+02  2e-16  4e-16\n",
      "10: -1.3270e+04 -1.3304e+04  3e+01  2e-16  5e-16\n",
      "11: -1.3278e+04 -1.3282e+04  5e+00  2e-16  5e-16\n",
      "12: -1.3279e+04 -1.3280e+04  5e-01  2e-16  5e-16\n",
      "13: -1.3279e+04 -1.3279e+04  2e-02  2e-16  5e-16\n",
      "14: -1.3279e+04 -1.3279e+04  7e-04  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9663e+03 -3.0440e+06  5e+07  2e-01  4e-15\n",
      " 1: -4.4665e+03 -7.2752e+05  1e+06  2e-03  4e-13\n",
      " 2: -2.4609e+03 -1.0151e+05  1e+05  1e-05  2e-13\n",
      " 3: -4.9792e+03 -4.2860e+04  4e+04  5e-06  6e-14\n",
      " 4: -1.1980e+04 -5.4566e+04  4e+04  2e-06  2e-14\n",
      " 5: -1.2702e+04 -2.0034e+04  7e+03  3e-07  4e-15\n",
      " 6: -1.2986e+04 -1.5856e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.3112e+04 -1.4091e+04  1e+03  2e-16  5e-16\n",
      " 8: -1.3182e+04 -1.3646e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.3212e+04 -1.3383e+04  2e+02  2e-16  5e-16\n",
      "10: -1.3228e+04 -1.3323e+04  1e+02  2e-16  5e-16\n",
      "11: -1.3240e+04 -1.3271e+04  3e+01  2e-16  5e-16\n",
      "12: -1.3246e+04 -1.3251e+04  6e+00  2e-16  5e-16\n",
      "13: -1.3247e+04 -1.3249e+04  2e+00  2e-16  5e-16\n",
      "14: -1.3248e+04 -1.3248e+04  8e-02  2e-16  5e-16\n",
      "15: -1.3248e+04 -1.3248e+04  1e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7890e+03 -3.0569e+06  5e+07  2e-01  2e-15\n",
      " 1: -4.2092e+03 -7.2783e+05  1e+06  2e-03  3e-13\n",
      " 2: -2.1463e+03 -1.0345e+05  1e+05  1e-05  3e-13\n",
      " 3: -4.7071e+03 -4.2872e+04  4e+04  5e-06  1e-13\n",
      " 4: -1.1993e+04 -5.5325e+04  4e+04  2e-06  4e-14\n",
      " 5: -1.2584e+04 -2.1418e+04  9e+03  3e-07  8e-15\n",
      " 6: -1.2838e+04 -1.6351e+04  4e+03  2e-16  5e-16\n",
      " 7: -1.2979e+04 -1.4018e+04  1e+03  2e-16  5e-16\n",
      " 8: -1.3051e+04 -1.3582e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.3082e+04 -1.3268e+04  2e+02  2e-16  5e-16\n",
      "10: -1.3099e+04 -1.3202e+04  1e+02  2e-16  5e-16\n",
      "11: -1.3111e+04 -1.3147e+04  4e+01  2e-16  4e-16\n",
      "12: -1.3118e+04 -1.3125e+04  7e+00  2e-16  5e-16\n",
      "13: -1.3120e+04 -1.3122e+04  2e+00  2e-16  5e-16\n",
      "14: -1.3120e+04 -1.3120e+04  2e-01  2e-16  5e-16\n",
      "15: -1.3120e+04 -1.3120e+04  4e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.9133e+03 -3.0433e+06  5e+07  2e-01  6e-15\n",
      " 1: -4.3631e+03 -7.2751e+05  1e+06  2e-03  4e-13\n",
      " 2: -2.3190e+03 -1.0240e+05  1e+05  1e-05  4e-13\n",
      " 3: -4.8553e+03 -4.2820e+04  4e+04  5e-06  9e-14\n",
      " 4: -1.1981e+04 -5.4883e+04  4e+04  2e-06  3e-14\n",
      " 5: -1.2633e+04 -2.0012e+04  7e+03  3e-07  5e-15\n",
      " 6: -1.2894e+04 -1.5862e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.3021e+04 -1.3971e+04  9e+02  2e-16  5e-16\n",
      " 8: -1.3089e+04 -1.3573e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.3120e+04 -1.3285e+04  2e+02  2e-16  4e-16\n",
      "10: -1.3133e+04 -1.3240e+04  1e+02  2e-16  4e-16\n",
      "11: -1.3147e+04 -1.3175e+04  3e+01  2e-16  4e-16\n",
      "12: -1.3151e+04 -1.3163e+04  1e+01  1e-16  5e-16\n",
      "13: -1.3154e+04 -1.3156e+04  1e+00  2e-16  5e-16\n",
      "14: -1.3155e+04 -1.3155e+04  1e-01  2e-16  5e-16\n",
      "15: -1.3155e+04 -1.3155e+04  4e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.5822e+03 -3.0869e+06  5e+07  2e-01  5e-15\n",
      " 1: -4.0028e+03 -7.2849e+05  1e+06  2e-03  4e-13\n",
      " 2: -1.8717e+03 -1.0443e+05  1e+05  1e-05  2e-13\n",
      " 3: -4.4632e+03 -4.2695e+04  4e+04  5e-06  7e-14\n",
      " 4: -1.1885e+04 -5.5623e+04  4e+04  1e-06  2e-14\n",
      " 5: -1.2390e+04 -2.1202e+04  9e+03  2e-07  4e-15\n",
      " 6: -1.2600e+04 -1.6006e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.2726e+04 -1.3745e+04  1e+03  2e-16  5e-16\n",
      " 8: -1.2797e+04 -1.3340e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.2831e+04 -1.2978e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2838e+04 -1.2957e+04  1e+02  2e-16  4e-16\n",
      "11: -1.2855e+04 -1.2887e+04  3e+01  2e-16  5e-16\n",
      "12: -1.2860e+04 -1.2872e+04  1e+01  2e-16  5e-16\n",
      "13: -1.2863e+04 -1.2865e+04  1e+00  2e-16  5e-16\n",
      "14: -1.2864e+04 -1.2864e+04  6e-02  2e-16  6e-16\n",
      "15: -1.2864e+04 -1.2864e+04  1e-03  2e-16  6e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.5882e+03 -3.0321e+06  5e+07  2e-01  6e-15\n",
      " 1: -4.0197e+03 -7.2677e+05  1e+06  2e-03  7e-13\n",
      " 2: -1.9459e+03 -1.0210e+05  1e+05  1e-05  2e-13\n",
      " 3: -4.5134e+03 -4.2713e+04  4e+04  5e-06  7e-14\n",
      " 4: -1.1668e+04 -5.4725e+04  4e+04  2e-06  3e-14\n",
      " 5: -1.2370e+04 -1.9955e+04  8e+03  3e-07  4e-15\n",
      " 6: -1.2633e+04 -1.5683e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.2757e+04 -1.3717e+04  1e+03  2e-16  5e-16\n",
      " 8: -1.2819e+04 -1.3324e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.2849e+04 -1.3018e+04  2e+02  2e-16  4e-16\n",
      "10: -1.2863e+04 -1.2963e+04  1e+02  2e-16  4e-16\n",
      "11: -1.2876e+04 -1.2906e+04  3e+01  2e-16  5e-16\n",
      "12: -1.2881e+04 -1.2889e+04  8e+00  2e-16  5e-16\n",
      "13: -1.2883e+04 -1.2884e+04  6e-01  2e-16  5e-16\n",
      "14: -1.2884e+04 -1.2884e+04  6e-02  2e-16  5e-16\n",
      "15: -1.2884e+04 -1.2884e+04  1e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8713e+03 -3.0196e+06  5e+07  2e-01  2e-15\n",
      " 1: -4.3313e+03 -7.2652e+05  1e+06  2e-03  4e-13\n",
      " 2: -2.2817e+03 -1.0043e+05  1e+05  1e-05  4e-13\n",
      " 3: -4.8492e+03 -4.2567e+04  4e+04  4e-06  1e-13\n",
      " 4: -1.1718e+04 -5.3921e+04  4e+04  2e-06  5e-14\n",
      " 5: -1.2496e+04 -2.0861e+04  8e+03  4e-07  9e-15\n",
      " 6: -1.2799e+04 -1.6021e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.2936e+04 -1.3971e+04  1e+03  2e-16  5e-16\n",
      " 8: -1.3007e+04 -1.3551e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.3040e+04 -1.3217e+04  2e+02  1e-16  5e-16\n",
      "10: -1.3051e+04 -1.3174e+04  1e+02  2e-16  5e-16\n",
      "11: -1.3068e+04 -1.3092e+04  2e+01  2e-16  5e-16\n",
      "12: -1.3072e+04 -1.3082e+04  1e+01  1e-16  5e-16\n",
      "13: -1.3075e+04 -1.3077e+04  2e+00  2e-16  5e-16\n",
      "14: -1.3075e+04 -1.3075e+04  1e-01  2e-16  5e-16\n",
      "15: -1.3075e+04 -1.3075e+04  3e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.5337e+03 -3.0338e+06  5e+07  2e-01  2e-15\n",
      " 1: -3.9591e+03 -7.2676e+05  1e+06  2e-03  5e-13\n",
      " 2: -1.8476e+03 -1.0259e+05  1e+05  1e-05  4e-13\n",
      " 3: -4.4410e+03 -4.2624e+04  4e+04  5e-06  1e-13\n",
      " 4: -1.1665e+04 -5.4870e+04  4e+04  2e-06  4e-14\n",
      " 5: -1.2326e+04 -2.0027e+04  8e+03  3e-07  7e-15\n",
      " 6: -1.2594e+04 -1.5645e+04  3e+03  2e-16  5e-16\n",
      " 7: -1.2727e+04 -1.3671e+04  9e+02  2e-16  5e-16\n",
      " 8: -1.2796e+04 -1.3303e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.2829e+04 -1.2997e+04  2e+02  1e-16  4e-16\n",
      "10: -1.2841e+04 -1.2952e+04  1e+02  2e-16  4e-16\n",
      "11: -1.2856e+04 -1.2889e+04  3e+01  2e-16  5e-16\n",
      "12: -1.2860e+04 -1.2873e+04  1e+01  2e-16  5e-16\n",
      "13: -1.2864e+04 -1.2865e+04  1e+00  2e-16  5e-16\n",
      "14: -1.2864e+04 -1.2864e+04  1e-01  2e-16  5e-16\n",
      "15: -1.2864e+04 -1.2864e+04  3e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0102e+03 -2.9917e+06  5e+07  2e-01  2e-15\n",
      " 1: -4.5141e+03 -7.2602e+05  1e+06  2e-03  5e-13\n",
      " 2: -2.4956e+03 -1.0038e+05  1e+05  1e-05  6e-13\n",
      " 3: -5.0345e+03 -4.2680e+04  4e+04  4e-06  2e-13\n",
      " 4: -1.1854e+04 -5.3912e+04  4e+04  2e-06  8e-14\n",
      " 5: -1.2659e+04 -1.9863e+04  7e+03  3e-07  1e-14\n",
      " 6: -1.2974e+04 -1.5780e+04  3e+03  1e-16  5e-16\n",
      " 7: -1.3106e+04 -1.4054e+04  9e+02  2e-16  5e-16\n",
      " 8: -1.3178e+04 -1.3649e+04  5e+02  2e-16  6e-16\n",
      " 9: -1.3213e+04 -1.3347e+04  1e+02  2e-16  5e-16\n",
      "10: -1.3234e+04 -1.3278e+04  4e+01  2e-16  6e-16\n",
      "11: -1.3241e+04 -1.3255e+04  1e+01  2e-16  5e-16\n",
      "12: -1.3244e+04 -1.3247e+04  2e+00  2e-16  5e-16\n",
      "13: -1.3245e+04 -1.3245e+04  3e-01  2e-16  5e-16\n",
      "14: -1.3245e+04 -1.3245e+04  7e-03  2e-16  6e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "RMSE List of KMM: [8.6949372700428, 9.682662771406278, 6.675530813311134, 10.819915818360814, 8.657339105635506, 5.523793789199311, 8.91155417840259, 11.003268712416821, 10.787628874386897, 7.845508689726234, 5.826823767962854, 9.758866708841488, 8.530370226145623, 12.243898282171806, 9.420121641631289, 10.905259328933258, 7.8472004541351446, 11.53975554991979, 3.311118369814115, 6.406472683495275]\n",
      "R^2 List of KMM: [0.41770205207492683, 0.714100682029543, 0.2762087215598127, 0.05944968212190968, 0.019214030964858644, 0.01850943888913765, 0.0037591950507749276, 0.7379077102978581, 0.21930995080899365, 0.6130104095737511, 0.8169158527575459, 0.821734870081924, 0.551352198674291, 0.13552354230363245, 0.48950896260336496, 0.3734063040695569, 0.2656151364410826, 0.40928534265973765, 0.6498735695764309, 0.48665498693405385]\n",
      "\n",
      "\n",
      "RMSE of KMM: 8.719601351796952 2.300075611176511\n",
      "R^2 of KMM: 0.4039521319736593 0.2725172742210476\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "################################### Kernel Mean Matching Housing #######################################################\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_KMM_housing = []\n",
    "rmselist_KMM_housing = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(housing_tgt_df):\n",
    "        \n",
    "    housing_train_df_X = housing_tgt_df.iloc[train_idx].loc[:, features_housing]\n",
    "    housing_test_df_X = housing_tgt_df.iloc[test_idx][features_housing]\n",
    "    housing_train_df_y = housing_tgt_df.iloc[train_idx].loc[:,target_housing]\n",
    "    housing_test_df_y = housing_tgt_df.loc[test_idx][target_housing]\n",
    "    \n",
    "    housing_np_train_X = housing_train_df_X.to_numpy()\n",
    "    housing_np_train_y = housing_train_df_y.to_numpy()\n",
    "\n",
    "    housing_np_source_X = housing_source_df_X.to_numpy()\n",
    "    housing_np_source_y = housing_source_df_y.to_numpy()\n",
    "\n",
    "    housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "    housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "    housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "    housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "    \n",
    "    src_size_housing = len(housing_source_df_y)\n",
    "    tgt_size_housing = len(housing_train_df_y)\n",
    "    \n",
    "    src_idx = np.arange(start = 0, stop = (src_size_housing - 1), step=1)\n",
    "    tgt_idx = np.arange(start = 0, stop = (tgt_size_housing - 1), step=1)\n",
    "\n",
    "    model_KMM_housing = KMM(DecisionTreeRegressor(max_depth = 6))\n",
    "    model_KMM_housing.fit(housing_np_source_X[src_idx], housing_np_source_y[src_idx], housing_np_train_X[tgt_idx], housing_np_train_y[tgt_idx])\n",
    "\n",
    "    y_pred_KMM_housing = model_KMM_housing.predict(housing_test_df_X) \n",
    "\n",
    "    mse_KMM_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_KMM_housing))\n",
    "    rmselist_KMM_housing.append(mse_KMM_housing)\n",
    "        \n",
    "    r2_score_KMM_housing = pearsonr(housing_np_test_y_list, y_pred_KMM_housing)\n",
    "    r2_score_KMM_housing = (r2_score_KMM_housing[0])**2\n",
    "    r2scorelist_KMM_housing.append(r2_score_KMM_housing)\n",
    "\n",
    "print(\"RMSE List of KMM:\", rmselist_KMM_housing)\n",
    "print(\"R^2 List of KMM:\", r2scorelist_KMM_housing)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of KMM:\", statistics.mean(rmselist_KMM_housing), statistics.stdev(rmselist_KMM_housing))\n",
    "print(\"R^2 of KMM:\", statistics.mean(r2scorelist_KMM_housing), statistics.stdev(r2scorelist_KMM_housing))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLIEP\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.123 (0.106)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.274 (0.646)\n",
      "Parameter sigma = 10.0000 -- J-score = -21.657 (1.667)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.086 (0.056)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.214 (0.428)\n",
      "Parameter sigma = 10.0000 -- J-score = -23.337 (1.310)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.116 (0.025)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.112 (0.388)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.534 (1.375)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.110 (0.091)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.290 (0.799)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.711 (2.165)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.119 (0.107)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.357 (0.714)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.184 (1.516)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.093 (0.115)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.406 (0.950)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.288 (1.688)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.105 (0.078)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.370 (0.252)\n",
      "Parameter sigma = 10.0000 -- J-score = -24.891 (1.264)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.076 (0.087)\n",
      "Parameter sigma = 1.0000 -- J-score = -1.970 (0.588)\n",
      "Parameter sigma = 10.0000 -- J-score = -21.308 (1.862)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.124 (0.122)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.321 (0.831)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.765 (1.275)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.132 (0.077)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.184 (0.472)\n",
      "Parameter sigma = 10.0000 -- J-score = -21.957 (1.683)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.124 (0.047)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.502 (0.634)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.233 (3.069)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.090 (0.065)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.209 (0.403)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.347 (1.697)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.120 (0.138)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.198 (1.040)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.683 (1.657)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.111 (0.077)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.477 (0.645)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.758 (1.834)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.088 (0.120)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.005 (0.422)\n",
      "Parameter sigma = 10.0000 -- J-score = -21.724 (0.939)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.135 (0.060)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.321 (0.370)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.492 (1.676)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.133 (0.099)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.256 (0.934)\n",
      "Parameter sigma = 10.0000 -- J-score = -21.979 (1.869)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.104 (0.128)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.378 (0.710)\n",
      "Parameter sigma = 10.0000 -- J-score = -23.710 (1.024)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.134 (0.099)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.186 (0.422)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.438 (0.814)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = -0.103 (0.055)\n",
      "Parameter sigma = 1.0000 -- J-score = -2.056 (0.407)\n",
      "Parameter sigma = 10.0000 -- J-score = -22.811 (1.157)\n",
      "Fit Estimator...\n",
      "RMSE List of KLIEP: [9.831953224855075, 8.69544311393119, 5.367663486847824, 9.9818437961736, 8.798048140266022, 6.274876918158557, 7.521507787565092, 10.433891837653743, 11.418241652091021, 12.02559257948152, 4.148496519578329, 8.281518250012574, 11.617866823361473, 12.73292494908616, 7.117374023883133, 10.992155484358364, 6.281888410941743, 6.482194959224831, 5.568297252656875, 1.3854701134192988]\n",
      "R^2 List of KLIEP: [0.6527779581566352, 0.7644216230312032, 0.9099281851708977, 0.11943688150822102, 0.032826288416205496, 0.5445526403173931, 0.12639040466582202, 0.6160307528679748, 0.31156630004850006, 0.6169295942347935, 0.7765727649678925, 0.7499802108795359, 0.19932134077982394, 0.8768375553086338, 0.8608392889535238, 0.45632116505755127, 0.47712434843094637, 0.8329702728901514, 0.4357476484566302, 0.8922629193428082]\n",
      "\n",
      "\n",
      "RMSE of KLIEP: 8.247862466177322 2.957408907062724\n",
      "R^2 of KLIEP: 0.5626419071742572 0.283122913137812\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### KLIEP Housing #######################################\n",
    "\n",
    "from adapt.instance_based import KLIEP\n",
    "\n",
    "print(\"KLIEP\")\n",
    "\n",
    "r2scorelist_KLIEP_housing = []\n",
    "rmselist_KLIEP_housing = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(housing_tgt_df):\n",
    "        \n",
    "    housing_train_df_X = housing_tgt_df.iloc[train_idx].loc[:, features_housing]\n",
    "    housing_test_df_X = housing_tgt_df.iloc[test_idx][features_housing]\n",
    "    housing_train_df_y = housing_tgt_df.iloc[train_idx].loc[:,target_housing]\n",
    "    housing_test_df_y = housing_tgt_df.loc[test_idx][target_housing]\n",
    "  \n",
    "    housing_np_train_X = housing_train_df_X.to_numpy()\n",
    "    housing_np_train_y = housing_train_df_y.to_numpy()\n",
    "\n",
    "    housing_np_source_X = housing_source_df_X.to_numpy()\n",
    "    housing_np_source_y = housing_source_df_y.to_numpy()\n",
    "\n",
    "    housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "    housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "    housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "    housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "    \n",
    "    src_size_housing = len(housing_source_df_y)\n",
    "    tgt_size_housing = len(housing_train_df_y)\n",
    "    \n",
    "    src_idx = np.arange(start = 0, stop = (src_size_housing - 1), step=1)\n",
    "    tgt_idx = np.arange(start = 0, stop = (tgt_size_housing - 1), step=1)\n",
    "    \n",
    "    model_KLIEP_housing = KLIEP(DecisionTreeRegressor(max_depth = 6), sigmas = [0.1, 1, 10])\n",
    "    model_KLIEP_housing.fit(housing_np_source_X[src_idx], housing_np_source_y[src_idx], housing_np_train_X[tgt_idx], housing_np_train_y[tgt_idx])\n",
    "\n",
    "    y_pred_KLIEP_housing = model_KLIEP_housing.predict(housing_test_df_X) \n",
    "\n",
    "    mse_KLIEP_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_KLIEP_housing))\n",
    "    rmselist_KLIEP_housing.append(mse_KLIEP_housing)\n",
    "\n",
    "    r2_score_KLIEP_housing = pearsonr(housing_np_test_y_list, y_pred_KLIEP_housing)\n",
    "    r2_score_KLIEP_housing = (r2_score_KLIEP_housing[0])**2\n",
    "    r2scorelist_KLIEP_housing.append(r2_score_KLIEP_housing)\n",
    "\n",
    "print(\"RMSE List of KLIEP:\", rmselist_KLIEP_housing)\n",
    "print(\"R^2 List of KLIEP:\", r2scorelist_KLIEP_housing)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of KLIEP:\", statistics.mean(rmselist_KLIEP_housing), statistics.stdev(rmselist_KLIEP_housing))\n",
    "print(\"R^2 of KLIEP:\", statistics.mean(r2scorelist_KLIEP_housing), statistics.stdev(r2scorelist_KLIEP_housing))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWKRR\n",
      "-------------------------------------------\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.5964e+04 -5.5653e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.5949e+04 -5.5423e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.2127e+04 -5.3023e+04  8e+03  3e+01  1e-03\n",
      " 3: -4.9215e+04 -4.0811e+04  1e+04  2e+01  9e-04\n",
      " 4: -4.5301e+04 -2.8722e+04  1e+04  2e+01  8e-04\n",
      " 5: -4.1016e+04 -2.1029e+04  2e+04  2e+01  7e-04\n",
      " 6: -2.9585e+04 -9.9420e+03  2e+04  1e+01  5e-04\n",
      " 7:  4.6381e+03 -1.8855e+03  1e+04  8e-01  3e-05\n",
      " 8:  4.2241e+02 -2.2934e+02  7e+02  8e-03  3e-07\n",
      " 9:  4.4409e+01 -3.0378e+01  8e+01  7e-05  3e-09\n",
      "10:  5.5841e+00 -4.0153e+00  1e+01  1e-07  5e-12\n",
      "11:  7.3565e-01 -5.2935e-01  1e+00  5e-16  6e-16\n",
      "12:  9.7231e-02 -6.9781e-02  2e-01  2e-16  5e-16\n",
      "13:  1.2713e-02 -9.2530e-03  2e-02  6e-17  6e-16\n",
      "14:  1.6300e-03 -1.2470e-03  3e-03  3e-17  5e-16\n",
      "15:  2.1859e-04 -1.6920e-04  4e-04  8e-18  5e-16\n",
      "16:  2.9769e-05 -2.2952e-05  5e-05  3e-18  5e-16\n",
      "17:  4.0486e-06 -3.1094e-06  7e-06  1e-18  5e-16\n",
      "18:  5.5026e-07 -4.2041e-07  1e-06  4e-19  4e-16\n",
      "19:  7.5521e-08 -5.6449e-08  1e-07  2e-19  4e-16\n",
      "20:  1.0245e-08 -7.5498e-09  2e-08  5e-20  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8196e+04 -5.7882e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.8180e+04 -5.7648e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.5454e+04 -5.5158e+04  6e+03  3e+01  1e-03\n",
      " 3: -5.2302e+04 -4.2511e+04  9e+03  2e+01  8e-04\n",
      " 4: -4.8172e+04 -2.9078e+04  1e+04  2e+01  7e-04\n",
      " 5: -4.4017e+04 -2.1788e+04  1e+04  2e+01  6e-04\n",
      " 6: -3.1586e+04 -9.9321e+03  2e+04  1e+01  5e-04\n",
      " 7:  5.2974e+03 -2.1783e+03  1e+04  8e-01  3e-05\n",
      " 8:  5.0531e+02 -2.6033e+02  8e+02  8e-03  3e-07\n",
      " 9:  5.0377e+01 -3.4309e+01  9e+01  7e-05  3e-09\n",
      "10:  6.4039e+00 -4.5919e+00  1e+01  4e-07  1e-11\n",
      "11:  8.4033e-01 -6.0551e-01  1e+00  7e-16  6e-16\n",
      "12:  1.1118e-01 -7.9829e-02  2e-01  2e-16  5e-16\n",
      "13:  1.4579e-02 -1.0573e-02  3e-02  9e-17  6e-16\n",
      "14:  1.8664e-03 -1.4231e-03  3e-03  3e-17  6e-16\n",
      "15:  2.4941e-04 -1.9307e-04  4e-04  1e-17  5e-16\n",
      "16:  3.3947e-05 -2.6197e-05  6e-05  4e-18  5e-16\n",
      "17:  4.6172e-06 -3.5509e-06  8e-06  1e-18  4e-16\n",
      "18:  6.2732e-07 -4.8054e-07  1e-06  4e-19  4e-16\n",
      "19:  8.6054e-08 -6.4637e-08  2e-07  1e-19  4e-16\n",
      "20:  1.1667e-08 -8.6645e-09  2e-08  7e-20  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.7261e+04 -5.6950e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.7246e+04 -5.6721e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.4447e+04 -5.4288e+04  6e+03  3e+01  1e-03\n",
      " 3: -5.1329e+04 -4.1820e+04  9e+03  2e+01  8e-04\n",
      " 4: -4.6670e+04 -2.7835e+04  1e+04  2e+01  7e-04\n",
      " 5: -4.2813e+04 -2.1108e+04  2e+04  2e+01  7e-04\n",
      " 6: -3.0377e+04 -9.6070e+03  2e+04  1e+01  5e-04\n",
      " 7:  5.6049e+03 -2.2055e+03  1e+04  7e-01  3e-05\n",
      " 8:  4.9300e+02 -2.6730e+02  8e+02  6e-03  2e-07\n",
      " 9:  5.1137e+01 -3.5408e+01  9e+01  5e-05  2e-09\n",
      "10:  6.5618e+00 -4.7398e+00  1e+01  2e-07  9e-12\n",
      "11:  8.6696e-01 -6.2486e-01  1e+00  6e-16  5e-16\n",
      "12:  1.1656e-01 -8.1693e-02  2e-01  2e-16  5e-16\n",
      "13:  1.5239e-02 -1.0685e-02  3e-02  6e-17  6e-16\n",
      "14:  1.9036e-03 -1.4280e-03  3e-03  3e-17  6e-16\n",
      "15:  2.5039e-04 -1.9344e-04  4e-04  8e-18  4e-16\n",
      "16:  3.3966e-05 -2.6260e-05  6e-05  4e-18  5e-16\n",
      "17:  4.6142e-06 -3.5646e-06  8e-06  1e-18  4e-16\n",
      "18:  6.2678e-07 -4.8375e-07  1e-06  4e-19  4e-16\n",
      "19:  8.5565e-08 -6.5481e-08  2e-07  2e-19  3e-16\n",
      "20:  1.1687e-08 -8.8265e-09  2e-08  5e-20  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.7716e+04 -5.7404e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.7700e+04 -5.7189e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.6799e+04 -5.4002e+04  2e+03  3e+01  1e-03\n",
      " 3: -5.5881e+04 -4.7328e+04  4e+03  3e+01  9e-04\n",
      " 4: -5.1140e+04 -3.2065e+04  7e+03  2e+01  7e-04\n",
      " 5: -4.7257e+04 -2.3953e+04  1e+04  2e+01  6e-04\n",
      " 6: -4.0822e+04 -1.5139e+04  1e+04  1e+01  5e-04\n",
      " 7: -2.3150e+04 -4.5811e+03  1e+04  8e+00  3e-04\n",
      " 8: -4.0252e+02 -2.2993e+02  2e+03  4e-01  1e-05\n",
      " 9:  3.4314e+01 -3.0059e+01  8e+01  4e-03  1e-07\n",
      "10:  5.4542e+00 -4.0107e+00  1e+01  2e-05  7e-10\n",
      "11:  7.3501e-01 -5.2881e-01  1e+00  7e-16  5e-16\n",
      "12:  9.7119e-02 -6.9705e-02  2e-01  2e-16  5e-16\n",
      "13:  1.2717e-02 -9.2363e-03  2e-02  6e-17  4e-16\n",
      "14:  1.6276e-03 -1.2443e-03  3e-03  3e-17  5e-16\n",
      "15:  2.1796e-04 -1.6890e-04  4e-04  8e-18  5e-16\n",
      "16:  2.9687e-05 -2.2923e-05  5e-05  3e-18  5e-16\n",
      "17:  4.0409e-06 -3.1067e-06  7e-06  2e-18  4e-16\n",
      "18:  5.4982e-07 -4.2009e-07  1e-06  4e-19  4e-16\n",
      "19:  7.5412e-08 -5.6431e-08  1e-07  2e-19  4e-16\n",
      "20:  1.0189e-08 -7.5540e-09  2e-08  4e-20  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8000e+04 -5.7690e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.7984e+04 -5.7464e+04  7e+02  3e+01  1e-03\n",
      " 2: -4.7661e+04 -5.7553e+04  2e+04  3e+01  1e-03\n",
      " 3: -4.7360e+04 -5.2694e+04  2e+04  3e+01  9e-04\n",
      " 4: -4.0426e+04 -3.1123e+04  3e+04  2e+01  7e-04\n",
      " 5: -3.7235e+04 -2.4429e+04  3e+04  2e+01  6e-04\n",
      " 6: -2.2257e+04 -1.0500e+04  3e+04  1e+01  4e-04\n",
      " 7:  3.8756e+03 -1.4359e+03  8e+03  4e-01  2e-05\n",
      " 8:  3.2814e+02 -1.6937e+02  5e+02  4e-03  1e-07\n",
      " 9:  3.2442e+01 -2.2341e+01  5e+01  3e-05  1e-09\n",
      "10:  4.2371e+00 -3.0166e+00  7e+00  3e-07  1e-11\n",
      "11:  5.5274e-01 -3.9750e-01  1e+00  4e-16  5e-16\n",
      "12:  7.2501e-02 -5.2567e-02  1e-01  1e-16  5e-16\n",
      "13:  9.5419e-03 -6.9874e-03  2e-02  5e-17  6e-16\n",
      "14:  1.2336e-03 -9.4109e-04  2e-03  2e-17  5e-16\n",
      "15:  1.6632e-04 -1.2719e-04  3e-04  8e-18  4e-16\n",
      "16:  2.2504e-05 -1.7196e-05  4e-05  3e-18  4e-16\n",
      "17:  3.0258e-06 -2.3304e-06  5e-06  8e-19  4e-16\n",
      "18:  4.1223e-07 -3.1524e-07  7e-07  3e-19  4e-16\n",
      "19:  5.6482e-08 -4.2381e-08  1e-07  1e-19  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.7817e+04 -5.7502e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.7801e+04 -5.7268e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.4868e+04 -5.4843e+04  6e+03  3e+01  1e-03\n",
      " 3: -5.1606e+04 -4.1913e+04  1e+04  2e+01  8e-04\n",
      " 4: -4.6438e+04 -2.6892e+04  1e+04  2e+01  7e-04\n",
      " 5: -4.2678e+04 -2.0572e+04  2e+04  2e+01  6e-04\n",
      " 6: -2.4720e+04 -6.9277e+03  2e+04  1e+01  4e-04\n",
      " 7:  7.4349e+02 -7.9573e+02  5e+03  7e-01  3e-05\n",
      " 8:  1.4846e+02 -1.0200e+02  3e+02  7e-03  2e-07\n",
      " 9:  1.8986e+01 -1.3766e+01  3e+01  6e-05  2e-09\n",
      "10:  2.4673e+00 -1.8315e+00  4e+00  1e-15  5e-16\n",
      "11:  3.3264e-01 -2.4312e-01  6e-01  3e-16  6e-16\n",
      "12:  4.4732e-02 -3.2062e-02  8e-02  1e-16  6e-16\n",
      "13:  5.8774e-03 -4.2373e-03  1e-02  5e-17  5e-16\n",
      "14:  7.5416e-04 -5.6813e-04  1e-03  1e-17  5e-16\n",
      "15:  1.0005e-04 -7.6848e-05  2e-04  6e-18  4e-16\n",
      "16:  1.3500e-05 -1.0423e-05  2e-05  2e-18  5e-16\n",
      "17:  1.8435e-06 -1.4099e-06  3e-06  8e-19  4e-16\n",
      "18:  2.5294e-07 -1.8943e-07  4e-07  3e-19  4e-16\n",
      "19:  3.4287e-08 -2.5336e-08  6e-08  1e-19  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.7578e+04 -5.7264e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.7562e+04 -5.7031e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.3831e+04 -5.4698e+04  8e+03  3e+01  1e-03\n",
      " 3: -5.0374e+04 -4.1081e+04  1e+04  2e+01  8e-04\n",
      " 4: -4.3436e+04 -2.4386e+04  2e+04  2e+01  7e-04\n",
      " 5: -3.9710e+04 -1.8772e+04  2e+04  2e+01  6e-04\n",
      " 6: -2.8392e+04 -9.0450e+03  2e+04  1e+01  4e-04\n",
      " 7:  4.4315e+03 -1.2528e+03  7e+03  2e-01  9e-06\n",
      " 8:  2.7319e+02 -1.5154e+02  4e+02  2e-03  8e-08\n",
      " 9:  2.9279e+01 -2.0147e+01  5e+01  2e-05  7e-10\n",
      "10:  3.6769e+00 -2.6478e+00  6e+00  1e-15  5e-16\n",
      "11:  4.8693e-01 -3.4864e-01  8e-01  5e-16  5e-16\n",
      "12:  6.3884e-02 -4.6002e-02  1e-01  1e-16  7e-16\n",
      "13:  8.3388e-03 -6.1163e-03  1e-02  6e-17  5e-16\n",
      "14:  1.0774e-03 -8.2493e-04  2e-03  2e-17  5e-16\n",
      "15:  1.4470e-04 -1.1191e-04  3e-04  1e-17  4e-16\n",
      "16:  1.9686e-05 -1.5180e-05  3e-05  2e-18  4e-16\n",
      "17:  2.6797e-06 -2.0561e-06  5e-06  8e-19  5e-16\n",
      "18:  3.6409e-07 -2.7784e-07  6e-07  4e-19  4e-16\n",
      "19:  5.0091e-08 -3.7252e-08  9e-08  1e-19  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.5802e+04 -5.5493e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.5787e+04 -5.5268e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.2925e+04 -5.2945e+04  6e+03  3e+01  1e-03\n",
      " 3: -5.0055e+04 -4.1392e+04  9e+03  2e+01  9e-04\n",
      " 4: -4.5709e+04 -2.8222e+04  1e+04  2e+01  8e-04\n",
      " 5: -4.1454e+04 -2.0736e+04  2e+04  2e+01  7e-04\n",
      " 6: -3.0225e+04 -9.8754e+03  2e+04  1e+01  5e-04\n",
      " 7:  4.7212e+03 -2.0486e+03  1e+04  9e-01  3e-05\n",
      " 8:  4.6531e+02 -2.4874e+02  8e+02  9e-03  3e-07\n",
      " 9:  4.7997e+01 -3.2902e+01  8e+01  8e-05  3e-09\n",
      "10:  6.0652e+00 -4.3806e+00  1e+01  2e-07  9e-12\n",
      "11:  7.9972e-01 -5.7857e-01  1e+00  6e-16  6e-16\n",
      "12:  1.0643e-01 -7.6236e-02  2e-01  2e-16  6e-16\n",
      "13:  1.3939e-02 -1.0087e-02  2e-02  8e-17  5e-16\n",
      "14:  1.7861e-03 -1.3557e-03  3e-03  2e-17  5e-16\n",
      "15:  2.3748e-04 -1.8387e-04  4e-04  7e-18  5e-16\n",
      "16:  3.2320e-05 -2.4954e-05  6e-05  3e-18  4e-16\n",
      "17:  4.3972e-06 -3.3820e-06  8e-06  1e-18  5e-16\n",
      "18:  6.0004e-07 -4.5661e-07  1e-06  4e-19  3e-16\n",
      "19:  8.2799e-08 -6.1041e-08  1e-07  2e-19  4e-16\n",
      "20:  1.1080e-08 -8.1437e-09  2e-08  6e-20  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.4729e+04 -5.4415e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.4713e+04 -5.4181e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.1562e+04 -5.1739e+04  7e+03  3e+01  1e-03\n",
      " 3: -4.8412e+04 -3.9130e+04  1e+04  2e+01  9e-04\n",
      " 4: -4.5153e+04 -2.8030e+04  1e+04  2e+01  8e-04\n",
      " 5: -3.7938e+04 -1.6499e+04  2e+04  2e+01  6e-04\n",
      " 6: -3.2005e+04 -1.0581e+04  2e+04  1e+01  5e-04\n",
      " 7: -3.6370e+01 -1.2192e+03  1e+04  2e+00  7e-05\n",
      " 8:  2.2068e+02 -1.5368e+02  5e+02  2e-02  8e-07\n",
      " 9:  2.8947e+01 -2.0526e+01  5e+01  2e-04  7e-09\n",
      "10:  3.7903e+00 -2.7023e+00  6e+00  2e-07  9e-12\n",
      "11:  4.9969e-01 -3.5464e-01  9e-01  4e-16  6e-16\n",
      "12:  6.4928e-02 -4.6776e-02  1e-01  1e-16  6e-16\n",
      "13:  8.4799e-03 -6.2209e-03  1e-02  5e-17  6e-16\n",
      "14:  1.0903e-03 -8.4086e-04  2e-03  2e-17  5e-16\n",
      "15:  1.4729e-04 -1.1421e-04  3e-04  9e-18  5e-16\n",
      "16:  2.0091e-05 -1.5494e-05  4e-05  4e-18  5e-16\n",
      "17:  2.7409e-06 -2.0969e-06  5e-06  9e-19  5e-16\n",
      "18:  3.7170e-07 -2.8314e-07  7e-07  3e-19  4e-16\n",
      "19:  5.1119e-08 -3.7932e-08  9e-08  1e-19  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.4042e+04 -5.3728e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.4027e+04 -5.3494e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.0936e+04 -5.1028e+04  7e+03  3e+01  1e-03\n",
      " 3: -4.8167e+04 -3.9068e+04  9e+03  2e+01  1e-03\n",
      " 4: -4.6287e+04 -3.1034e+04  1e+04  2e+01  9e-04\n",
      " 5: -3.9060e+04 -1.7868e+04  1e+04  2e+01  7e-04\n",
      " 6: -3.3008e+04 -1.1414e+04  2e+04  1e+01  6e-04\n",
      " 7: -2.9815e+02 -1.7185e+03  1e+04  2e+00  1e-04\n",
      " 8:  3.1731e+02 -2.1511e+02  7e+02  3e-02  1e-06\n",
      " 9:  4.0667e+01 -2.8647e+01  7e+01  3e-04  1e-08\n",
      "10:  5.2567e+00 -3.7771e+00  9e+00  3e-07  1e-11\n",
      "11:  6.9422e-01 -4.9725e-01  1e+00  4e-16  7e-16\n",
      "12:  9.1114e-02 -6.5613e-02  2e-01  2e-16  6e-16\n",
      "13:  1.1894e-02 -8.7225e-03  2e-02  6e-17  6e-16\n",
      "14:  1.5332e-03 -1.1774e-03  3e-03  2e-17  6e-16\n",
      "15:  2.0583e-04 -1.6003e-04  4e-04  1e-17  6e-16\n",
      "16:  2.8019e-05 -2.1758e-05  5e-05  3e-18  5e-16\n",
      "17:  3.8382e-06 -2.9493e-06  7e-06  1e-18  4e-16\n",
      "18:  5.2221e-07 -3.9848e-07  9e-07  4e-19  4e-16\n",
      "19:  7.2271e-08 -5.3265e-08  1e-07  2e-19  4e-16\n",
      "20:  9.7325e-09 -7.0955e-09  2e-08  5e-20  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8012e+04 -5.7699e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.7996e+04 -5.7471e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.4859e+04 -5.4585e+04  7e+03  3e+01  1e-03\n",
      " 3: -5.2937e+04 -4.4328e+04  9e+03  2e+01  9e-04\n",
      " 4: -4.7586e+04 -2.8548e+04  1e+04  2e+01  7e-04\n",
      " 5: -4.3812e+04 -2.1780e+04  2e+04  2e+01  6e-04\n",
      " 6: -3.0561e+04 -9.6312e+03  2e+04  1e+01  4e-04\n",
      " 7:  5.8359e+03 -2.2985e+03  1e+04  8e-01  3e-05\n",
      " 8:  5.3714e+02 -2.7279e+02  8e+02  7e-03  3e-07\n",
      " 9:  5.3072e+01 -3.5871e+01  9e+01  6e-05  2e-09\n",
      "10:  6.7102e+00 -4.7940e+00  1e+01  3e-07  1e-11\n",
      "11:  8.7657e-01 -6.3213e-01  2e+00  5e-16  6e-16\n",
      "12:  1.1613e-01 -8.3332e-02  2e-01  2e-16  5e-16\n",
      "13:  1.5209e-02 -1.1037e-02  3e-02  5e-17  5e-16\n",
      "14:  1.9515e-03 -1.4848e-03  3e-03  2e-17  5e-16\n",
      "15:  2.5994e-04 -2.0150e-04  5e-04  1e-17  5e-16\n",
      "16:  3.5404e-05 -2.7355e-05  6e-05  3e-18  5e-16\n",
      "17:  4.8126e-06 -3.7110e-06  9e-06  2e-18  4e-16\n",
      "18:  6.5465e-07 -5.0264e-07  1e-06  4e-19  3e-16\n",
      "19:  9.0207e-08 -6.7520e-08  2e-07  2e-19  3e-16\n",
      "20:  1.2324e-08 -9.0061e-09  2e-08  5e-20  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.6754e+04 -5.6445e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.6738e+04 -5.6197e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.5285e+04 -5.2458e+04  3e+03  3e+01  1e-03\n",
      " 3: -5.3397e+04 -4.3678e+04  5e+03  2e+01  9e-04\n",
      " 4: -5.0753e+04 -3.3254e+04  8e+03  2e+01  8e-04\n",
      " 5: -4.4925e+04 -2.2104e+04  1e+04  2e+01  7e-04\n",
      " 6: -4.0042e+04 -1.5126e+04  1e+04  2e+01  6e-04\n",
      " 7: -2.0785e+04 -3.8285e+03  1e+04  8e+00  3e-04\n",
      " 8: -5.4605e+01 -2.3628e+02  2e+03  3e-01  1e-05\n",
      " 9:  3.9200e+01 -3.0989e+01  9e+01  3e-03  1e-07\n",
      "10:  5.5935e+00 -4.1303e+00  1e+01  1e-05  4e-10\n",
      "11:  7.5320e-01 -5.4641e-01  1e+00  6e-16  5e-16\n",
      "12:  9.9978e-02 -7.2203e-02  2e-01  2e-16  6e-16\n",
      "13:  1.3154e-02 -9.5748e-03  2e-02  6e-17  5e-16\n",
      "14:  1.6986e-03 -1.2862e-03  3e-03  2e-17  5e-16\n",
      "15:  2.2639e-04 -1.7404e-04  4e-04  9e-18  5e-16\n",
      "16:  3.0688e-05 -2.3571e-05  5e-05  3e-18  5e-16\n",
      "17:  4.1674e-06 -3.1885e-06  7e-06  1e-18  5e-16\n",
      "18:  5.6706e-07 -4.3003e-07  1e-06  4e-19  5e-16\n",
      "19:  7.7373e-08 -5.7659e-08  1e-07  2e-19  4e-16\n",
      "20:  1.0465e-08 -7.6965e-09  2e-08  5e-20  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.6764e+04 -5.6452e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.6748e+04 -5.6223e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.3364e+04 -5.3885e+04  7e+03  3e+01  1e-03\n",
      " 3: -5.0188e+04 -4.1112e+04  1e+04  2e+01  8e-04\n",
      " 4: -4.5164e+04 -2.6661e+04  2e+04  2e+01  7e-04\n",
      " 5: -4.1418e+04 -2.0414e+04  2e+04  2e+01  6e-04\n",
      " 6: -3.0259e+04 -9.8590e+03  2e+04  1e+01  5e-04\n",
      " 7:  6.5160e+03 -1.8027e+03  9e+03  2e-01  8e-06\n",
      " 8:  4.0835e+02 -2.1036e+02  6e+02  2e-03  7e-08\n",
      " 9:  4.0183e+01 -2.8057e+01  7e+01  1e-05  6e-10\n",
      "10:  5.1102e+00 -3.7500e+00  9e+00  4e-08  1e-12\n",
      "11:  6.8008e-01 -4.9769e-01  1e+00  4e-16  5e-16\n",
      "12:  9.0617e-02 -6.5972e-02  2e-01  2e-16  6e-16\n",
      "13:  1.1927e-02 -8.7881e-03  2e-02  6e-17  5e-16\n",
      "14:  1.5386e-03 -1.1888e-03  3e-03  2e-17  5e-16\n",
      "15:  2.0655e-04 -1.6199e-04  4e-04  7e-18  5e-16\n",
      "16:  2.8512e-05 -2.1983e-05  5e-05  3e-18  4e-16\n",
      "17:  3.8995e-06 -2.9693e-06  7e-06  1e-18  5e-16\n",
      "18:  5.3075e-07 -3.9901e-07  9e-07  5e-19  4e-16\n",
      "19:  7.3192e-08 -5.2983e-08  1e-07  2e-19  4e-16\n",
      "20:  9.6997e-09 -7.0375e-09  2e-08  6e-20  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.5029e+04 -5.4716e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.5013e+04 -5.4487e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.1417e+04 -5.2183e+04  8e+03  3e+01  1e-03\n",
      " 3: -4.8065e+04 -3.9322e+04  1e+04  2e+01  9e-04\n",
      " 4: -4.2380e+04 -2.4214e+04  2e+04  2e+01  7e-04\n",
      " 5: -3.8509e+04 -1.8140e+04  2e+04  2e+01  6e-04\n",
      " 6: -2.8419e+04 -9.1812e+03  2e+04  1e+01  5e-04\n",
      " 7:  4.7549e+03 -1.2801e+03  7e+03  2e-01  9e-06\n",
      " 8:  2.8534e+02 -1.5268e+02  4e+02  2e-03  8e-08\n",
      " 9:  2.9571e+01 -2.0283e+01  5e+01  2e-05  8e-10\n",
      "10:  3.6843e+00 -2.6709e+00  6e+00  1e-15  6e-16\n",
      "11:  4.9057e-01 -3.5209e-01  8e-01  4e-16  6e-16\n",
      "12:  6.4552e-02 -4.6454e-02  1e-01  1e-16  6e-16\n",
      "13:  8.4239e-03 -6.1767e-03  1e-02  5e-17  6e-16\n",
      "14:  1.0831e-03 -8.3463e-04  2e-03  2e-17  5e-16\n",
      "15:  1.4638e-04 -1.1330e-04  3e-04  7e-18  6e-16\n",
      "16:  1.9918e-05 -1.5374e-05  4e-05  3e-18  5e-16\n",
      "17:  2.7116e-06 -2.0834e-06  5e-06  9e-19  5e-16\n",
      "18:  3.6789e-07 -2.8197e-07  6e-07  3e-19  4e-16\n",
      "19:  5.0568e-08 -3.7906e-08  9e-08  1e-19  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.5766e+04 -5.5455e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.5751e+04 -5.5231e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.2530e+04 -5.3284e+04  7e+03  3e+01  1e-03\n",
      " 3: -5.0287e+04 -4.2339e+04  9e+03  2e+01  9e-04\n",
      " 4: -4.5840e+04 -2.8472e+04  1e+04  2e+01  8e-04\n",
      " 5: -4.1850e+04 -2.1237e+04  2e+04  2e+01  7e-04\n",
      " 6: -2.9899e+04 -9.7510e+03  2e+04  1e+01  5e-04\n",
      " 7:  5.5617e+03 -2.1602e+03  1e+04  8e-01  3e-05\n",
      " 8:  5.0057e+02 -2.5736e+02  8e+02  7e-03  3e-07\n",
      " 9:  4.9769e+01 -3.3945e+01  8e+01  6e-05  2e-09\n",
      "10:  6.3210e+00 -4.5324e+00  1e+01  3e-07  1e-11\n",
      "11:  8.3006e-01 -5.9758e-01  1e+00  5e-16  5e-16\n",
      "12:  1.0912e-01 -7.9004e-02  2e-01  2e-16  5e-16\n",
      "13:  1.4295e-02 -1.0515e-02  2e-02  6e-17  6e-16\n",
      "14:  1.8476e-03 -1.4200e-03  3e-03  2e-17  5e-16\n",
      "15:  2.4831e-04 -1.9296e-04  4e-04  8e-18  5e-16\n",
      "16:  3.3858e-05 -2.6215e-05  6e-05  3e-18  5e-16\n",
      "17:  4.6039e-06 -3.5598e-06  8e-06  2e-18  5e-16\n",
      "18:  6.2631e-07 -4.8272e-07  1e-06  4e-19  4e-16\n",
      "19:  8.6703e-08 -6.4830e-08  2e-07  2e-19  3e-16\n",
      "20:  1.1855e-08 -8.6249e-09  2e-08  6e-20  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.7073e+04 -5.6758e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.7057e+04 -5.6525e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.3633e+04 -5.4189e+04  7e+03  3e+01  1e-03\n",
      " 3: -5.0436e+04 -4.1319e+04  1e+04  2e+01  8e-04\n",
      " 4: -4.5703e+04 -2.7214e+04  2e+04  2e+01  7e-04\n",
      " 5: -4.1756e+04 -2.0420e+04  2e+04  2e+01  6e-04\n",
      " 6: -3.0543e+04 -9.8379e+03  2e+04  1e+01  5e-04\n",
      " 7:  5.8043e+03 -1.6154e+03  9e+03  3e-01  1e-05\n",
      " 8:  3.6419e+02 -1.9038e+02  6e+02  2e-03  9e-08\n",
      " 9:  3.6763e+01 -2.5283e+01  6e+01  2e-05  8e-10\n",
      "10:  4.6404e+00 -3.3508e+00  8e+00  4e-08  1e-12\n",
      "11:  6.1471e-01 -4.4176e-01  1e+00  4e-16  6e-16\n",
      "12:  8.1041e-02 -5.8267e-02  1e-01  1e-16  5e-16\n",
      "13:  1.0598e-02 -7.7349e-03  2e-02  5e-17  5e-16\n",
      "14:  1.3597e-03 -1.0436e-03  2e-03  3e-17  5e-16\n",
      "15:  1.8298e-04 -1.4163e-04  3e-04  7e-18  5e-16\n",
      "16:  2.4917e-05 -1.9212e-05  4e-05  3e-18  5e-16\n",
      "17:  3.3912e-06 -2.6022e-06  6e-06  9e-19  4e-16\n",
      "18:  4.6077e-07 -3.5167e-07  8e-07  4e-19  4e-16\n",
      "19:  6.3308e-08 -4.7175e-08  1e-07  2e-19  4e-16\n",
      "20:  8.5603e-09 -6.3072e-09  1e-08  5e-20  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.7536e+04 -5.7222e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.7520e+04 -5.6989e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.3878e+04 -5.4600e+04  8e+03  3e+01  1e-03\n",
      " 3: -5.0232e+04 -4.0911e+04  1e+04  2e+01  8e-04\n",
      " 4: -4.4985e+04 -2.6388e+04  2e+04  2e+01  7e-04\n",
      " 5: -4.1207e+04 -2.0130e+04  2e+04  2e+01  6e-04\n",
      " 6: -3.0150e+04 -9.8116e+03  2e+04  1e+01  5e-04\n",
      " 7:  6.3757e+03 -1.5022e+03  8e+03  1e-14  1e-15\n",
      " 8:  3.3720e+02 -1.7332e+02  5e+02  9e-15  7e-16\n",
      " 9:  3.3528e+01 -2.3071e+01  6e+01  4e-15  6e-16\n",
      "10:  4.1979e+00 -3.0413e+00  7e+00  1e-15  5e-16\n",
      "11:  5.5789e-01 -4.0109e-01  1e+00  5e-16  5e-16\n",
      "12:  7.3614e-02 -5.2899e-02  1e-01  1e-16  5e-16\n",
      "13:  9.6099e-03 -7.0267e-03  2e-02  6e-17  5e-16\n",
      "14:  1.2318e-03 -9.4945e-04  2e-03  2e-17  5e-16\n",
      "15:  1.6590e-04 -1.2911e-04  3e-04  8e-18  5e-16\n",
      "16:  2.2602e-05 -1.7558e-05  4e-05  3e-18  5e-16\n",
      "17:  3.1015e-06 -2.3784e-06  5e-06  1e-18  4e-16\n",
      "18:  4.2333e-07 -3.2060e-07  7e-07  3e-19  4e-16\n",
      "19:  5.8074e-08 -4.2869e-08  1e-07  1e-19  4e-16\n",
      "20:  7.7616e-09 -5.7224e-09  1e-08  5e-20  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.7213e+04 -5.6898e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.7198e+04 -5.6663e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.4038e+04 -5.4216e+04  7e+03  3e+01  1e-03\n",
      " 3: -5.2199e+04 -4.4291e+04  9e+03  2e+01  9e-04\n",
      " 4: -4.7748e+04 -2.9859e+04  1e+04  2e+01  8e-04\n",
      " 5: -4.3402e+04 -2.1837e+04  1e+04  2e+01  7e-04\n",
      " 6: -3.0514e+04 -9.7105e+03  2e+04  1e+01  5e-04\n",
      " 7:  4.6573e+03 -2.1959e+03  1e+04  1e+00  4e-05\n",
      " 8:  5.0430e+02 -2.6522e+02  8e+02  1e-02  4e-07\n",
      " 9:  5.1167e+01 -3.5011e+01  9e+01  8e-05  3e-09\n",
      "10:  6.5136e+00 -4.6762e+00  1e+01  4e-07  1e-11\n",
      "11:  8.5573e-01 -6.1668e-01  1e+00  6e-16  6e-16\n",
      "12:  1.1329e-01 -8.1296e-02  2e-01  2e-16  6e-16\n",
      "13:  1.4824e-02 -1.0773e-02  3e-02  7e-17  6e-16\n",
      "14:  1.9019e-03 -1.4503e-03  3e-03  3e-17  5e-16\n",
      "15:  2.5444e-04 -1.9668e-04  5e-04  9e-18  5e-16\n",
      "16:  3.4610e-05 -2.6675e-05  6e-05  6e-18  5e-16\n",
      "17:  4.7033e-06 -3.6143e-06  8e-06  1e-18  5e-16\n",
      "18:  6.3964e-07 -4.8873e-07  1e-06  4e-19  4e-16\n",
      "19:  8.7651e-08 -6.5665e-08  2e-07  2e-19  4e-16\n",
      "20:  1.1924e-08 -8.7793e-09  2e-08  5e-20  3e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.8124e+04 -5.7811e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.8109e+04 -5.7579e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.5719e+04 -5.5102e+04  5e+03  3e+01  1e-03\n",
      " 3: -5.2758e+04 -4.3234e+04  8e+03  2e+01  8e-04\n",
      " 4: -4.9658e+04 -3.1535e+04  1e+04  2e+01  8e-04\n",
      " 5: -4.5017e+04 -2.2700e+04  1e+04  2e+01  6e-04\n",
      " 6: -3.1775e+04 -9.8669e+03  2e+04  1e+01  5e-04\n",
      " 7:  4.7946e+03 -2.5083e+03  1e+04  1e+00  4e-05\n",
      " 8:  5.7976e+02 -3.0424e+02  9e+02  1e-02  4e-07\n",
      " 9:  5.7867e+01 -4.0442e+01  1e+02  1e-04  4e-09\n",
      "10:  7.4608e+00 -5.4761e+00  1e+01  6e-07  2e-11\n",
      "11:  9.8160e-01 -7.3040e-01  2e+00  5e-16  5e-16\n",
      "12:  1.3145e-01 -9.7482e-02  2e-01  3e-16  6e-16\n",
      "13:  1.7421e-02 -1.3066e-02  3e-02  6e-17  6e-16\n",
      "14:  2.2829e-03 -1.7713e-03  4e-03  2e-17  5e-16\n",
      "15:  3.0677e-04 -2.4181e-04  5e-04  1e-17  5e-16\n",
      "16:  4.1954e-05 -3.3021e-05  7e-05  4e-18  5e-16\n",
      "17:  5.7971e-06 -4.4870e-06  1e-05  2e-18  4e-16\n",
      "18:  7.9548e-07 -6.0644e-07  1e-06  5e-19  5e-16\n",
      "19:  1.0793e-07 -8.1745e-08  2e-07  2e-19  4e-16\n",
      "20:  1.4613e-08 -1.0993e-08  3e-08  8e-20  4e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.7952e+04 -5.7640e+04  1e+03  5e+01  2e-03\n",
      " 1: -5.7936e+04 -5.7413e+04  7e+02  3e+01  1e-03\n",
      " 2: -5.5203e+04 -5.4919e+04  6e+03  3e+01  1e-03\n",
      " 3: -5.2346e+04 -4.3102e+04  9e+03  2e+01  8e-04\n",
      " 4: -4.7788e+04 -2.8906e+04  1e+04  2e+01  7e-04\n",
      " 5: -4.3807e+04 -2.1774e+04  1e+04  2e+01  6e-04\n",
      " 6: -3.1913e+04 -1.0167e+04  2e+04  1e+01  5e-04\n",
      " 7:  5.3443e+03 -2.0943e+03  1e+04  8e-01  3e-05\n",
      " 8:  4.8564e+02 -2.4974e+02  8e+02  7e-03  3e-07\n",
      " 9:  4.8141e+01 -3.3030e+01  8e+01  6e-05  2e-09\n",
      "10:  6.1232e+00 -4.4288e+00  1e+01  3e-07  1e-11\n",
      "11:  8.0754e-01 -5.8541e-01  1e+00  6e-16  6e-16\n",
      "12:  1.0756e-01 -7.7193e-02  2e-01  2e-16  6e-16\n",
      "13:  1.4134e-02 -1.0209e-02  2e-02  9e-17  5e-16\n",
      "14:  1.8078e-03 -1.3719e-03  3e-03  3e-17  5e-16\n",
      "15:  2.4073e-04 -1.8591e-04  4e-04  7e-18  5e-16\n",
      "16:  3.2777e-05 -2.5194e-05  6e-05  3e-18  5e-16\n",
      "17:  4.4375e-06 -3.4147e-06  8e-06  2e-18  5e-16\n",
      "18:  6.0295e-07 -4.6227e-07  1e-06  4e-19  4e-16\n",
      "19:  8.2691e-08 -6.2197e-08  1e-07  2e-19  4e-16\n",
      "20:  1.1293e-08 -8.3056e-09  2e-08  6e-20  3e-16\n",
      "Optimal solution found.\n",
      "RMSE List of IWKRR: [3.9363398639757317, 5.023037661652506, 4.803939858671789, 6.666978556379079, 1.7358164884356782, 3.460346209815064, 3.2387625573903054, 9.867427705258455, 4.393420263602854, 8.498704749153147, 3.8573412257657087, 15.453736441693097, 7.591249876981768, 6.383893708124643, 17.852567791873202, 4.842579030173577, 2.5457028064228444, 6.869075154002829, 3.771664343633124, 10.02300293104854]\n",
      "R^2 List of IWKRR: [0.7737063137815803, 0.7342684317189698, 0.6736670158835412, 0.24608691182681738, 0.6368403109169828, 0.7973594229956321, 0.4149141663387741, 0.44618643147921355, 0.8281096639235493, 0.815986404292722, 0.8414843606580118, 0.5624628538953198, 0.5881668465099743, 0.12947015211394097, 0.02497896520888096, 0.6676224005329529, 0.7005142781214996, 0.9028800624328405, 0.834298304402508, 0.33387921888511374]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 6.540779361202697 4.164909347346431\n",
      "Mean, STDev of R^2: 0.5976441257959413 0.2533687933751801\n"
     ]
    }
   ],
   "source": [
    "#################################### Instance_KRR Housing ################################################################\n",
    "from IW_KRR import InstanceKRR\n",
    "\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 20\n",
    "\n",
    "r2scorelist_IWKRR_housing = []\n",
    "rmselist_IWKRR_housing = []\n",
    "\n",
    "print(\"IWKRR\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(housing_tgt_df):\n",
    "        \n",
    "    housing_train_df_X = housing_tgt_df.iloc[train_idx].loc[:, features_housing]\n",
    "    housing_test_df_X = housing_tgt_df.iloc[test_idx][features_housing]\n",
    "    housing_train_df_y = housing_tgt_df.iloc[train_idx].loc[:,target_housing]\n",
    "    housing_test_df_y = housing_tgt_df.loc[test_idx][target_housing]\n",
    "    \n",
    "    housing_np_tgt_X = housing_train_df_X.to_numpy()\n",
    "    housing_np_tgt_y = housing_train_df_y.to_numpy()\n",
    "\n",
    "        \n",
    "    housing_X_df = pd.concat([housing_source_df_X, housing_train_df_X], ignore_index=True)\n",
    "    housing_y_df = pd.concat([housing_source_df_y, housing_train_df_y], ignore_index=True)\n",
    "\n",
    "    housing_np_train_X = housing_X_df.to_numpy()\n",
    "    housing_np_train_y = housing_y_df.to_numpy()\n",
    "\n",
    "    housing_np_test_X = housing_test_df_X.to_numpy()\n",
    "    housing_np_test_y = housing_test_df_y.to_numpy()\n",
    "\n",
    "    housing_np_train_y_list = housing_np_train_y.ravel()\n",
    "    housing_np_test_y_list = housing_np_test_y.ravel()\n",
    "    \n",
    "    sample_size = [len(housing_source_df_X), len(housing_train_df_X)]\n",
    "\n",
    "\n",
    "    model_IWKRR_housing = InstanceKRR(lmbd = 0.5, kernel = 'rbf',gamma = None, degree = 3, coef0 = 1,kernel_params = None)\n",
    "    model_IWKRR_housing.fit(housing_np_train_X, housing_np_train_y_list)\n",
    "    model_IWKRR_housing.Solve_alpha(housing_np_tgt_X,housing_np_tgt_y)\n",
    "    \n",
    "    y_pred_IWKRR_housing = model_IWKRR_housing.predict(housing_np_test_X)\n",
    "    y_pred_IWKRR_housing = [item for sublist in y_pred_IWKRR_housing for item in sublist]\n",
    "\n",
    "    mse_IWKRR_housing = sqrt(mean_squared_error(housing_np_test_y, y_pred_IWKRR_housing))\n",
    "    rmselist_IWKRR_housing.append(mse_IWKRR_housing)\n",
    "        \n",
    "    r2_score_IWKRR_housing = pearsonr(housing_np_test_y_list, y_pred_IWKRR_housing)\n",
    "    r2_score_IWKRR_housing = (r2_score_IWKRR_housing[0])**2\n",
    "    r2scorelist_IWKRR_housing.append(r2_score_IWKRR_housing)\n",
    "\n",
    "\n",
    "print(\"RMSE List of IWKRR:\", rmselist_IWKRR_housing)\n",
    "print(\"R^2 List of IWKRR:\", r2scorelist_IWKRR_housing)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_IWKRR_housing), statistics.stdev(rmselist_IWKRR_housing))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_IWKRR_housing), statistics.stdev(r2scorelist_IWKRR_housing))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.11320807483759392 0.9111186613495608\n",
      "0.6142376111006888 0.5467442730953394\n",
      "-0.7877168016462025 0.4411126634078205\n",
      "\n",
      "\n",
      "-0.3577646135896259 0.7246802877655424\n",
      "-0.6235793100410496 0.5407261834520463\n",
      "1.9792126669704677 0.06329652761434805\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats_StAd_rmse, pval_StAd_rmse = stats.ttest_ind(rmselist_stradaboost_housing, rmselist_AdaTL_housing)\n",
    "print(stats_StAd_rmse, pval_StAd_rmse)\n",
    "\n",
    "stats_StGb_rmse, pval_StGb_rmse = stats.ttest_ind(rmselist_stradaboost_housing, rmselist_GBRTL_housing)\n",
    "print(stats_StGb_rmse, pval_StGb_rmse)\n",
    "\n",
    "stats_StTr_rmse, pval_StTr_rmse = stats.ttest_ind(rmselist_stradaboost_housing, rmselist_TwoTrAda_housing)\n",
    "print(stats_StTr_rmse, pval_StTr_rmse)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "stats_StAd_r2, pval_StAd_r2 = stats.ttest_ind(r2scorelist_stradaboost_housing, r2scorelist_AdaTL_housing)\n",
    "print(stats_StAd_r2, pval_StAd_r2)\n",
    "\n",
    "stats_StGb_r2, pval_StGb_r2 = stats.ttest_ind(r2scorelist_stradaboost_housing, r2scorelist_GBRTL_housing)\n",
    "print(stats_StGb_r2, pval_StGb_r2)\n",
    "\n",
    "stats_StTr_r2, pval_StTr_r2 = stats.ttest_ind(r2scorelist_stradaboost_housing, r2scorelist_TwoTrAda_housing)\n",
    "print(stats_StTr_r2, pval_StTr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7996854083202125 0.44448619214735663\n",
      "1.7669802852038805 0.11103400281068965\n",
      "-1.7148762764672583 0.12050921388855486\n",
      "\n",
      "\n",
      "-1.1582914763418435 0.2765565179145322\n",
      "-0.9686871369054251 0.35801096964238777\n",
      "2.7169621385318274 0.023725511885053154\n"
     ]
    }
   ],
   "source": [
    "#### Dependent(paired) t-test\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "\n",
    "stats_StAd_rmse, pval_StAd_rmse = stats.ttest_rel(rmselist_stradaboost_housing, rmselist_AdaTL_housing)\n",
    "print(stats_StAd_rmse, pval_StAd_rmse)\n",
    "\n",
    "stats_StGb_rmse, pval_StGb_rmse = stats.ttest_rel(rmselist_stradaboost_housing, rmselist_GBRTL_housing)\n",
    "print(stats_StGb_rmse, pval_StGb_rmse)\n",
    "\n",
    "stats_StTr_rmse, pval_StTr_rmse = stats.ttest_rel(rmselist_stradaboost_housing, rmselist_TwoTrAda_housing)\n",
    "print(stats_StTr_rmse, pval_StTr_rmse)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "stats_StAd_r2, pval_StAd_r2 = stats.ttest_rel(r2scorelist_stradaboost_housing, r2scorelist_AdaTL_housing)\n",
    "print(stats_StAd_r2, pval_StAd_r2)\n",
    "\n",
    "stats_StGb_r2, pval_StGb_r2 = stats.ttest_rel(r2scorelist_stradaboost_housing, r2scorelist_GBRTL_housing)\n",
    "print(stats_StGb_r2, pval_StGb_r2)\n",
    "\n",
    "stats_StTr_r2, pval_StTr_r2 = stats.ttest_rel(r2scorelist_stradaboost_housing, r2scorelist_TwoTrAda_housing)\n",
    "print(stats_StTr_r2, pval_StTr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Input data is:  (392, 8)\n",
      "Target Set:  (119, 7)\n",
      "Source Set 1:  (157, 7)\n",
      "Source Set 2:  (116, 7)\n"
     ]
    }
   ],
   "source": [
    "######################################################## Automobile ################################################################\n",
    "## horsepower column has correlation 0.4 :: [46 - 230] :: 30\n",
    "#################################################################################################################################\n",
    "dropcol_initial_auto = ['name']\n",
    "AutoData_df = pd.read_csv('UCI_regression/MPG/Auto.csv') ## horsepower column has correlation 0.4 :: [46 - 230] :: 30\n",
    "AutoData_df = AutoData_df.drop(dropcol_initial_auto, axis = 1)\n",
    "print(\"The shape of the Input data is: \", AutoData_df.shape)\n",
    "\n",
    "drop_col_auto = ['horsepower']\n",
    "\n",
    "auto_tgt_df = AutoData_df.loc[(AutoData_df['horsepower'] <= 80)]\n",
    "auto_tgt_df = auto_tgt_df.drop(drop_col_auto, axis = 1)\n",
    "auto_tgt_df = auto_tgt_df.reset_index(drop=True)\n",
    "print(\"Target Set: \",auto_tgt_df.shape)\n",
    "\n",
    "auto_source1_df = AutoData_df.loc[(AutoData_df['horsepower'] > 80) & (AutoData_df['horsepower'] <= 110)]\n",
    "auto_source1_df = auto_source1_df.drop(drop_col_auto, axis = 1)\n",
    "auto_source1_df = auto_source1_df.reset_index(drop=True)\n",
    "print(\"Source Set 1: \",auto_source1_df.shape)\n",
    "\n",
    "auto_source2_df = AutoData_df.loc[(AutoData_df['horsepower'] > 110)]\n",
    "auto_source2_df = auto_source2_df.drop(drop_col_auto, axis = 1)\n",
    "auto_source2_df = auto_source2_df.reset_index(drop=True)\n",
    "print(\"Source Set 2: \",auto_source2_df.shape)\n",
    "\n",
    "################################# Standardization ############################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "auto_cols = auto_tgt_df.columns.difference(['medv'])\n",
    "\n",
    "ss = StandardScaler()\n",
    "auto_tgt_df[auto_cols] = ss.fit_transform(auto_tgt_df[auto_cols])\n",
    "auto_source1_df[auto_cols] = ss.fit_transform(auto_source1_df[auto_cols])\n",
    "auto_source2_df[auto_cols] = ss.fit_transform(auto_source2_df[auto_cols])\n",
    "\n",
    "## Concatenating the source datasets\n",
    "auto_source_df = pd.concat([auto_source1_df, auto_source2_df], ignore_index = True)\n",
    "auto_source_df = auto_source_df.reset_index(drop = True)\n",
    "\n",
    "#################### Splitting into features and target ####################\n",
    "target_auto = ['mpg']\n",
    "\n",
    "auto_source_df_y = auto_source_df[target_auto]\n",
    "auto_source_df_X = auto_source_df.drop(target_auto, axis = 1)\n",
    "\n",
    "features_auto = auto_source_df_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of TrAdaboost.R2: [0.4243043188387373, 0.517195423770981, 0.6519664186500195, 0.31278770618508533, 0.9106076952664754, 0.7497905408530762, 0.7627149189699569, 1.121907562688717, 0.5554295196299659, 0.7564328904509023]\n",
      "R^2 List of TrAdaboost.R2: [0.6554314111862946, 0.692713134420256, 0.6919383600901492, 0.8320631128745823, 0.12787056044070017, 0.6518615219543017, 0.3360064656178717, 0.0010568568496436836, 0.015296602690126363, 0.08681036876262815]\n",
      "\n",
      "\n",
      "Mean, Stdev of RMSE: 0.6763136995303917 0.23779424942091276\n",
      "Mean, Stdev of R^2: 0.4091048394886554 0.32809681066253876\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### TwoStage-TrAdaBoostR2 Auto #######################################\n",
    "\n",
    "from adapt.instance_based import TrAdaBoost, TrAdaBoostR2, TwoStageTrAdaBoostR2\n",
    "\n",
    "\n",
    "def get_estimator(**kwargs):\n",
    "    return DecisionTreeRegressor(max_depth = 6)\n",
    "\n",
    "kwargs_TwoTrAda = {'steps': 30,\n",
    "                    'fold': 10,\n",
    "                  'learning_rate': 0.1}\n",
    "\n",
    "###########################################################################################################################\n",
    "\n",
    "print(\"Two-Stage TrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_TwoTrAda_auto = []\n",
    "rmselist_TwoTrAda_auto = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "\n",
    "for train_idx, test_idx in kf.split(auto_tgt_df):\n",
    "        \n",
    "    auto_train_df_X = auto_tgt_df.iloc[train_idx].loc[:, features_auto]\n",
    "    auto_test_df_X = auto_tgt_df.iloc[test_idx][features_auto]\n",
    "    auto_train_df_y = auto_tgt_df.iloc[train_idx].loc[:,target_auto]\n",
    "    auto_test_df_y = auto_tgt_df.loc[test_idx][target_auto]\n",
    "    \n",
    "    auto_X_df = pd.concat([auto_source_df_X, auto_train_df_X], ignore_index=True)\n",
    "    auto_y_df = pd.concat([auto_source_df_y, auto_train_df_y], ignore_index=True)\n",
    "\n",
    "    auto_np_train_X = auto_X_df.to_numpy()\n",
    "    auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "    auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "    auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "    auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "    auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "\n",
    "    src_size_auto = len(auto_source_df_y)\n",
    "    tgt_size_auto = len(auto_train_df_y)\n",
    "    \n",
    "    src_idx_auto = np.arange(start=0, stop=(src_size_auto - 1), step=1)\n",
    "    tgt_idx_auto = np.arange(start=src_size_auto, stop=((src_size_auto + tgt_size_auto)-1), step=1)\n",
    "\n",
    "\n",
    "    model_TwoTrAda_auto = TwoStageTrAdaBoostR2(get_estimator = get_estimator, n_estimators = 100) #, cv = 10) \n",
    "    model_TwoTrAda_auto.fit(auto_np_train_X, auto_np_train_y_list, src_idx_auto, tgt_idx_auto)\n",
    "\n",
    "    y_pred_TwoTrAda_auto = model_TwoTrAda_auto.predict(auto_np_test_X)\n",
    "\n",
    "    mse_TwoTrAda_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_TwoTrAda_auto))\n",
    "    rmselist_TwoTrAda_auto.append(mse_TwoTrAda_auto)\n",
    "        \n",
    "    r2_score_TwoTrAda_auto = pearsonr(auto_np_test_y_list, y_pred_TwoTrAda_auto)\n",
    "    r2_score_TwoTrAda_auto = (r2_score_TwoTrAda_auto[0])**2\n",
    "    r2scorelist_TwoTrAda_auto.append(r2_score_TwoTrAda_auto)\n",
    "\n",
    "\n",
    "print(\"RMSE List of TrAdaboost.R2:\", rmselist_TwoTrAda_auto)\n",
    "print(\"R^2 List of TrAdaboost.R2:\", r2scorelist_TwoTrAda_auto)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, Stdev of RMSE:\", statistics.mean(rmselist_TwoTrAda_auto), statistics.stdev(rmselist_TwoTrAda_auto))\n",
    "print(\"Mean, Stdev of R^2:\", statistics.mean(r2scorelist_TwoTrAda_auto), statistics.stdev(r2scorelist_TwoTrAda_auto))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Stage STrAdaboost.R2\n",
      "-------------------------------------------\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "Inside Updated Sampling TrAdaBoost.R2\n",
      "RMSE List of STrAdaboostR2: [0.5582854151910699, 0.4436385935251228, 0.6053261547923454, 0.45073472858445096, 0.9299787194313835, 0.4053955864341286, 0.9734016786434954, 1.0113509646269083, 0.30055525875003813, 0.506236630402056]\n",
      "R^2 List of STrAdaboostR2: [0.8264871364575337, 0.5535348790808966, 0.8478100005728715, 0.8284247951938495, 0.04558676968026823, 0.5657909125356079, 0.3070933003253697, 0.05651190865072696, 0.5732291139313791, 0.5207809014653438]\n",
      "\n",
      "\n",
      "Mean, Stdev of RMSE: 0.6184903730381 0.2579691048590702\n",
      "Mean, Stdev of R^2: 0.5125249717893847 0.29575413699869174\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#################################### STrAdaBoost.R2 Active Sampling Auto ################################################################\n",
    "from two_TrAdaBoostR2 import TwoStageTrAdaBoostR2\n",
    "\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 10\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "r2scorelist_stradaboost_auto = []\n",
    "rmselist_stradaboost_auto = []\n",
    "\n",
    "print(\"Two-Stage STrAdaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "\n",
    "for train_idx, test_idx in kf.split(auto_tgt_df):\n",
    "\n",
    "    auto_train_df_X = auto_tgt_df.iloc[train_idx].loc[:, features_auto]\n",
    "    auto_test_df_X = auto_tgt_df.iloc[test_idx][features_auto]\n",
    "    auto_train_df_y = auto_tgt_df.iloc[train_idx].loc[:,target_auto]\n",
    "    auto_test_df_y = auto_tgt_df.loc[test_idx][target_auto]\n",
    "\n",
    "    auto_X_df = pd.concat([auto_source_df_X, auto_train_df_X], ignore_index=True)\n",
    "    auto_y_df = pd.concat([auto_source_df_y, auto_train_df_y], ignore_index=True)\n",
    "\n",
    "    auto_np_train_X = auto_X_df.to_numpy()\n",
    "    auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "    auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "    auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "    auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "    auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "\n",
    "    sample_size = [len(auto_source_df_X), len(auto_train_df_X)]\n",
    "\n",
    "\n",
    "    model_stradaboost_auto = TwoStageTrAdaBoostR2(DecisionTreeRegressor(max_depth = 6),\n",
    "                        n_estimators = n_estimators, sample_size = sample_size,\n",
    "                        steps = steps, fold = fold, random_state = random_state)\n",
    "\n",
    "\n",
    "    model_stradaboost_auto.fit(auto_np_train_X, auto_np_train_y_list)\n",
    "    y_pred_stradaboost_auto = model_stradaboost_auto.predict(auto_np_test_X)\n",
    "\n",
    "\n",
    "    mse_stradaboost_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_stradaboost_auto))\n",
    "    rmselist_stradaboost_auto.append(mse_stradaboost_auto)\n",
    "\n",
    "    r2_score_stradaboost_auto = pearsonr(auto_np_test_y_list, y_pred_stradaboost_auto)\n",
    "    r2_score_stradaboost_auto = (r2_score_stradaboost_auto[0])**2\n",
    "    r2scorelist_stradaboost_auto.append(r2_score_stradaboost_auto)\n",
    "\n",
    "\n",
    "print(\"RMSE List of STrAdaboostR2:\", rmselist_stradaboost_auto)\n",
    "print(\"R^2 List of STrAdaboostR2:\", r2scorelist_stradaboost_auto)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, Stdev of RMSE:\", statistics.mean(rmselist_stradaboost_auto), statistics.stdev(rmselist_stradaboost_auto))\n",
    "print(\"Mean, Stdev of R^2:\", statistics.mean(r2scorelist_stradaboost_auto), statistics.stdev(r2scorelist_stradaboost_auto))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost.R2 Transfer Learning\n",
      "-------------------------------------------\n",
      "RMSE List of TL Adaboost.R2: [0.5135340662862089, 0.45359876137148253, 0.5592345186096519, 0.3134179943083618, 0.8944293662623398, 0.397764732639691, 0.9622384274167044, 0.9788976778450925, 0.30320142517921744, 0.48423314234349674]\n",
      "R^2 List of TL Adaboost.R2: [0.8274059627537894, 0.6488743694737944, 0.8217234574146408, 0.8640250561996212, 0.10495483046155453, 0.5214274608220493, 0.4256364319788598, 0.0587711740828452, 0.5886460061348928, 0.5412400077405197]\n",
      "\n",
      "\n",
      "Mean, Stdev of RMSE: 0.5860550112262247 0.2613246951608417\n",
      "Mean, Stdev of R^2: 0.5402704757062567 0.2819481525530993\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "########################### AdaBoostR2 Transfer Learning Auto #####################################################\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "print(\"Adaboost.R2 Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_AdaTL_auto = []\n",
    "rmselist_AdaTL_auto = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(auto_tgt_df):\n",
    "        \n",
    "    auto_train_df_X = auto_tgt_df.iloc[train_idx].loc[:, features_auto]\n",
    "    auto_test_df_X = auto_tgt_df.iloc[test_idx][features_auto]\n",
    "    auto_train_df_y = auto_tgt_df.iloc[train_idx].loc[:,target_auto]\n",
    "    auto_test_df_y = auto_tgt_df.loc[test_idx][target_auto]\n",
    "    \n",
    "    auto_X_df = pd.concat([auto_source_df_X, auto_train_df_X], ignore_index = True)\n",
    "    auto_y_df = pd.concat([auto_source_df_y, auto_train_df_y], ignore_index = True)\n",
    "\n",
    "    auto_np_train_X = auto_X_df.to_numpy()\n",
    "    auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "    auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "    auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "    auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "    auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "\n",
    "\n",
    "    model_AdaTL_auto = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_AdaTL_auto.fit(auto_np_train_X, auto_np_train_y_list)\n",
    "\n",
    "    y_pred_AdaTL_auto = model_AdaTL_auto.predict(auto_np_test_X)\n",
    "\n",
    "    mse_AdaTL_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_AdaTL_auto))\n",
    "    rmselist_AdaTL_auto.append(mse_AdaTL_auto)\n",
    "        \n",
    "    r2_score_AdaTL_auto = pearsonr(auto_np_test_y_list, y_pred_AdaTL_auto)\n",
    "    r2_score_AdaTL_auto = (r2_score_AdaTL_auto[0])**2\n",
    "    r2scorelist_AdaTL_auto.append(r2_score_AdaTL_auto)\n",
    "\n",
    "print(\"RMSE List of TL Adaboost.R2:\", rmselist_AdaTL_auto)\n",
    "print(\"R^2 List of TL Adaboost.R2:\", r2scorelist_AdaTL_auto)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "print(\"Mean, Stdev of RMSE:\", statistics.mean(rmselist_AdaTL_auto), statistics.stdev(rmselist_AdaTL_auto))\n",
    "print(\"Mean, Stdev of R^2:\", statistics.mean(r2scorelist_AdaTL_auto), statistics.stdev(r2scorelist_AdaTL_auto))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regression Transfer Learning\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of GBRTL: [0.4799244385805726, 0.3587433734146151, 0.5365625957008113, 0.33479450177460846, 0.7964150001985001, 0.33743326679686797, 0.7912499860574775, 0.8972658678878713, 0.36048449001455546, 0.5728416221664219]\n",
      "R^2 List of GBRTL: [0.8541224062235835, 0.6386941888664273, 0.7540019820483619, 0.7868740060520802, 0.14682011249376833, 0.6124702169484553, 0.45062813434510973, 0.08525885072998268, 0.5428910694971595, 0.36585768008897507]\n",
      "\n",
      "\n",
      "Mean, RMSE of GBRTL: 0.5465715142592302 0.21317808988559206\n",
      "R^2 of GBRTL: 0.5237618647293903 0.2619315829208315\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:434: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "######################### Gradient Boosting Regression Transfer Learning Auto #######################################\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "print(\"Gradient Boosting Regression Transfer Learning\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBRTL_auto = []\n",
    "rmselist_GBRTL_auto = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(auto_tgt_df):\n",
    "        \n",
    "    auto_train_df_X = auto_tgt_df.iloc[train_idx].loc[:, features_auto]\n",
    "    auto_test_df_X = auto_tgt_df.iloc[test_idx][features_auto]\n",
    "    auto_train_df_y = auto_tgt_df.iloc[train_idx].loc[:,target_auto]\n",
    "    auto_test_df_y = auto_tgt_df.loc[test_idx][target_auto]\n",
    "    \n",
    "    auto_X_df = pd.concat([auto_source_df_X, auto_train_df_X], ignore_index = True)\n",
    "    auto_y_df = pd.concat([auto_source_df_y, auto_train_df_y], ignore_index = True)\n",
    "\n",
    "    auto_np_train_X = auto_X_df.to_numpy()\n",
    "    auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "    auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "    auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "    auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "    auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "\n",
    "\n",
    "    model_GBRTL_auto = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100) #, subsample=0.5)\n",
    "    model_GBRTL_auto.fit(auto_np_train_X, auto_np_train_y_list)\n",
    "\n",
    "    y_pred_GBRTL_auto = model_GBRTL_auto.predict(auto_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBRTL_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_GBRTL_auto))\n",
    "    rmselist_GBRTL_auto.append(mse_GBRTL_auto)\n",
    "        \n",
    "    r2_score_GBRTL_auto = pearsonr(auto_np_test_y_list, y_pred_GBRTL_auto)\n",
    "    r2_score_GBRTL_auto = (r2_score_GBRTL_auto[0])**2\n",
    "    r2scorelist_GBRTL_auto.append(r2_score_GBRTL_auto)\n",
    "\n",
    "print(\"RMSE List of GBRTL:\", rmselist_GBRTL_auto)\n",
    "print(\"R^2 List of GBRTL:\", r2scorelist_GBRTL_auto)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "    \n",
    "print(\"Mean, RMSE of GBRTL:\", statistics.mean(rmselist_GBRTL_auto), statistics.stdev(rmselist_GBRTL_auto))\n",
    "print(\"R^2 of GBRTL:\", statistics.mean(r2scorelist_GBRTL_auto), statistics.stdev(r2scorelist_GBRTL_auto))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Adaboost.R2\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE List of Adaboost.R2: [0.3838967893594653, 0.3416413881894274, 0.2444321236897413, 0.4134993068092464, 0.3709401141947047, 0.1786142749270033, 0.24919616448757317, 0.15499934723398578, 0.4739698919547968, 1.0960643191736616, 0.8172329492391315, 0.5271224814343081, 0.7499156277237901, 0.8037198409069433, 1.3484439312594783, 0.4819283676525053, 0.3744363655820952, 0.46083800714169637, 0.4751592297097938, 0.6371578939922319]\n",
      "R^2 List of AdaboostR2: [0.7961340532907566, 0.6814159292035401, 0.8381651463542741, 0.6259306225967437, 0.9126853485955568, 0.9709864638373563, 0.9617322427974916, 0.8577780767225823, 0.35937500000000006, 0.15605923821316103, 0.007166725734026551, 0.9139501711048148, 0.35168881129652324, 0.5998422086175346, 0.005163363839464342, 0.1121307660259244, 0.44735507370562944, 0.22573263103730093, 0.006431167166500816, 0.8151839542147438]\n",
      "\n",
      "\n",
      "RMSE of Adaboost.R2: 0.529160420733079 0.30480196053791286\n",
      "R^2 of AdaboostR2: 0.5322453497176963 0.3527255563759451\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but AdaBoostRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "########################### Regular AdaBoostR2 Auto #####################################################\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "print(\"Regular Adaboost.R2\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_Ada_auto = []\n",
    "rmselist_Ada_auto = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(auto_tgt_df):\n",
    "        \n",
    "    auto_train_df_X = auto_tgt_df.iloc[train_idx].loc[:, features_auto]\n",
    "    auto_test_df_X = auto_tgt_df.iloc[test_idx][features_auto]\n",
    "    auto_train_df_y = auto_tgt_df.iloc[train_idx].loc[:,target_auto]\n",
    "    auto_test_df_y = auto_tgt_df.loc[test_idx][target_auto]\n",
    "    \n",
    "    auto_np_train_X = auto_X_df.to_numpy()\n",
    "    auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "    auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "    auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "    auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "    auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "\n",
    "    model_Ada_auto = AdaBoostRegressor(DecisionTreeRegressor(max_depth = 6), learning_rate = 0.1, n_estimators = 100) \n",
    "    model_Ada_auto.fit(auto_train_df_X, auto_train_df_y)\n",
    "\n",
    "    y_pred_Ada_auto = model_Ada_auto.predict(auto_np_test_X)\n",
    "\n",
    "    mse_Ada_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_Ada_auto))\n",
    "    rmselist_Ada_auto.append(mse_Ada_auto)\n",
    "        \n",
    "    r2_score_Ada_auto = pearsonr(auto_np_test_y_list, y_pred_Ada_auto)\n",
    "    r2_score_Ada_auto = (r2_score_Ada_auto[0])**2\n",
    "    r2scorelist_Ada_auto.append(r2_score_Ada_auto)\n",
    "\n",
    "\n",
    "print(\"RMSE List of Adaboost.R2:\", rmselist_Ada_auto)\n",
    "print(\"R^2 List of AdaboostR2:\", r2scorelist_Ada_auto)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "    \n",
    "print(\"RMSE of Adaboost.R2:\", statistics.mean(rmselist_Ada_auto), statistics.stdev(rmselist_Ada_auto))\n",
    "print(\"R^2 of AdaboostR2:\", statistics.mean(r2scorelist_Ada_auto), statistics.stdev(r2scorelist_Ada_auto))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular Gradient Boosting Regression\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of GBR: [0.40787943913669134, 0.2193633266759435, 0.1678248517980159, 0.4376083979207031, 0.34977136736838477, 0.18362487883938727, 0.6360561321614489, 0.2322512635852351, 0.5883978595318685, 1.0568290174850532, 0.9503625731601781, 0.8094510664448067, 0.7817492676919726, 0.7507974751323631, 1.4249819039153397, 0.6753750787482214, 0.5071647176809019, 0.4793262957279925, 0.6699053141446059, 0.8196833685896063]\n",
      "R^2 of GBR: [0.8474887707004102, 0.7361211046117644, 0.9277432136842418, 0.4955977998874099, 0.9035499525835932, 0.9700073856070317, 0.7207497640024061, 0.6794319361850766, 0.38882572134361687, 0.040260676740455976, 0.030259282993436196, 0.32552795947652097, 0.017954372839371135, 0.6739668466488907, 0.0005995911591421167, 0.10096524683658224, 0.005749554076190218, 0.1761496944819733, 0.00024647177580027597, 0.4792864200903471]\n",
      "\n",
      "\n",
      "RMSE of GBR: 0.607420179786936 0.32119758753226374\n",
      "R^2 of GBR: 0.426024088286213 0.35983521449936356\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrey/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "######################### Regular Gradient Boosting Regression Auto #######################################\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "print(\"Regular Gradient Boosting Regression\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_GBR_auto = []\n",
    "rmselist_GBR_auto = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(auto_tgt_df):\n",
    "        \n",
    "    auto_train_df_X = auto_tgt_df.iloc[train_idx].loc[:, features_auto]\n",
    "    auto_test_df_X = auto_tgt_df.iloc[test_idx][features_auto]\n",
    "    auto_train_df_y = auto_tgt_df.iloc[train_idx].loc[:,target_auto]\n",
    "    auto_test_df_y = auto_tgt_df.loc[test_idx][target_auto]\n",
    "    \n",
    "    auto_np_train_X = auto_X_df.to_numpy()\n",
    "    auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "    auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "    auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "    auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "    auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "\n",
    "    model_GBR_auto = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 100)\n",
    "    model_GBR_auto.fit(auto_train_df_X, auto_train_df_y)\n",
    "    \n",
    "    y_pred_GBR_auto = model_GBR_auto.predict(auto_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_GBR_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_GBR_auto))\n",
    "    rmselist_GBR_auto.append(mse_GBR_auto)\n",
    "        \n",
    "    r2_score_GBR_auto = pearsonr(auto_np_test_y_list, y_pred_GBR_auto)\n",
    "    r2_score_GBR_auto = (r2_score_GBR_auto[0])**2\n",
    "    r2scorelist_GBR_auto.append(r2_score_GBR_auto)\n",
    "\n",
    "print(\"RMSE of GBR:\", rmselist_GBR_auto)\n",
    "print(\"R^2 of GBR:\", r2scorelist_GBR_auto)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of GBR:\", statistics.mean(rmselist_GBR_auto), statistics.stdev(rmselist_GBR_auto))\n",
    "print(\"R^2 of GBR:\", statistics.mean(r2scorelist_GBR_auto), statistics.stdev(r2scorelist_GBR_auto))\n",
    "\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Mean Matching\n",
      "-------------------------------------------\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -6.0142e+02 -2.3284e+06  6e+07  3e-01  2e-15\n",
      " 1: -6.3825e+03 -6.1530e+05  1e+06  3e-03  4e-13\n",
      " 2: -4.5562e+03 -1.3790e+05  1e+05  2e-05  5e-13\n",
      " 3: -5.7765e+03 -3.4440e+04  3e+04  5e-06  1e-13\n",
      " 4: -9.7438e+03 -3.5943e+04  3e+04  5e-16  3e-15\n",
      " 5: -1.1919e+04 -1.9794e+04  8e+03  2e-16  6e-16\n",
      " 6: -1.2284e+04 -1.8402e+04  6e+03  2e-16  5e-16\n",
      " 7: -1.2677e+04 -1.4142e+04  1e+03  2e-16  4e-16\n",
      " 8: -1.2825e+04 -1.3235e+04  4e+02  2e-16  5e-16\n",
      " 9: -1.2889e+04 -1.3015e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2907e+04 -1.2960e+04  5e+01  2e-16  4e-16\n",
      "11: -1.2919e+04 -1.2932e+04  1e+01  2e-16  5e-16\n",
      "12: -1.2923e+04 -1.2924e+04  2e+00  2e-16  5e-16\n",
      "13: -1.2923e+04 -1.2923e+04  2e-01  2e-16  5e-16\n",
      "14: -1.2923e+04 -1.2923e+04  4e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.7440e+02 -2.3230e+06  6e+07  3e-01  3e-15\n",
      " 1: -6.2853e+03 -6.1506e+05  1e+06  3e-03  3e-13\n",
      " 2: -4.3806e+03 -1.3907e+05  1e+05  2e-05  3e-13\n",
      " 3: -5.6317e+03 -3.4367e+04  3e+04  5e-06  9e-14\n",
      " 4: -9.5877e+03 -3.5773e+04  3e+04  5e-16  2e-15\n",
      " 5: -1.1818e+04 -1.9823e+04  8e+03  2e-16  5e-16\n",
      " 6: -1.2177e+04 -1.8437e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2569e+04 -1.4098e+04  2e+03  1e-16  5e-16\n",
      " 8: -1.2714e+04 -1.3162e+04  4e+02  2e-16  4e-16\n",
      " 9: -1.2782e+04 -1.2902e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2804e+04 -1.2836e+04  3e+01  2e-16  5e-16\n",
      "11: -1.2813e+04 -1.2818e+04  5e+00  2e-16  5e-16\n",
      "12: -1.2814e+04 -1.2815e+04  8e-01  2e-16  5e-16\n",
      "13: -1.2815e+04 -1.2815e+04  4e-02  2e-16  5e-16\n",
      "14: -1.2815e+04 -1.2815e+04  9e-04  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8286e+02 -2.3330e+06  6e+07  3e-01  5e-15\n",
      " 1: -6.0394e+03 -6.1515e+05  1e+06  3e-03  7e-13\n",
      " 2: -4.1422e+03 -1.3858e+05  1e+05  2e-05  3e-13\n",
      " 3: -5.3947e+03 -3.4327e+04  3e+04  5e-06  7e-14\n",
      " 4: -9.4215e+03 -3.5865e+04  3e+04  5e-16  2e-15\n",
      " 5: -1.1651e+04 -1.9475e+04  8e+03  2e-16  5e-16\n",
      " 6: -1.1999e+04 -1.8190e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2392e+04 -1.3928e+04  2e+03  2e-16  5e-16\n",
      " 8: -1.2538e+04 -1.2989e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.2607e+04 -1.2743e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2625e+04 -1.2682e+04  6e+01  2e-16  4e-16\n",
      "11: -1.2635e+04 -1.2656e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2641e+04 -1.2645e+04  4e+00  2e-16  5e-16\n",
      "13: -1.2642e+04 -1.2642e+04  5e-01  2e-16  5e-16\n",
      "14: -1.2642e+04 -1.2642e+04  1e-02  2e-16  5e-16\n",
      "15: -1.2642e+04 -1.2642e+04  2e-04  2e-16  6e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.1770e+02 -2.3526e+06  6e+07  3e-01  4e-15\n",
      " 1: -5.9106e+03 -6.1592e+05  1e+06  3e-03  3e-13\n",
      " 2: -3.9910e+03 -1.3961e+05  1e+05  2e-05  3e-13\n",
      " 3: -5.2510e+03 -3.4330e+04  3e+04  5e-06  6e-14\n",
      " 4: -9.3042e+03 -3.5839e+04  3e+04  6e-16  2e-15\n",
      " 5: -1.1581e+04 -1.9403e+04  8e+03  2e-16  6e-16\n",
      " 6: -1.1925e+04 -1.8139e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2325e+04 -1.3853e+04  2e+03  2e-16  4e-16\n",
      " 8: -1.2474e+04 -1.2936e+04  5e+02  2e-16  4e-16\n",
      " 9: -1.2542e+04 -1.2698e+04  2e+02  2e-16  5e-16\n",
      "10: -1.2563e+04 -1.2621e+04  6e+01  2e-16  5e-16\n",
      "11: -1.2572e+04 -1.2601e+04  3e+01  2e-16  5e-16\n",
      "12: -1.2579e+04 -1.2584e+04  6e+00  2e-16  5e-16\n",
      "13: -1.2580e+04 -1.2581e+04  5e-01  2e-16  5e-16\n",
      "14: -1.2581e+04 -1.2581e+04  1e-02  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.5749e+02 -2.3377e+06  6e+07  3e-01  3e-15\n",
      " 1: -5.9750e+03 -6.1524e+05  1e+06  3e-03  3e-13\n",
      " 2: -4.1064e+03 -1.3788e+05  1e+05  2e-05  3e-13\n",
      " 3: -5.3542e+03 -3.4266e+04  3e+04  5e-06  7e-14\n",
      " 4: -9.3909e+03 -3.5850e+04  3e+04  6e-16  2e-15\n",
      " 5: -1.1588e+04 -1.9241e+04  8e+03  2e-16  5e-16\n",
      " 6: -1.1925e+04 -1.8044e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2312e+04 -1.3806e+04  1e+03  2e-16  5e-16\n",
      " 8: -1.2457e+04 -1.2907e+04  4e+02  2e-16  5e-16\n",
      " 9: -1.2522e+04 -1.2680e+04  2e+02  2e-16  5e-16\n",
      "10: -1.2543e+04 -1.2603e+04  6e+01  2e-16  4e-16\n",
      "11: -1.2553e+04 -1.2576e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2558e+04 -1.2565e+04  6e+00  2e-16  5e-16\n",
      "13: -1.2560e+04 -1.2561e+04  8e-01  2e-16  6e-16\n",
      "14: -1.2561e+04 -1.2561e+04  3e-02  2e-16  5e-16\n",
      "15: -1.2561e+04 -1.2561e+04  6e-04  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.5709e+02 -2.3551e+06  6e+07  3e-01  3e-15\n",
      " 1: -5.9441e+03 -6.1601e+05  1e+06  3e-03  3e-13\n",
      " 2: -4.0453e+03 -1.3889e+05  1e+05  2e-05  4e-13\n",
      " 3: -5.2972e+03 -3.4286e+04  3e+04  5e-06  7e-14\n",
      " 4: -9.3236e+03 -3.5794e+04  3e+04  5e-16  3e-15\n",
      " 5: -1.1573e+04 -1.9207e+04  8e+03  2e-16  6e-16\n",
      " 6: -1.1903e+04 -1.8031e+04  6e+03  2e-16  5e-16\n",
      " 7: -1.2295e+04 -1.3817e+04  2e+03  2e-16  4e-16\n",
      " 8: -1.2443e+04 -1.2890e+04  4e+02  2e-16  5e-16\n",
      " 9: -1.2510e+04 -1.2656e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2531e+04 -1.2580e+04  5e+01  2e-16  5e-16\n",
      "11: -1.2538e+04 -1.2564e+04  3e+01  2e-16  5e-16\n",
      "12: -1.2544e+04 -1.2548e+04  4e+00  2e-16  5e-16\n",
      "13: -1.2546e+04 -1.2546e+04  3e-01  2e-16  5e-16\n",
      "14: -1.2546e+04 -1.2546e+04  7e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.4781e+02 -2.3436e+06  6e+07  3e-01  5e-15\n",
      " 1: -6.1536e+03 -6.1568e+05  1e+06  3e-03  4e-13\n",
      " 2: -4.2846e+03 -1.3798e+05  1e+05  2e-05  4e-13\n",
      " 3: -5.5264e+03 -3.4310e+04  3e+04  5e-06  6e-14\n",
      " 4: -9.5232e+03 -3.5832e+04  3e+04  5e-16  3e-15\n",
      " 5: -1.1722e+04 -1.9470e+04  8e+03  2e-16  6e-16\n",
      " 6: -1.2065e+04 -1.8237e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2462e+04 -1.3990e+04  2e+03  2e-16  5e-16\n",
      " 8: -1.2609e+04 -1.3092e+04  5e+02  2e-16  4e-16\n",
      " 9: -1.2684e+04 -1.2809e+04  1e+02  1e-16  5e-16\n",
      "10: -1.2704e+04 -1.2754e+04  5e+01  2e-16  5e-16\n",
      "11: -1.2714e+04 -1.2730e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2719e+04 -1.2722e+04  4e+00  2e-16  5e-16\n",
      "13: -1.2720e+04 -1.2720e+04  4e-01  2e-16  5e-16\n",
      "14: -1.2720e+04 -1.2720e+04  7e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  2.6845e+01 -2.3606e+06  6e+07  3e-01  6e-15\n",
      " 1: -5.6897e+03 -6.1592e+05  1e+06  3e-03  7e-13\n",
      " 2: -3.7986e+03 -1.3841e+05  1e+05  2e-05  5e-13\n",
      " 3: -5.0499e+03 -3.4250e+04  3e+04  5e-06  1e-13\n",
      " 4: -9.1360e+03 -3.5887e+04  3e+04  5e-16  2e-15\n",
      " 5: -1.1384e+04 -1.8903e+04  8e+03  2e-16  5e-16\n",
      " 6: -1.1705e+04 -1.7815e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2089e+04 -1.3676e+04  2e+03  2e-16  5e-16\n",
      " 8: -1.2242e+04 -1.2700e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.2310e+04 -1.2453e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2329e+04 -1.2384e+04  5e+01  2e-16  4e-16\n",
      "11: -1.2338e+04 -1.2362e+04  2e+01  2e-16  6e-16\n",
      "12: -1.2345e+04 -1.2348e+04  4e+00  2e-16  5e-16\n",
      "13: -1.2346e+04 -1.2346e+04  6e-01  2e-16  5e-16\n",
      "14: -1.2346e+04 -1.2346e+04  1e-02  2e-16  5e-16\n",
      "15: -1.2346e+04 -1.2346e+04  2e-04  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  3.6905e+02 -2.4005e+06  6e+07  3e-01  2e-15\n",
      " 1: -5.3292e+03 -6.1697e+05  1e+06  3e-03  9e-13\n",
      " 2: -3.4474e+03 -1.3666e+05  1e+05  2e-05  2e-13\n",
      " 3: -4.7044e+03 -3.4096e+04  3e+04  5e-06  6e-14\n",
      " 4: -8.8876e+03 -3.5976e+04  3e+04  5e-16  2e-15\n",
      " 5: -1.1095e+04 -1.8189e+04  7e+03  2e-16  5e-16\n",
      " 6: -1.1401e+04 -1.7239e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.1784e+04 -1.3287e+04  2e+03  2e-16  5e-16\n",
      " 8: -1.1934e+04 -1.2364e+04  4e+02  2e-16  4e-16\n",
      " 9: -1.2002e+04 -1.2137e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2020e+04 -1.2075e+04  5e+01  2e-16  5e-16\n",
      "11: -1.2030e+04 -1.2052e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2035e+04 -1.2040e+04  4e+00  2e-16  5e-16\n",
      "13: -1.2036e+04 -1.2037e+04  7e-01  2e-16  5e-16\n",
      "14: -1.2037e+04 -1.2037e+04  2e-02  2e-16  5e-16\n",
      "15: -1.2037e+04 -1.2037e+04  2e-04  2e-16  6e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.9760e+02 -2.3915e+06  6e+07  3e-01  3e-15\n",
      " 1: -5.5339e+03 -6.1679e+05  1e+06  3e-03  5e-13\n",
      " 2: -3.6920e+03 -1.3624e+05  1e+05  2e-05  3e-13\n",
      " 3: -4.9293e+03 -3.4192e+04  3e+04  5e-06  7e-14\n",
      " 4: -9.0868e+03 -3.6078e+04  3e+04  5e-16  2e-15\n",
      " 5: -1.1276e+04 -1.8273e+04  7e+03  2e-16  5e-16\n",
      " 6: -1.1585e+04 -1.7294e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.1964e+04 -1.3435e+04  1e+03  2e-16  4e-16\n",
      " 8: -1.2109e+04 -1.2560e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.2180e+04 -1.2309e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2198e+04 -1.2251e+04  5e+01  2e-16  4e-16\n",
      "11: -1.2208e+04 -1.2227e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2213e+04 -1.2218e+04  5e+00  2e-16  4e-16\n",
      "13: -1.2214e+04 -1.2215e+04  7e-01  2e-16  5e-16\n",
      "14: -1.2214e+04 -1.2214e+04  2e-02  2e-16  5e-16\n",
      "15: -1.2214e+04 -1.2214e+04  4e-04  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  2.9569e+02 -2.3700e+06  6e+07  3e-01  3e-15\n",
      " 1: -5.4157e+03 -6.1593e+05  1e+06  3e-03  7e-13\n",
      " 2: -3.5211e+03 -1.3764e+05  1e+05  2e-05  2e-13\n",
      " 3: -4.7803e+03 -3.4119e+04  3e+04  5e-06  7e-14\n",
      " 4: -8.9198e+03 -3.5874e+04  3e+04  5e-16  3e-15\n",
      " 5: -1.1153e+04 -1.8462e+04  7e+03  2e-16  6e-16\n",
      " 6: -1.1462e+04 -1.7443e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.1842e+04 -1.3343e+04  2e+03  2e-16  5e-16\n",
      " 8: -1.1996e+04 -1.2435e+04  4e+02  2e-16  5e-16\n",
      " 9: -1.2063e+04 -1.2200e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2082e+04 -1.2136e+04  5e+01  2e-16  5e-16\n",
      "11: -1.2092e+04 -1.2112e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2097e+04 -1.2102e+04  5e+00  2e-16  5e-16\n",
      "13: -1.2098e+04 -1.2099e+04  5e-01  2e-16  5e-16\n",
      "14: -1.2098e+04 -1.2098e+04  1e-02  2e-16  5e-16\n",
      "15: -1.2098e+04 -1.2098e+04  2e-04  2e-16  4e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -7.4123e+02 -2.3527e+06  6e+07  3e-01  4e-15\n",
      " 1: -6.4765e+03 -6.1664e+05  1e+06  3e-03  6e-13\n",
      " 2: -4.5770e+03 -1.4030e+05  1e+05  2e-05  2e-13\n",
      " 3: -5.8230e+03 -3.4438e+04  3e+04  5e-06  6e-14\n",
      " 4: -9.7287e+03 -3.5696e+04  3e+04  6e-16  4e-15\n",
      " 5: -1.1987e+04 -2.0038e+04  8e+03  2e-16  6e-16\n",
      " 6: -1.2337e+04 -1.8651e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2728e+04 -1.4254e+04  2e+03  2e-16  4e-16\n",
      " 8: -1.2880e+04 -1.3320e+04  4e+02  2e-16  4e-16\n",
      " 9: -1.2948e+04 -1.3114e+04  2e+02  2e-16  5e-16\n",
      "10: -1.2972e+04 -1.3019e+04  5e+01  2e-16  5e-16\n",
      "11: -1.2977e+04 -1.3007e+04  3e+01  2e-16  4e-16\n",
      "12: -1.2984e+04 -1.2990e+04  6e+00  1e-16  5e-16\n",
      "13: -1.2986e+04 -1.2986e+04  3e-01  2e-16  5e-16\n",
      "14: -1.2986e+04 -1.2986e+04  9e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  2.9695e+02 -2.3867e+06  6e+07  3e-01  2e-15\n",
      " 1: -5.4369e+03 -6.1655e+05  1e+06  3e-03  5e-13\n",
      " 2: -3.5708e+03 -1.3672e+05  1e+05  2e-05  5e-13\n",
      " 3: -4.8178e+03 -3.4140e+04  3e+04  5e-06  8e-14\n",
      " 4: -8.9729e+03 -3.5987e+04  3e+04  6e-16  2e-15\n",
      " 5: -1.1197e+04 -1.7979e+04  7e+03  2e-16  5e-16\n",
      " 6: -1.1495e+04 -1.7007e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.1855e+04 -1.3272e+04  1e+03  2e-16  4e-16\n",
      " 8: -1.1996e+04 -1.2423e+04  4e+02  2e-16  5e-16\n",
      " 9: -1.2061e+04 -1.2207e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2081e+04 -1.2139e+04  6e+01  2e-16  4e-16\n",
      "11: -1.2091e+04 -1.2112e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2096e+04 -1.2101e+04  5e+00  2e-16  5e-16\n",
      "13: -1.2097e+04 -1.2098e+04  4e-01  2e-16  5e-16\n",
      "14: -1.2098e+04 -1.2098e+04  8e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.2656e+02 -2.3643e+06  6e+07  3e-01  5e-15\n",
      " 1: -5.6407e+03 -6.1584e+05  1e+06  3e-03  3e-13\n",
      " 2: -3.7557e+03 -1.3699e+05  1e+05  2e-05  2e-13\n",
      " 3: -5.0068e+03 -3.4193e+04  3e+04  5e-06  6e-14\n",
      " 4: -9.1132e+03 -3.5948e+04  3e+04  5e-16  4e-15\n",
      " 5: -1.1363e+04 -1.8028e+04  7e+03  2e-16  6e-16\n",
      " 6: -1.1659e+04 -1.7070e+04  5e+03  2e-16  4e-16\n",
      " 7: -1.2018e+04 -1.3436e+04  1e+03  2e-16  5e-16\n",
      " 8: -1.2154e+04 -1.2601e+04  4e+02  2e-16  4e-16\n",
      " 9: -1.2224e+04 -1.2334e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2242e+04 -1.2283e+04  4e+01  2e-16  5e-16\n",
      "11: -1.2249e+04 -1.2266e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2254e+04 -1.2256e+04  3e+00  2e-16  5e-16\n",
      "13: -1.2255e+04 -1.2255e+04  3e-01  2e-16  6e-16\n",
      "14: -1.2255e+04 -1.2255e+04  7e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0609e+02 -2.3552e+06  6e+07  3e-01  2e-15\n",
      " 1: -6.1797e+03 -6.1614e+05  1e+06  3e-03  6e-13\n",
      " 2: -4.3392e+03 -1.3769e+05  1e+05  2e-05  2e-13\n",
      " 3: -5.5631e+03 -3.4419e+04  3e+04  5e-06  7e-14\n",
      " 4: -9.5707e+03 -3.5999e+04  3e+04  5e-16  3e-15\n",
      " 5: -1.1798e+04 -1.9107e+04  7e+03  2e-16  5e-16\n",
      " 6: -1.2126e+04 -1.7971e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2519e+04 -1.3991e+04  1e+03  1e-16  5e-16\n",
      " 8: -1.2668e+04 -1.3123e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.2740e+04 -1.2872e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2764e+04 -1.2796e+04  3e+01  2e-16  5e-16\n",
      "11: -1.2770e+04 -1.2782e+04  1e+01  1e-16  5e-16\n",
      "12: -1.2773e+04 -1.2775e+04  2e+00  2e-16  5e-16\n",
      "13: -1.2774e+04 -1.2774e+04  7e-02  2e-16  5e-16\n",
      "14: -1.2774e+04 -1.2774e+04  1e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  6.4950e+01 -2.3875e+06  6e+07  3e-01  4e-15\n",
      " 1: -5.6665e+03 -6.1679e+05  1e+06  3e-03  1e-12\n",
      " 2: -3.8491e+03 -1.3621e+05  1e+05  2e-05  3e-13\n",
      " 3: -5.0717e+03 -3.4246e+04  3e+04  5e-06  9e-14\n",
      " 4: -9.1982e+03 -3.6096e+04  3e+04  6e-16  2e-15\n",
      " 5: -1.1394e+04 -1.8093e+04  7e+03  2e-16  5e-16\n",
      " 6: -1.1695e+04 -1.7129e+04  5e+03  2e-16  4e-16\n",
      " 7: -1.2061e+04 -1.3504e+04  1e+03  2e-16  4e-16\n",
      " 8: -1.2205e+04 -1.2640e+04  4e+02  2e-16  4e-16\n",
      " 9: -1.2274e+04 -1.2403e+04  1e+02  1e-16  5e-16\n",
      "10: -1.2292e+04 -1.2343e+04  5e+01  2e-16  5e-16\n",
      "11: -1.2301e+04 -1.2320e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2306e+04 -1.2309e+04  3e+00  2e-16  4e-16\n",
      "13: -1.2307e+04 -1.2308e+04  4e-01  2e-16  5e-16\n",
      "14: -1.2307e+04 -1.2307e+04  9e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.0511e+01 -2.3448e+06  6e+07  3e-01  2e-15\n",
      " 1: -5.7537e+03 -6.1524e+05  1e+06  3e-03  3e-13\n",
      " 2: -3.8668e+03 -1.3762e+05  1e+05  2e-05  3e-13\n",
      " 3: -5.1217e+03 -3.4209e+04  3e+04  5e-06  6e-14\n",
      " 4: -9.2047e+03 -3.5880e+04  3e+04  6e-16  6e-15\n",
      " 5: -1.1430e+04 -1.8787e+04  7e+03  2e-16  8e-16\n",
      " 6: -1.1748e+04 -1.7720e+04  6e+03  2e-16  5e-16\n",
      " 7: -1.2131e+04 -1.3683e+04  2e+03  2e-16  4e-16\n",
      " 8: -1.2277e+04 -1.2778e+04  5e+02  2e-16  4e-16\n",
      " 9: -1.2352e+04 -1.2510e+04  2e+02  2e-16  5e-16\n",
      "10: -1.2374e+04 -1.2433e+04  6e+01  2e-16  5e-16\n",
      "11: -1.2383e+04 -1.2409e+04  3e+01  2e-16  5e-16\n",
      "12: -1.2390e+04 -1.2395e+04  5e+00  2e-16  5e-16\n",
      "13: -1.2391e+04 -1.2392e+04  5e-01  2e-16  6e-16\n",
      "14: -1.2391e+04 -1.2391e+04  1e-02  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -5.9752e+02 -2.3197e+06  6e+07  3e-01  3e-15\n",
      " 1: -6.3797e+03 -6.1505e+05  1e+06  3e-03  7e-13\n",
      " 2: -4.5131e+03 -1.3880e+05  1e+05  2e-05  6e-13\n",
      " 3: -5.7425e+03 -3.4397e+04  3e+04  5e-06  1e-13\n",
      " 4: -9.6504e+03 -3.5756e+04  3e+04  6e-16  2e-15\n",
      " 5: -1.1898e+04 -1.9239e+04  7e+03  2e-16  5e-16\n",
      " 6: -1.2213e+04 -1.8078e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2584e+04 -1.4100e+04  2e+03  2e-16  4e-16\n",
      " 8: -1.2730e+04 -1.3184e+04  5e+02  2e-16  4e-16\n",
      " 9: -1.2797e+04 -1.2923e+04  1e+02  2e-16  4e-16\n",
      "10: -1.2822e+04 -1.2853e+04  3e+01  2e-16  5e-16\n",
      "11: -1.2829e+04 -1.2837e+04  9e+00  2e-16  4e-16\n",
      "12: -1.2831e+04 -1.2833e+04  2e+00  2e-16  5e-16\n",
      "13: -1.2832e+04 -1.2832e+04  7e-02  1e-16  5e-16\n",
      "14: -1.2832e+04 -1.2832e+04  1e-03  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.4383e+01 -2.3374e+06  6e+07  3e-01  2e-15\n",
      " 1: -5.8669e+03 -6.1504e+05  1e+06  3e-03  3e-13\n",
      " 2: -4.0146e+03 -1.3720e+05  1e+05  2e-05  2e-13\n",
      " 3: -5.2504e+03 -3.4253e+04  3e+04  5e-06  6e-14\n",
      " 4: -9.3000e+03 -3.5917e+04  3e+04  6e-16  2e-15\n",
      " 5: -1.1512e+04 -1.8610e+04  7e+03  2e-16  6e-16\n",
      " 6: -1.1819e+04 -1.7578e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2189e+04 -1.3712e+04  2e+03  2e-16  5e-16\n",
      " 8: -1.2335e+04 -1.2801e+04  5e+02  2e-16  5e-16\n",
      " 9: -1.2408e+04 -1.2536e+04  1e+02  2e-16  6e-16\n",
      "10: -1.2426e+04 -1.2478e+04  5e+01  1e-16  5e-16\n",
      "11: -1.2436e+04 -1.2452e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2440e+04 -1.2443e+04  3e+00  2e-16  4e-16\n",
      "13: -1.2441e+04 -1.2442e+04  7e-01  2e-16  5e-16\n",
      "14: -1.2441e+04 -1.2441e+04  3e-02  2e-16  6e-16\n",
      "15: -1.2441e+04 -1.2441e+04  7e-04  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3030e+02 -2.3538e+06  6e+07  3e-01  2e-15\n",
      " 1: -5.9332e+03 -6.1575e+05  1e+06  3e-03  8e-13\n",
      " 2: -4.1268e+03 -1.3658e+05  1e+05  2e-05  6e-13\n",
      " 3: -5.3387e+03 -3.4326e+04  3e+04  5e-06  2e-13\n",
      " 4: -9.3855e+03 -3.6046e+04  3e+04  5e-16  2e-15\n",
      " 5: -1.1577e+04 -1.8546e+04  7e+03  2e-16  5e-16\n",
      " 6: -1.1887e+04 -1.7512e+04  6e+03  2e-16  4e-16\n",
      " 7: -1.2255e+04 -1.3768e+04  2e+03  2e-16  4e-16\n",
      " 8: -1.2407e+04 -1.2805e+04  4e+02  2e-16  4e-16\n",
      " 9: -1.2469e+04 -1.2605e+04  1e+02  2e-16  5e-16\n",
      "10: -1.2487e+04 -1.2541e+04  5e+01  2e-16  4e-16\n",
      "11: -1.2497e+04 -1.2515e+04  2e+01  2e-16  5e-16\n",
      "12: -1.2501e+04 -1.2504e+04  3e+00  1e-16  5e-16\n",
      "13: -1.2502e+04 -1.2503e+04  5e-01  2e-16  5e-16\n",
      "14: -1.2502e+04 -1.2502e+04  2e-02  2e-16  5e-16\n",
      "15: -1.2502e+04 -1.2502e+04  5e-04  2e-16  5e-16\n",
      "Optimal solution found.\n",
      "Fit Estimator...\n",
      "RMSE List of KMM: [0.6985486274978585, 0.8214676126797688, 0.7514421305012239, 0.6708007046672295, 0.7392233533460094, 0.7979943022695238, 0.5560162070872517, 0.377834201048935, 0.5163842170307349, 1.2214604338610613, 0.27926264366887354, 0.8197770728296725, 0.9251795674972355, 0.7434870590526138, 1.3469981694537014, 0.6315909226423323, 0.5923919517360873, 0.35972359739544696, 0.6767712606146137, 1.388478469155192]\n",
      "R^2 List of KMM: [0.6616775143545652, 0.3799887425605703, 0.4792340245162432, 0.10765863223792922, 0.8447393760100548, 0.7676065146045152, 0.6993770603125012, 0.5523219110500399, 0.37418360940805295, 6.575024580466884e-05, 0.6303613855195697, 0.643176808780509, 0.05776167082036713, 0.777641802814463, 0.008240573547252491, 0.29888695281106653, 0.43285197448741963, 0.5029216760954641, 0.0350141343498556, 0.13403368191842482]\n",
      "\n",
      "\n",
      "RMSE of KMM: 0.7457416252017683 0.2979639899670142\n",
      "R^2 of KMM: 0.41938718982223344 0.28197945749534203\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### Kernel Mean Matching Auto #######################################\n",
    "from adapt.instance_based import KMM\n",
    "\n",
    "\n",
    "print(\"Kernel Mean Matching\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_KMM_auto = []\n",
    "rmselist_KMM_auto = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(auto_tgt_df):\n",
    "        \n",
    "    auto_train_df_X = auto_tgt_df.iloc[train_idx].loc[:, features_auto]\n",
    "    auto_test_df_X = auto_tgt_df.iloc[test_idx][features_auto]\n",
    "    auto_train_df_y = auto_tgt_df.iloc[train_idx].loc[:,target_auto]\n",
    "    auto_test_df_y = auto_tgt_df.loc[test_idx][target_auto]\n",
    "    \n",
    "    auto_np_train_X = auto_train_df_X.to_numpy()\n",
    "    auto_np_train_y = auto_train_df_y.to_numpy()\n",
    "\n",
    "    auto_np_source_X = auto_source_df_X.to_numpy()\n",
    "    auto_np_source_y = auto_source_df_y.to_numpy()\n",
    "\n",
    "    auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "    auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "    auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "    auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "    \n",
    "    src_size_auto = len(auto_source_df_y)\n",
    "    tgt_size_auto = len(auto_train_df_y)\n",
    "    \n",
    "    src_idx = np.arange(start = 0, stop = (src_size_auto - 1), step=1)\n",
    "    tgt_idx = np.arange(start = 0, stop = (tgt_size_auto - 1), step=1)\n",
    "\n",
    "    model_KMM_auto = KMM(DecisionTreeRegressor(max_depth = 6))\n",
    "    model_KMM_auto.fit(auto_np_source_X[src_idx], auto_np_source_y[src_idx], auto_np_train_X[tgt_idx], auto_np_train_y[tgt_idx])\n",
    "\n",
    "    y_pred_KMM_auto = model_KMM_auto.predict(auto_test_df_X) \n",
    "\n",
    "    mse_KMM_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_KMM_auto))\n",
    "    rmselist_KMM_auto.append(mse_KMM_auto)\n",
    "        \n",
    "    r2_score_KMM_auto = pearsonr(auto_np_test_y_list, y_pred_KMM_auto)\n",
    "    r2_score_KMM_auto = (r2_score_KMM_auto[0])**2\n",
    "    r2scorelist_KMM_auto.append(r2_score_KMM_auto)\n",
    "\n",
    "print(\"RMSE List of KMM:\", rmselist_KMM_auto)\n",
    "print(\"R^2 List of KMM:\", r2scorelist_KMM_auto)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of KMM:\", statistics.mean(rmselist_KMM_auto), statistics.stdev(rmselist_KMM_auto))\n",
    "print(\"R^2 of KMM:\", statistics.mean(r2scorelist_KMM_auto), statistics.stdev(r2scorelist_KMM_auto))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLIEP\n",
      "-------------------------------------------\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.084 (0.035)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.863 (0.299)\n",
      "Parameter sigma = 10.0000 -- J-score = -0.893 (1.151)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.070 (0.109)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.875 (0.306)\n",
      "Parameter sigma = 10.0000 -- J-score = -1.002 (2.299)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.060 (0.181)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.668 (0.672)\n",
      "Parameter sigma = 10.0000 -- J-score = -1.944 (3.155)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.080 (0.085)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.878 (0.169)\n",
      "Parameter sigma = 10.0000 -- J-score = -0.961 (0.598)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.057 (0.132)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.814 (0.414)\n",
      "Parameter sigma = 10.0000 -- J-score = -1.205 (2.124)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.104 (0.062)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.925 (0.229)\n",
      "Parameter sigma = 10.0000 -- J-score = -0.669 (1.566)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.064 (0.124)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.659 (0.631)\n",
      "Parameter sigma = 10.0000 -- J-score = -1.213 (1.298)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.066 (0.128)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.700 (0.782)\n",
      "Parameter sigma = 10.0000 -- J-score = -1.099 (2.307)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.081 (0.043)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.876 (0.197)\n",
      "Parameter sigma = 10.0000 -- J-score = -0.708 (1.226)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.058 (0.107)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.798 (0.394)\n",
      "Parameter sigma = 10.0000 -- J-score = -1.087 (2.215)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.053 (0.098)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.762 (0.329)\n",
      "Parameter sigma = 10.0000 -- J-score = -1.118 (1.819)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.108 (0.083)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.911 (0.104)\n",
      "Parameter sigma = 10.0000 -- J-score = -0.220 (1.047)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.074 (0.086)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.821 (0.269)\n",
      "Parameter sigma = 10.0000 -- J-score = -0.928 (1.361)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.053 (0.058)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.788 (0.397)\n",
      "Parameter sigma = 10.0000 -- J-score = -1.052 (1.638)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.098 (0.049)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.815 (0.202)\n",
      "Parameter sigma = 10.0000 -- J-score = -1.041 (1.073)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.070 (0.072)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.817 (0.181)\n",
      "Parameter sigma = 10.0000 -- J-score = -0.891 (0.940)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.085 (0.120)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.845 (0.380)\n",
      "Parameter sigma = 10.0000 -- J-score = -0.935 (2.155)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.101 (0.050)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.921 (0.223)\n",
      "Parameter sigma = 10.0000 -- J-score = -0.652 (1.022)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.068 (0.048)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.781 (0.235)\n",
      "Parameter sigma = 10.0000 -- J-score = -1.031 (1.117)\n",
      "Fit Estimator...\n",
      "Fit weights...\n",
      "Cross Validation process...\n",
      "Parameter sigma = 0.1000 -- J-score = 0.094 (0.061)\n",
      "Parameter sigma = 1.0000 -- J-score = 0.847 (0.159)\n",
      "Parameter sigma = 10.0000 -- J-score = -0.813 (1.403)\n",
      "Fit Estimator...\n",
      "RMSE List of KLIEP: [1.0984217007687935, 0.6470777536591259, 0.8753738235131581, 0.7098242417263779, 0.7942126187284614, 0.8791883697909675, 0.6461324793662547, 0.4574354492563662, 0.707035564868901, 1.5422030173977284, 0.5507163135863009, 0.8723477830935499, 0.9840829502574183, 1.1199854229437385, 1.2868544379600448, 1.2450796533850197, 0.5083450407660289, 0.8802908534883641, 0.8647783945185638, 1.2304945462156585]\n",
      "R^2 List of KLIEP: [0.05725205888814348, 0.23734788099199564, 1.6014692985663532e-06, 0.026437688510040552, 0.754218788360617, 0.4947685899551858, 0.6043956385861913, 0.08731141090276766, 0.3264266304347826, 0.05638586956521742, 0.04358342136358884, 0.006612013521691805, 0.1421417276563583, 0.0191925673030692, 0.11192346686084516, 0.006877040564147216, 0.37422603445671637, 0.285278638371602, 0.12150133671266738, 0.120483037192564]\n",
      "\n",
      "\n",
      "RMSE of KLIEP: 0.894994020764541 0.2876787263637546\n",
      "R^2 of KLIEP: 0.19381827208337452 0.2165629983389706\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "######################### KLIEP Auto #######################################\n",
    "from adapt.instance_based import KLIEP\n",
    "\n",
    "\n",
    "print(\"KLIEP\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "r2scorelist_KLIEP_auto = []\n",
    "rmselist_KLIEP_auto = []\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(auto_tgt_df):\n",
    "        \n",
    "    auto_train_df_X = auto_tgt_df.iloc[train_idx].loc[:, features_auto]\n",
    "    auto_test_df_X = auto_tgt_df.iloc[test_idx][features_auto]\n",
    "    auto_train_df_y = auto_tgt_df.iloc[train_idx].loc[:,target_auto]\n",
    "    auto_test_df_y = auto_tgt_df.loc[test_idx][target_auto]\n",
    "        \n",
    "    auto_np_train_X = auto_train_df_X.to_numpy()\n",
    "    auto_np_train_y = auto_train_df_y.to_numpy()\n",
    "\n",
    "    auto_np_source_X = auto_source_df_X.to_numpy()\n",
    "    auto_np_source_y = auto_source_df_y.to_numpy()\n",
    "\n",
    "    auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "    auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "    auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "    auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "    \n",
    "    src_size_auto = len(auto_source_df_y)\n",
    "    tgt_size_auto = len(auto_train_df_y)\n",
    "    \n",
    "    src_idx = np.arange(start = 0, stop = (src_size_auto - 1), step=1)\n",
    "    tgt_idx = np.arange(start = 0, stop = (tgt_size_auto - 1), step=1)\n",
    "    \n",
    "    model_KLIEP_auto = KLIEP(DecisionTreeRegressor(max_depth = 6), sigmas = [0.1, 1, 10])\n",
    "    model_KLIEP_auto.fit(auto_np_source_X[src_idx], auto_np_source_y[src_idx], auto_np_train_X[tgt_idx], auto_np_train_y[tgt_idx])\n",
    "\n",
    "    y_pred_KLIEP_auto = model_KLIEP_auto.predict(auto_test_df_X) ##Using dataframe instead of the numpy matrix\n",
    "\n",
    "    mse_KLIEP_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_KLIEP_auto))\n",
    "    rmselist_KLIEP_auto.append(mse_KLIEP_auto)\n",
    "        \n",
    "    r2_score_KLIEP_auto = pearsonr(auto_np_test_y_list, y_pred_KLIEP_auto)\n",
    "    r2_score_KLIEP_auto = (r2_score_KLIEP_auto[0])**2\n",
    "    r2scorelist_KLIEP_auto.append(r2_score_KLIEP_auto)\n",
    "\n",
    "print(\"RMSE List of KLIEP:\", rmselist_KLIEP_auto)\n",
    "print(\"R^2 List of KLIEP:\", r2scorelist_KLIEP_auto)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"RMSE of KLIEP:\", statistics.mean(rmselist_KLIEP_auto), statistics.stdev(rmselist_KLIEP_auto))\n",
    "print(\"R^2 of KLIEP:\", statistics.mean(r2scorelist_KLIEP_auto), statistics.stdev(r2scorelist_KLIEP_auto))\n",
    "\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IWKRR\n",
      "-------------------------------------------\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.5679e+01  3.9645e+00  9e+02  4e+01  7e-01\n",
      " 1: -7.3486e+00 -6.3545e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.3502e+01 -2.8023e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.3191e+01 -5.2578e+00  3e+01  3e-01  6e-03\n",
      " 4:  1.9241e+00 -4.1547e-01  2e+00  3e-03  5e-05\n",
      " 5:  1.2002e-01 -3.5695e-02  2e-01  1e-05  2e-07\n",
      " 6:  4.7694e-03 -6.5826e-03  1e-02  1e-07  2e-09\n",
      " 7: -2.6193e-03 -3.7347e-03  1e-03  7e-10  1e-11\n",
      " 8: -3.2864e-03 -3.4116e-03  1e-04  5e-12  9e-14\n",
      " 9: -3.3571e-03 -3.3723e-03  2e-05  4e-14  1e-15\n",
      "10: -3.3654e-03 -3.3673e-03  2e-06  3e-16  1e-15\n",
      "11: -3.3665e-03 -3.3667e-03  2e-07  4e-17  1e-15\n",
      "12: -3.3666e-03 -3.3666e-03  3e-08  1e-19  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3645e+01  4.1243e+00  9e+02  4e+01  7e-01\n",
      " 1: -4.7732e+00 -6.7589e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.4853e+01 -3.0053e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.3891e+01 -5.8410e+00  3e+01  4e-01  7e-03\n",
      " 4:  2.1752e+00 -4.5134e-01  3e+00  3e-03  6e-05\n",
      " 5:  1.3541e-01 -3.5893e-02  2e-01  1e-05  2e-07\n",
      " 6:  4.7031e-03 -6.7100e-03  1e-02  9e-08  2e-09\n",
      " 7: -2.8119e-03 -3.8913e-03  1e-03  7e-10  1e-11\n",
      " 8: -3.4243e-03 -3.5551e-03  1e-04  5e-12  9e-14\n",
      " 9: -3.4974e-03 -3.5135e-03  2e-05  4e-14  1e-15\n",
      "10: -3.5063e-03 -3.5083e-03  2e-06  3e-16  8e-16\n",
      "11: -3.5074e-03 -3.5077e-03  2e-07  1e-17  9e-16\n",
      "12: -3.5076e-03 -3.5076e-03  3e-08  1e-17  8e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.4276e+01  6.0098e+00  9e+02  4e+01  7e-01\n",
      " 1: -3.9769e+00 -6.4268e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.6192e+01 -2.9269e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.3850e+01 -5.4645e+00  3e+01  3e-01  6e-03\n",
      " 4:  2.0245e+00 -4.1726e-01  2e+00  3e-03  5e-05\n",
      " 5:  1.2591e-01 -3.3370e-02  2e-01  1e-05  2e-07\n",
      " 6:  4.4173e-03 -6.2370e-03  1e-02  9e-08  2e-09\n",
      " 7: -2.6717e-03 -3.6596e-03  1e-03  7e-10  1e-11\n",
      " 8: -3.2356e-03 -3.3538e-03  1e-04  5e-12  9e-14\n",
      " 9: -3.3010e-03 -3.3156e-03  1e-05  4e-14  1e-15\n",
      "10: -3.3088e-03 -3.3107e-03  2e-06  3e-16  9e-16\n",
      "11: -3.3099e-03 -3.3101e-03  2e-07  1e-18  1e-15\n",
      "12: -3.3100e-03 -3.3100e-03  3e-08  7e-20  9e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.5854e+01  6.0072e+00  9e+02  4e+01  7e-01\n",
      " 1: -2.8869e+00 -6.7024e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.8050e+01 -3.0573e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.4386e+01 -5.5944e+00  3e+01  3e-01  6e-03\n",
      " 4:  2.0629e+00 -4.2120e-01  3e+00  3e-03  5e-05\n",
      " 5:  1.2808e-01 -3.3281e-02  2e-01  1e-05  2e-07\n",
      " 6:  4.1062e-03 -6.4036e-03  1e-02  8e-08  1e-09\n",
      " 7: -2.8668e-03 -3.8475e-03  1e-03  6e-10  1e-11\n",
      " 8: -3.4251e-03 -3.5425e-03  1e-04  4e-12  8e-14\n",
      " 9: -3.4895e-03 -3.5042e-03  1e-05  3e-14  1e-15\n",
      "10: -3.4974e-03 -3.4993e-03  2e-06  3e-16  8e-16\n",
      "11: -3.4985e-03 -3.4987e-03  2e-07  3e-17  7e-16\n",
      "12: -3.4986e-03 -3.4986e-03  3e-08  3e-17  8e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1731e+01  9.1649e+00  9e+02  4e+01  8e-01\n",
      " 1: -7.2316e-01 -6.2392e+01  3e+02  1e+01  2e-01\n",
      " 2:  1.5849e+01 -2.4104e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.0948e+01 -5.3470e+00  3e+01  5e-01  1e-02\n",
      " 4:  1.9993e+00 -4.2564e-01  2e+00  2e-03  4e-05\n",
      " 5:  1.2744e-01 -3.4584e-02  2e-01  9e-06  2e-07\n",
      " 6:  4.5976e-03 -6.4845e-03  1e-02  6e-08  1e-09\n",
      " 7: -2.8585e-03 -3.8651e-03  1e-03  5e-10  1e-11\n",
      " 8: -3.4375e-03 -3.5567e-03  1e-04  4e-12  8e-14\n",
      " 9: -3.5033e-03 -3.5181e-03  1e-05  3e-14  1e-15\n",
      "10: -3.5112e-03 -3.5131e-03  2e-06  2e-16  9e-16\n",
      "11: -3.5122e-03 -3.5125e-03  2e-07  1e-17  1e-15\n",
      "12: -3.5123e-03 -3.5124e-03  3e-08  1e-17  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1618e+01  7.7553e+00  9e+02  4e+01  8e-01\n",
      " 1:  3.4478e-01 -6.2918e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.0586e+01 -2.5938e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.2044e+01 -4.8958e+00  2e+01  3e-01  6e-03\n",
      " 4:  1.7640e+00 -3.8373e-01  2e+00  2e-03  4e-05\n",
      " 5:  1.1273e-01 -3.2572e-02  1e-01  1e-05  2e-07\n",
      " 6:  3.5543e-03 -6.7746e-03  1e-02  7e-08  1e-09\n",
      " 7: -3.5458e-03 -4.4470e-03  9e-04  6e-10  1e-11\n",
      " 8: -4.0720e-03 -4.1760e-03  1e-04  4e-12  9e-14\n",
      " 9: -4.1284e-03 -4.1416e-03  1e-05  3e-14  1e-15\n",
      "10: -4.1354e-03 -4.1371e-03  2e-06  3e-16  8e-16\n",
      "11: -4.1363e-03 -4.1366e-03  2e-07  1e-18  9e-16\n",
      "12: -4.1365e-03 -4.1365e-03  3e-08  7e-20  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3873e+01  4.5472e+00  9e+02  4e+01  7e-01\n",
      " 1: -5.3393e+00 -6.2740e+01  3e+02  1e+01  2e-01\n",
      " 2:  1.6228e+01 -2.4436e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.1105e+01 -4.7245e+00  2e+01  4e-01  7e-03\n",
      " 4:  1.7243e+00 -3.6795e-01  2e+00  2e-03  4e-05\n",
      " 5:  1.0814e-01 -3.1602e-02  1e-01  1e-05  2e-07\n",
      " 6:  2.7153e-03 -6.9862e-03  1e-02  8e-08  2e-09\n",
      " 7: -3.7718e-03 -4.6672e-03  9e-04  6e-10  1e-11\n",
      " 8: -4.2872e-03 -4.3927e-03  1e-04  5e-12  9e-14\n",
      " 9: -4.3446e-03 -4.3580e-03  1e-05  3e-14  1e-15\n",
      "10: -4.3517e-03 -4.3535e-03  2e-06  3e-16  9e-16\n",
      "11: -4.3527e-03 -4.3529e-03  2e-07  3e-17  8e-16\n",
      "12: -4.3528e-03 -4.3528e-03  3e-08  3e-17  8e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.7257e+01  2.4472e+00  9e+02  4e+01  7e-01\n",
      " 1: -8.7878e+00 -6.4431e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.3283e+01 -2.7973e+01  1e+02  3e+00  5e-02\n",
      " 3:  1.3118e+01 -5.1427e+00  3e+01  3e-01  6e-03\n",
      " 4:  1.8906e+00 -3.9838e-01  2e+00  3e-03  5e-05\n",
      " 5:  1.1938e-01 -3.2725e-02  2e-01  1e-05  2e-07\n",
      " 6:  4.2102e-03 -6.2018e-03  1e-02  1e-07  2e-09\n",
      " 7: -2.7223e-03 -3.6870e-03  1e-03  8e-10  1e-11\n",
      " 8: -3.2745e-03 -3.3891e-03  1e-04  6e-12  1e-13\n",
      " 9: -3.3369e-03 -3.3513e-03  1e-05  4e-14  1e-15\n",
      "10: -3.3446e-03 -3.3465e-03  2e-06  3e-16  8e-16\n",
      "11: -3.3456e-03 -3.3458e-03  2e-07  3e-17  9e-16\n",
      "12: -3.3457e-03 -3.3457e-03  3e-08  1e-17  8e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.7341e+01  2.2364e+00  9e+02  4e+01  7e-01\n",
      " 1: -9.0071e+00 -6.4374e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.3011e+01 -2.7794e+01  1e+02  3e+00  5e-02\n",
      " 3:  1.3123e+01 -5.1249e+00  3e+01  3e-01  6e-03\n",
      " 4:  1.8946e+00 -3.9546e-01  2e+00  3e-03  5e-05\n",
      " 5:  1.1792e-01 -3.2745e-02  2e-01  1e-05  2e-07\n",
      " 6:  3.9651e-03 -6.3725e-03  1e-02  1e-07  2e-09\n",
      " 7: -2.8879e-03 -3.8552e-03  1e-03  8e-10  1e-11\n",
      " 8: -3.4421e-03 -3.5570e-03  1e-04  6e-12  1e-13\n",
      " 9: -3.5048e-03 -3.5193e-03  1e-05  4e-14  1e-15\n",
      "10: -3.5125e-03 -3.5144e-03  2e-06  3e-16  1e-15\n",
      "11: -3.5136e-03 -3.5138e-03  2e-07  1e-17  7e-16\n",
      "12: -3.5137e-03 -3.5137e-03  3e-08  4e-17  9e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.4224e+01  4.9295e+00  9e+02  4e+01  7e-01\n",
      " 1: -5.4367e+00 -6.3707e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.5624e+01 -2.7725e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.3473e+01 -4.8916e+00  2e+01  2e-01  5e-03\n",
      " 4:  1.7907e+00 -3.6965e-01  2e+00  2e-03  4e-05\n",
      " 5:  1.0911e-01 -3.0448e-02  1e-01  8e-06  2e-07\n",
      " 6:  3.9553e-03 -5.7060e-03  1e-02  6e-08  1e-09\n",
      " 7: -2.4043e-03 -3.3178e-03  9e-04  5e-10  9e-12\n",
      " 8: -2.9230e-03 -3.0331e-03  1e-04  4e-12  7e-14\n",
      " 9: -2.9836e-03 -2.9974e-03  1e-05  3e-14  1e-15\n",
      "10: -2.9911e-03 -2.9928e-03  2e-06  2e-16  8e-16\n",
      "11: -2.9921e-03 -2.9923e-03  2e-07  1e-18  1e-15\n",
      "12: -2.9922e-03 -2.9922e-03  3e-08  1e-17  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.7605e+01  3.6138e+00  9e+02  4e+01  7e-01\n",
      " 1: -8.0349e+00 -6.5121e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.4379e+01 -2.8000e+01  1e+02  3e+00  5e-02\n",
      " 3:  1.3275e+01 -4.9723e+00  3e+01  3e-01  5e-03\n",
      " 4:  1.8312e+00 -3.7778e-01  2e+00  3e-03  5e-05\n",
      " 5:  1.1199e-01 -3.1671e-02  1e-01  1e-05  2e-07\n",
      " 6:  3.5177e-03 -6.3520e-03  1e-02  9e-08  2e-09\n",
      " 7: -2.9540e-03 -3.8972e-03  9e-04  7e-10  1e-11\n",
      " 8: -3.4918e-03 -3.6047e-03  1e-04  5e-12  9e-14\n",
      " 9: -3.5538e-03 -3.5679e-03  1e-05  4e-14  1e-15\n",
      "10: -3.5613e-03 -3.5631e-03  2e-06  3e-16  1e-15\n",
      "11: -3.5623e-03 -3.5625e-03  2e-07  1e-17  1e-15\n",
      "12: -3.5624e-03 -3.5625e-03  3e-08  1e-17  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.6626e+01  2.4096e+00  9e+02  4e+01  7e-01\n",
      " 1: -8.4510e+00 -6.4023e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.3576e+01 -2.7982e+01  1e+02  3e+00  5e-02\n",
      " 3:  1.3340e+01 -5.2864e+00  3e+01  3e-01  6e-03\n",
      " 4:  1.9500e+00 -4.1267e-01  2e+00  3e-03  5e-05\n",
      " 5:  1.2080e-01 -3.5063e-02  2e-01  1e-05  2e-07\n",
      " 6:  3.9871e-03 -6.9556e-03  1e-02  1e-07  2e-09\n",
      " 7: -3.1390e-03 -4.1988e-03  1e-03  8e-10  1e-11\n",
      " 8: -3.7449e-03 -3.8708e-03  1e-04  5e-12  9e-14\n",
      " 9: -3.8138e-03 -3.8295e-03  2e-05  4e-14  1e-15\n",
      "10: -3.8220e-03 -3.8240e-03  2e-06  3e-16  1e-15\n",
      "11: -3.8230e-03 -3.8233e-03  3e-07  1e-17  9e-16\n",
      "12: -3.8232e-03 -3.8232e-03  3e-08  4e-17  9e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.5395e+01  3.7420e+00  9e+02  4e+01  7e-01\n",
      " 1: -7.6937e+00 -6.1322e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.7344e+01 -2.5569e+01  1e+02  3e+00  5e-02\n",
      " 3:  1.2568e+01 -3.8856e+00  2e+01  9e-02  2e-03\n",
      " 4:  1.3863e+00 -2.7741e-01  2e+00  7e-04  1e-05\n",
      " 5:  8.0673e-02 -2.4555e-02  1e-01  4e-06  8e-08\n",
      " 6:  1.8408e-03 -5.5297e-03  7e-03  3e-08  6e-10\n",
      " 7: -2.9046e-03 -3.6340e-03  7e-04  2e-10  5e-12\n",
      " 8: -3.3182e-03 -3.4059e-03  9e-05  2e-12  3e-14\n",
      " 9: -3.3660e-03 -3.3771e-03  1e-05  1e-14  9e-16\n",
      "10: -3.3720e-03 -3.3734e-03  1e-06  1e-16  1e-15\n",
      "11: -3.3728e-03 -3.3729e-03  2e-07  3e-17  9e-16\n",
      "12: -3.3729e-03 -3.3729e-03  2e-08  3e-17  9e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0822e+01  6.5032e+00  9e+02  4e+01  7e-01\n",
      " 1: -4.2631e+00 -6.1444e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.5865e+01 -2.7078e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.2985e+01 -4.4971e+00  2e+01  2e-01  4e-03\n",
      " 4:  1.6258e+00 -3.3209e-01  2e+00  2e-03  3e-05\n",
      " 5:  9.9506e-02 -2.7484e-02  1e-01  8e-06  2e-07\n",
      " 6:  3.5711e-03 -5.1338e-03  9e-03  6e-08  1e-09\n",
      " 7: -2.1230e-03 -2.9536e-03  8e-04  5e-10  9e-12\n",
      " 8: -2.5913e-03 -2.6916e-03  1e-04  3e-12  7e-14\n",
      " 9: -2.6453e-03 -2.6582e-03  1e-05  2e-14  1e-15\n",
      "10: -2.6522e-03 -2.6539e-03  2e-06  1e-16  8e-16\n",
      "11: -2.6532e-03 -2.6534e-03  2e-07  1e-17  1e-15\n",
      "12: -2.6533e-03 -2.6533e-03  2e-08  1e-17  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3681e+01  3.5424e+00  9e+02  4e+01  7e-01\n",
      " 1: -7.0951e+00 -6.0769e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.3829e+01 -2.6153e+01  1e+02  3e+00  5e-02\n",
      " 3:  1.2724e+01 -4.5342e+00  2e+01  3e-01  5e-03\n",
      " 4:  1.6902e+00 -3.3570e-01  2e+00  2e-03  4e-05\n",
      " 5:  1.0576e-01 -2.5273e-02  1e-01  1e-05  2e-07\n",
      " 6:  6.6444e-03 -2.5736e-03  9e-03  1e-07  2e-09\n",
      " 7:  5.6248e-04 -3.1344e-04  9e-04  7e-10  1e-11\n",
      " 8:  6.5967e-05 -3.9612e-05  1e-04  5e-12  9e-14\n",
      " 9:  8.3017e-06 -5.0470e-06  1e-05  4e-14  1e-15\n",
      "10:  1.1117e-06 -6.2898e-07  2e-06  3e-16  9e-16\n",
      "11:  1.3214e-07 -7.7970e-08  2e-07  1e-18  9e-16\n",
      "12:  1.6239e-08 -1.0081e-08  3e-08  7e-20  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.5372e+01  4.6482e+00  9e+02  4e+01  7e-01\n",
      " 1: -6.0714e+00 -6.3559e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.8635e+01 -2.6450e+01  1e+02  3e+00  5e-02\n",
      " 3:  1.2672e+01 -3.8189e+00  2e+01  4e-02  9e-04\n",
      " 4:  1.3357e+00 -2.6818e-01  2e+00  3e-04  6e-06\n",
      " 5:  7.7158e-02 -2.4124e-02  1e-01  2e-06  3e-08\n",
      " 6:  1.4116e-03 -5.6845e-03  7e-03  1e-08  3e-10\n",
      " 7: -3.0974e-03 -3.8153e-03  7e-04  1e-10  2e-12\n",
      " 8: -3.4991e-03 -3.5868e-03  9e-05  7e-13  1e-14\n",
      " 9: -3.5465e-03 -3.5578e-03  1e-05  5e-15  1e-15\n",
      "10: -3.5527e-03 -3.5541e-03  1e-06  4e-17  9e-16\n",
      "11: -3.5535e-03 -3.5537e-03  2e-07  1e-17  1e-15\n",
      "12: -3.5536e-03 -3.5536e-03  2e-08  1e-17  8e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.6694e+01  4.8200e+00  9e+02  4e+01  7e-01\n",
      " 1: -7.1137e+00 -6.3351e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.7008e+01 -2.6868e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.2303e+01 -3.8605e+00  2e+01  9e-02  2e-03\n",
      " 4:  1.3626e+00 -2.7779e-01  2e+00  7e-04  1e-05\n",
      " 5:  8.0567e-02 -2.4820e-02  1e-01  4e-06  7e-08\n",
      " 6:  1.3849e-03 -5.9318e-03  7e-03  3e-08  6e-10\n",
      " 7: -3.3300e-03 -4.0544e-03  7e-04  2e-10  4e-12\n",
      " 8: -3.7416e-03 -3.8284e-03  9e-05  2e-12  3e-14\n",
      " 9: -3.7888e-03 -3.7998e-03  1e-05  1e-14  9e-16\n",
      "10: -3.7947e-03 -3.7962e-03  1e-06  9e-17  9e-16\n",
      "11: -3.7955e-03 -3.7957e-03  2e-07  1e-17  9e-16\n",
      "12: -3.7956e-03 -3.7956e-03  2e-08  8e-20  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.7139e+01  3.2710e+00  9e+02  4e+01  7e-01\n",
      " 1: -8.3984e+00 -6.3796e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.4379e+01 -2.7332e+01  1e+02  3e+00  5e-02\n",
      " 3:  1.3234e+01 -4.9190e+00  2e+01  3e-01  5e-03\n",
      " 4:  1.8265e+00 -3.7205e-01  2e+00  2e-03  4e-05\n",
      " 5:  1.1122e-01 -3.0758e-02  1e-01  1e-05  2e-07\n",
      " 6:  3.7119e-03 -5.9665e-03  1e-02  9e-08  2e-09\n",
      " 7: -2.6535e-03 -3.5694e-03  9e-04  7e-10  1e-11\n",
      " 8: -3.1724e-03 -3.2827e-03  1e-04  5e-12  9e-14\n",
      " 9: -3.2324e-03 -3.2464e-03  1e-05  4e-14  1e-15\n",
      "10: -3.2399e-03 -3.2417e-03  2e-06  3e-16  9e-16\n",
      "11: -3.2409e-03 -3.2412e-03  2e-07  3e-17  1e-15\n",
      "12: -3.2411e-03 -3.2411e-03  3e-08  1e-17  1e-15\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.5988e+01  4.2609e+00  9e+02  4e+01  7e-01\n",
      " 1: -6.2809e+00 -6.4558e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.4731e+01 -2.8669e+01  1e+02  3e+00  6e-02\n",
      " 3:  1.4458e+01 -5.5367e+00  3e+01  3e-01  6e-03\n",
      " 4:  2.0732e+00 -4.2138e-01  3e+00  3e-03  5e-05\n",
      " 5:  1.2682e-01 -3.3590e-02  2e-01  1e-05  2e-07\n",
      " 6:  4.4368e-03 -6.2595e-03  1e-02  8e-08  2e-09\n",
      " 7: -2.6460e-03 -3.6476e-03  1e-03  6e-10  1e-11\n",
      " 8: -3.2195e-03 -3.3384e-03  1e-04  5e-12  9e-14\n",
      " 9: -3.2842e-03 -3.2993e-03  2e-05  3e-14  1e-15\n",
      "10: -3.2923e-03 -3.2943e-03  2e-06  3e-16  1e-15\n",
      "11: -3.2934e-03 -3.2936e-03  2e-07  1e-17  1e-15\n",
      "12: -3.2935e-03 -3.2936e-03  3e-08  8e-20  8e-16\n",
      "Optimal solution found.\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.3751e+01  5.9629e+00  9e+02  4e+01  7e-01\n",
      " 1: -4.5117e+00 -6.2794e+01  3e+02  1e+01  2e-01\n",
      " 2:  2.7550e+01 -2.6497e+01  1e+02  3e+00  5e-02\n",
      " 3:  1.2731e+01 -3.9089e+00  2e+01  7e-02  1e-03\n",
      " 4:  1.3586e+00 -2.8433e-01  2e+00  5e-04  1e-05\n",
      " 5:  7.9900e-02 -2.6313e-02  1e-01  3e-06  5e-08\n",
      " 6:  1.5025e-03 -6.3219e-03  8e-03  2e-08  4e-10\n",
      " 7: -3.6079e-03 -4.3696e-03  8e-04  1e-10  3e-12\n",
      " 8: -4.0548e-03 -4.1422e-03  9e-05  1e-12  2e-14\n",
      " 9: -4.1025e-03 -4.1135e-03  1e-05  7e-15  8e-16\n",
      "10: -4.1084e-03 -4.1098e-03  1e-06  8e-17  1e-15\n",
      "11: -4.1092e-03 -4.1094e-03  2e-07  3e-17  1e-15\n",
      "12: -4.1093e-03 -4.1093e-03  2e-08  3e-17  1e-15\n",
      "Optimal solution found.\n",
      "RMSE List of IWKRR: [0.5167320477019498, 0.4025134758811422, 0.26531505739249034, 0.36640895331559253, 0.44057059590288217, 0.49193060847211945, 0.5428149386866571, 0.24490467011908243, 0.4791052941887234, 0.6996077040323616, 0.34089008287875794, 0.5467309051903643, 0.8010450846549195, 0.9827993442739485, 1.1019085011517415, 0.42359201680174485, 0.4128093603855924, 0.14528032960478363, 0.5049947124116744, 0.49922303002291424]\n",
      "R^2 List of IWKRR: [0.7436130684207419, 0.0406739199496014, 0.881361694513919, 0.806366162537984, 0.9282985710936419, 0.9242856924858668, 0.7875804667994849, 0.8438845768434655, 0.4290377865887559, 0.3905970995269758, 0.7141551832006939, 0.6900304665180985, 0.12424281191610838, 0.6032491968474238, 0.13513445120104367, 0.25805439083862053, 0.5822115479978621, 0.9792862630901723, 0.06521467038197802, 0.8237085565829456]\n",
      "\n",
      "\n",
      "Mean, STDev of RMSE: 0.5104588356534722 0.23442111100572105\n",
      "Mean, STDev of R^2: 0.5875493288667692 0.31568978914200974\n"
     ]
    }
   ],
   "source": [
    "#################################### Instance_KRR Housing ################################################################\n",
    "from IW_KRR import InstanceKRR\n",
    "\n",
    "n_estimators = 100\n",
    "steps = 30\n",
    "fold = 20\n",
    "\n",
    "r2scorelist_IWKRR_auto = []\n",
    "rmselist_IWKRR_auto = []\n",
    "\n",
    "print(\"IWKRR\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "\n",
    "kf = KFold(n_splits = 20)\n",
    "\n",
    "for train_idx, test_idx in kf.split(auto_tgt_df):\n",
    "        \n",
    "    auto_train_df_X = auto_tgt_df.iloc[train_idx].loc[:, features_auto]\n",
    "    auto_test_df_X = auto_tgt_df.iloc[test_idx][features_auto]\n",
    "    auto_train_df_y = auto_tgt_df.iloc[train_idx].loc[:,target_auto]\n",
    "    auto_test_df_y = auto_tgt_df.loc[test_idx][target_auto]\n",
    "    \n",
    "    auto_np_tgt_X = auto_train_df_X.to_numpy()\n",
    "    auto_np_tgt_y = auto_train_df_y.to_numpy()\n",
    "\n",
    "    auto_X_df = pd.concat([auto_source_df_X, auto_train_df_X], ignore_index=True)\n",
    "    auto_y_df = pd.concat([auto_source_df_y, auto_train_df_y], ignore_index=True)\n",
    "\n",
    "    auto_np_train_X = auto_X_df.to_numpy()\n",
    "    auto_np_train_y = auto_y_df.to_numpy()\n",
    "\n",
    "    auto_np_test_X = auto_test_df_X.to_numpy()\n",
    "    auto_np_test_y = auto_test_df_y.to_numpy()\n",
    "\n",
    "    auto_np_train_y_list = auto_np_train_y.ravel()\n",
    "    auto_np_test_y_list = auto_np_test_y.ravel()\n",
    "    \n",
    "    sample_size = [len(auto_source_df_X), len(auto_train_df_X)]\n",
    "\n",
    "\n",
    "    model_IWKRR_auto = InstanceKRR(lmbd = 0.5, kernel = 'rbf', gamma = None, degree = 3, coef0 = 1, kernel_params = None)\n",
    "    model_IWKRR_auto.fit(auto_np_train_X, auto_np_train_y_list)\n",
    "    model_IWKRR_auto.Solve_alpha(auto_np_tgt_X, auto_np_tgt_y)\n",
    "    \n",
    "    y_pred_IWKRR_auto = model_IWKRR_auto.predict(auto_np_test_X)\n",
    "    y_pred_IWKRR_auto = [item for sublist in y_pred_IWKRR_auto for item in sublist]\n",
    "\n",
    "    mse_IWKRR_auto = sqrt(mean_squared_error(auto_np_test_y, y_pred_IWKRR_auto))\n",
    "    rmselist_IWKRR_auto.append(mse_IWKRR_auto)\n",
    "        \n",
    "    r2_score_IWKRR_auto = pearsonr(auto_np_test_y_list, y_pred_IWKRR_auto)\n",
    "    r2_score_IWKRR_auto = (r2_score_IWKRR_auto[0])**2\n",
    "    r2scorelist_IWKRR_auto.append(r2_score_IWKRR_auto)\n",
    "\n",
    "\n",
    "print(\"RMSE List of IWKRR:\", rmselist_IWKRR_auto)\n",
    "print(\"R^2 List of IWKRR:\", r2scorelist_IWKRR_auto)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Mean, STDev of RMSE:\", statistics.mean(rmselist_IWKRR_auto), statistics.stdev(rmselist_IWKRR_auto))\n",
    "print(\"Mean, STDev of R^2:\", statistics.mean(r2scorelist_IWKRR_auto), statistics.stdev(r2scorelist_IWKRR_auto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09387925740000946 0.9262421791063029\n",
      "0.468273988433133 0.6452092125474611\n",
      "-0.7005342904293791 0.4925503891649965\n",
      "\n",
      "\n",
      "-0.21561187287426226 0.8317146184323403\n",
      "-0.08862966216384667 0.9303548911060949\n",
      "0.7542751148496798 0.46043871525449653\n"
     ]
    }
   ],
   "source": [
    "#### Independent t-test\n",
    "from scipy import stats\n",
    "\n",
    "stats_StAd_rmse, pval_StAd_rmse = stats.ttest_ind(rmselist_stradaboost_auto, rmselist_AdaTL_auto)\n",
    "print(stats_StAd_rmse, pval_StAd_rmse)\n",
    "\n",
    "stats_StGb_rmse, pval_StGb_rmse = stats.ttest_ind(rmselist_stradaboost_auto, rmselist_GBRTL_auto)\n",
    "print(stats_StGb_rmse, pval_StGb_rmse)\n",
    "\n",
    "stats_StTr_rmse, pval_StTr_rmse = stats.ttest_ind(rmselist_stradaboost_auto, rmselist_TwoTrAda_auto)\n",
    "print(stats_StTr_rmse, pval_StTr_rmse)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "stats_StAd_r2, pval_StAd_r2 = stats.ttest_ind(r2scorelist_stradaboost_auto, r2scorelist_AdaTL_auto)\n",
    "print(stats_StAd_r2, pval_StAd_r2)\n",
    "\n",
    "stats_StGb_r2, pval_StGb_r2 = stats.ttest_ind(r2scorelist_stradaboost_auto, r2scorelist_GBRTL_auto)\n",
    "print(stats_StGb_r2, pval_StGb_r2)\n",
    "\n",
    "stats_StTr_r2, pval_StTr_r2 = stats.ttest_ind(r2scorelist_stradaboost_auto, r2scorelist_TwoTrAda_auto)\n",
    "print(stats_StTr_r2, pval_StTr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.027595320206241 0.33096466564742744\n",
      "2.3507126938039717 0.04325455224503656\n",
      "-1.4188348219534268 0.1896360652668623\n",
      "\n",
      "\n",
      "-1.5799623613158462 0.14857296728108557\n",
      "-0.55014538292201 0.5956072149748616\n",
      "1.6768498418527644 0.12788653793474053\n"
     ]
    }
   ],
   "source": [
    "#### Dependent(paired) t-test\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "stats_StAd_rmse, pval_StAd_rmse = stats.ttest_rel(rmselist_stradaboost_auto, rmselist_AdaTL_auto)\n",
    "print(stats_StAd_rmse, pval_StAd_rmse)\n",
    "\n",
    "stats_StGb_rmse, pval_StGb_rmse = stats.ttest_rel(rmselist_stradaboost_auto, rmselist_GBRTL_auto)\n",
    "print(stats_StGb_rmse, pval_StGb_rmse)\n",
    "\n",
    "stats_StTr_rmse, pval_StTr_rmse = stats.ttest_rel(rmselist_stradaboost_auto, rmselist_TwoTrAda_auto)\n",
    "print(stats_StTr_rmse, pval_StTr_rmse)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "stats_StAd_r2, pval_StAd_r2 = stats.ttest_rel(r2scorelist_stradaboost_auto, r2scorelist_AdaTL_auto)\n",
    "print(stats_StAd_r2, pval_StAd_r2)\n",
    "\n",
    "stats_StGb_r2, pval_StGb_r2 = stats.ttest_rel(r2scorelist_stradaboost_auto, r2scorelist_GBRTL_auto)\n",
    "print(stats_StGb_r2, pval_StGb_r2)\n",
    "\n",
    "stats_StTr_r2, pval_StTr_r2 = stats.ttest_rel(r2scorelist_stradaboost_auto, r2scorelist_TwoTrAda_auto)\n",
    "print(stats_StTr_r2, pval_StTr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "labels = ['Concrete', 'Housing', 'Auto']\n",
    "\n",
    "TR_means = [20, 35, 30]\n",
    "STR_means = [25, 32, 34]\n",
    "ADA_means = [25, 32, 34]\n",
    "GBR_means = [25, 32, 34]\n",
    "\n",
    "TR_std = [20, 35, 30]\n",
    "STR_std = [25, 32, 34]\n",
    "ADA_std = [25, 32, 34]\n",
    "GBR_std = [25, 32, 34]\n",
    "\n",
    "width = 0.35       \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(labels, men_means, width, yerr=men_std, label='Men')\n",
    "ax.bar(labels, women_means, width, yerr=women_std, bottom=men_means,\n",
    "       label='Women')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
